{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys \n",
    "# sys.path.clear()\n",
    "sys.path.insert(0, 'D:\\\\Anaconda\\\\envs\\\\tensorflow_cpu\\\\python36.zip')\n",
    "sys.path.insert(0, 'D:\\\\Anaconda\\\\envs\\\\tensorflow_cpu\\\\DLLs')\n",
    "sys.path.insert(0, 'D:\\\\Anaconda\\\\envs\\\\tensorflow_cpu\\\\lib')\n",
    "sys.path.insert(0, 'D:\\\\Anaconda\\\\envs\\\\tensorflow_cpu')\n",
    "sys.path.insert(0, 'D:\\\\Anaconda\\\\envs\\\\tensorflow_cpu\\\\lib\\\\site-packages')\n",
    "sys.path.insert(0, '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " 'D:\\\\Anaconda\\\\envs\\\\tensorflow_cpu\\\\lib\\\\site-packages',\n",
       " 'D:\\\\Anaconda\\\\envs\\\\tensorflow_cpu',\n",
       " 'D:\\\\Anaconda\\\\envs\\\\tensorflow_cpu\\\\lib',\n",
       " 'D:\\\\Anaconda\\\\envs\\\\tensorflow_cpu\\\\DLLs',\n",
       " 'D:\\\\Anaconda\\\\envs\\\\tensorflow_cpu\\\\python36.zip']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "# TensorFlow and tf.keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# Helper libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix, load_npz, save_npz\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import normalize\n",
    "import datetime\n",
    "import json\n",
    "import pandas as pd\n",
    "import time\n",
    "import yaml\n",
    "import scipy.sparse as sparse\n",
    "from ast import literal_eval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load Original Data\n",
    "df_train = pd.read_csv('../../data/yelp/Train.csv',encoding='latin-1')\n",
    "df_valid = pd.read_csv('../../data/yelp/Valid.csv',encoding='latin-1')\n",
    "df_test = pd.read_csv('../../data/yelp/Test.csv',encoding='latin-1')\n",
    "keyphrases = pd.read_csv('../../data/yelp/KeyPhrases.csv')['Phrases'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def to_sparse_matrix(df, num_user, num_item, user_col, item_col, rating_col):\n",
    "\n",
    "    dok = df[[user_col, item_col, rating_col]].copy()\n",
    "    dok = dok.values\n",
    "    dok = dok[dok[:, 2] > 0]\n",
    "    shape = [num_user, num_item]\n",
    "    return sparse.csr_matrix((dok[:, 2].astype(np.float32), (dok[:, 0], dok[:, 1])), shape=shape)\n",
    "\n",
    "def generate_sparse():\n",
    "#     num_users = df_train['UserIndex'].nunique()\n",
    "#     num_items = df_train['ItemIndex'].nunique()\n",
    "    num_users = df_train['UserIndex'].max() + 1\n",
    "    num_items = df_train['ItemIndex'].max() + 1\n",
    "    R_train = to_sparse_matrix(df_train, num_users, num_items, 'UserIndex', 'ItemIndex', rating_col)\n",
    "    sparse.save_npz('../../data/yelp/' + 'Rtrain.npz', R_train)\n",
    "    \n",
    "    R_valid = to_sparse_matrix(df_valid, num_users, num_items, 'UserIndex','ItemIndex', rating_col)\n",
    "    sparse.save_npz('../../data/yelp/' + 'Rvalid.npz', R_valid)\n",
    "    \n",
    "    R_test = to_sparse_matrix(df_test, num_users, num_items, 'UserIndex', 'ItemIndex', rating_col)\n",
    "    sparse.save_npz('../../data/yelp/' + 'Rtest.npz', R_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7455"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['ItemIndex'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2191"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['UserIndex'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2342"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['UserIndex'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rating_col = 'rating'\n",
    "generate_sparse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load U-I Data \n",
    "rtrain = load_npz(\"../../data/yelp/Rtrain.npz\")\n",
    "rvalid = load_npz(\"../../data/yelp/Rvalid.npz\")\n",
    "rtest = load_npz(\"../../data/yelp/Rtest.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2343x7456 sparse matrix of type '<class 'numpy.float32'>'\n",
       "\twith 95153 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rtrain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Models\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "def train(matrix_train):\n",
    "    similarity = cosine_similarity(X=matrix_train, Y=None, dense_output=True)\n",
    "    return similarity\n",
    "\n",
    "def get_I_K(df, row_name = 'ItemIndex', shape = (3668,75)):\n",
    "    rows = []\n",
    "    cols = []\n",
    "    vals = []\n",
    "    for i in tqdm(range(df.shape[0])):\n",
    "        key_vector = literal_eval(df['keyVector'][i])\n",
    "        rows.extend([df[row_name][i]]*len(key_vector)) ## Item index\n",
    "        cols.extend(key_vector) ## Keyword Index\n",
    "        vals.extend(np.array([1]*len(key_vector)))\n",
    "    return csr_matrix((vals, (rows, cols)), shape=shape)\n",
    "\n",
    "def predict(matrix_train, k, similarity, item_similarity_en = False):\n",
    "    \"\"\"\n",
    "    res = similarity * matrix_train    if item_similarity_en = False\n",
    "    res = similarity * matrix_train.T  if item_similarity_en = True\n",
    "    \"\"\"\n",
    "    prediction_scores = []\n",
    "    \n",
    "    if item_similarity_en:\n",
    "        matrix_train = matrix_train.transpose()\n",
    "        \n",
    "    for user_index in tqdm(range(matrix_train.shape[0])):\n",
    "        # Get user u's prediction scores to all users\n",
    "        vector_u = similarity[user_index]\n",
    "\n",
    "        # Get closest K neighbors excluding user u self\n",
    "        similar_users = vector_u.argsort()[::-1][1:k+1]\n",
    "        # Get neighbors similarity weights and ratings\n",
    "        similar_users_weights = similarity[user_index][similar_users]\n",
    "        similar_users_ratings = matrix_train[similar_users].toarray()\n",
    "\n",
    "        prediction_scores_u = similar_users_ratings * similar_users_weights[:, np.newaxis]\n",
    "\n",
    "        prediction_scores.append(np.sum(prediction_scores_u, axis=0))\n",
    "    res = np.array(prediction_scores)\n",
    "    \n",
    "    if item_similarity_en:\n",
    "        res = res.transpose()\n",
    "    \n",
    "    return res\n",
    "\n",
    "def prediction(prediction_score, topK, matrix_Train):\n",
    "\n",
    "    prediction = []\n",
    "\n",
    "    for user_index in tqdm(range(matrix_Train.shape[0])):\n",
    "        vector_u = prediction_score[user_index]\n",
    "        vector_train = matrix_Train[user_index]\n",
    "        if len(vector_train.nonzero()[0]) > 0:\n",
    "            vector_predict = sub_routine(vector_u, vector_train, topK=topK)\n",
    "        else:\n",
    "            vector_predict = np.zeros(topK, dtype=np.float32)\n",
    "\n",
    "        prediction.append(vector_predict)\n",
    "\n",
    "    return np.vstack(prediction)\n",
    "\n",
    "\n",
    "def sub_routine(vector_u, vector_train, topK=500):\n",
    "\n",
    "    train_index = vector_train.nonzero()[1]\n",
    "\n",
    "    vector_u = vector_u\n",
    "\n",
    "    candidate_index = np.argpartition(-vector_u, topK+len(train_index))[:topK+len(train_index)]\n",
    "    vector_u = candidate_index[vector_u[candidate_index].argsort()[::-1]]\n",
    "    vector_u = np.delete(vector_u, np.isin(vector_u, train_index).nonzero()[0])\n",
    "\n",
    "    return vector_u[:topK]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Evluation \n",
    "def recallk(vector_true_dense, hits, **unused):\n",
    "    hits = len(hits.nonzero()[0])\n",
    "    return float(hits)/len(vector_true_dense)\n",
    "\n",
    "def precisionk(vector_predict, hits, **unused):\n",
    "    hits = len(hits.nonzero()[0])\n",
    "    return float(hits)/len(vector_predict)\n",
    "\n",
    "\n",
    "def average_precisionk(vector_predict, hits, **unused):\n",
    "    precisions = np.cumsum(hits, dtype=np.float32)/range(1, len(vector_predict)+1)\n",
    "    return np.mean(precisions)\n",
    "\n",
    "\n",
    "def r_precision(vector_true_dense, vector_predict, **unused):\n",
    "    vector_predict_short = vector_predict[:len(vector_true_dense)]\n",
    "    hits = len(np.isin(vector_predict_short, vector_true_dense).nonzero()[0])\n",
    "    return float(hits)/len(vector_true_dense)\n",
    "\n",
    "\n",
    "def _dcg_support(size):\n",
    "    arr = np.arange(1, size+1)+1\n",
    "    return 1./np.log2(arr)\n",
    "\n",
    "\n",
    "def ndcg(vector_true_dense, vector_predict, hits):\n",
    "    idcg = np.sum(_dcg_support(len(vector_true_dense)))\n",
    "    dcg_base = _dcg_support(len(vector_predict))\n",
    "    dcg_base[np.logical_not(hits)] = 0\n",
    "    dcg = np.sum(dcg_base)\n",
    "    return dcg/idcg\n",
    "\n",
    "\n",
    "def click(hits, **unused):\n",
    "    first_hit = next((i for i, x in enumerate(hits) if x), None)\n",
    "    if first_hit is None:\n",
    "        return 5\n",
    "    else:\n",
    "        return first_hit/10\n",
    "\n",
    "\n",
    "def evaluate(matrix_Predict, matrix_Test, metric_names =['R-Precision', 'NDCG', 'Precision', 'Recall', 'MAP'], atK = [5, 10, 15, 20, 50], analytical=False):\n",
    "    \"\"\"\n",
    "    :param matrix_U: Latent representations of users, for LRecs it is RQ, for ALSs it is U\n",
    "    :param matrix_V: Latent representations of items, for LRecs it is Q, for ALSs it is V\n",
    "    :param matrix_Train: Rating matrix for training, features.\n",
    "    :param matrix_Test: Rating matrix for evaluation, true labels.\n",
    "    :param k: Top K retrieval\n",
    "    :param metric_names: Evaluation metrics\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    global_metrics = {\n",
    "        \"R-Precision\": r_precision,\n",
    "        \"NDCG\": ndcg,\n",
    "        \"Clicks\": click\n",
    "    }\n",
    "\n",
    "    local_metrics = {\n",
    "        \"Precision\": precisionk,\n",
    "        \"Recall\": recallk,\n",
    "        \"MAP\": average_precisionk\n",
    "    }\n",
    "\n",
    "    output = dict()\n",
    "\n",
    "    num_users = matrix_Predict.shape[0]\n",
    "\n",
    "    for k in atK:\n",
    "\n",
    "        local_metric_names = list(set(metric_names).intersection(local_metrics.keys()))\n",
    "        results = {name: [] for name in local_metric_names}\n",
    "        topK_Predict = matrix_Predict[:, :k]\n",
    "\n",
    "        for user_index in tqdm(range(topK_Predict.shape[0])):\n",
    "            vector_predict = topK_Predict[user_index]\n",
    "            if len(vector_predict.nonzero()[0]) > 0:\n",
    "                vector_true = matrix_Test[user_index]\n",
    "                vector_true_dense = vector_true.nonzero()[1]\n",
    "                hits = np.isin(vector_predict, vector_true_dense)\n",
    "\n",
    "                if vector_true_dense.size > 0:\n",
    "                    for name in local_metric_names:\n",
    "                        results[name].append(local_metrics[name](vector_true_dense=vector_true_dense,\n",
    "                                                                 vector_predict=vector_predict,\n",
    "                                                                 hits=hits))\n",
    "\n",
    "        results_summary = dict()\n",
    "        if analytical:\n",
    "            for name in local_metric_names:\n",
    "                results_summary['{0}@{1}'.format(name, k)] = results[name]\n",
    "        else:\n",
    "            for name in local_metric_names:\n",
    "                results_summary['{0}@{1}'.format(name, k)] = (np.average(results[name]),\n",
    "                                                              1.96*np.std(results[name])/np.sqrt(num_users))\n",
    "        output.update(results_summary)\n",
    "\n",
    "    global_metric_names = list(set(metric_names).intersection(global_metrics.keys()))\n",
    "    results = {name: [] for name in global_metric_names}\n",
    "\n",
    "    topK_Predict = matrix_Predict[:]\n",
    "\n",
    "    for user_index in tqdm(range(topK_Predict.shape[0])):\n",
    "        vector_predict = topK_Predict[user_index]\n",
    "\n",
    "        if len(vector_predict.nonzero()[0]) > 0:\n",
    "            vector_true = matrix_Test[user_index]\n",
    "            vector_true_dense = vector_true.nonzero()[1]\n",
    "            hits = np.isin(vector_predict, vector_true_dense)\n",
    "\n",
    "            # if user_index == 1:\n",
    "            #     import ipdb;\n",
    "            #     ipdb.set_trace()\n",
    "\n",
    "            if vector_true_dense.size > 0:\n",
    "                for name in global_metric_names:\n",
    "                    results[name].append(global_metrics[name](vector_true_dense=vector_true_dense,\n",
    "                                                              vector_predict=vector_predict,\n",
    "                                                              hits=hits))\n",
    "\n",
    "    results_summary = dict()\n",
    "    if analytical:\n",
    "        for name in global_metric_names:\n",
    "            results_summary[name] = results[name]\n",
    "    else:\n",
    "        for name in global_metric_names:\n",
    "            results_summary[name] = (np.average(results[name]), 1.96*np.std(results[name])/np.sqrt(num_users))\n",
    "    output.update(results_summary)\n",
    "\n",
    "    return output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2343x7456 sparse matrix of type '<class 'numpy.float32'>'\n",
       "\twith 95153 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rtrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "235"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(keyphrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 95153/95153 [04:33<00:00, 348.48it/s]\n"
     ]
    }
   ],
   "source": [
    "# Generate U-K \n",
    "U_K = get_I_K(df_train, row_name = 'UserIndex', shape = (2343,235))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_npz(\"../../data/yelp/U_K\",U_K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "U_K = load_npz(\"../../data/yelp/U_K.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 95153/95153 [04:03<00:00, 391.29it/s]\n"
     ]
    }
   ],
   "source": [
    "# Generate I-K \n",
    "I_K = get_I_K(df_train, row_name = 'ItemIndex', shape = (7456,235))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_npz(\"../../data/yelp/I_K\",I_K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "I_K = load_npz(\"../../data/yelp/I_K.npz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# U_I Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 2343/2343 [00:07<00:00, 297.19it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 2343/2343 [00:00<00:00, 2633.63it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 2343/2343 [00:00<00:00, 4633.66it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 2343/2343 [00:00<00:00, 4390.92it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 2343/2343 [00:00<00:00, 4326.47it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 2343/2343 [00:00<00:00, 4526.53it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 2343/2343 [00:00<00:00, 4500.23it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 2343/2343 [00:00<00:00, 4043.50it/s]\n"
     ]
    }
   ],
   "source": [
    "similarity = normalize(train(rtrain))\n",
    "user_item_prediction_score = predict(rtrain, 100, similarity, item_similarity_en= False)\n",
    "user_item_predict = prediction(user_item_prediction_score, 50, rtrain)\n",
    "user_item_res = evaluate(user_item_predict, rvalid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MAP@10': (0.051073692522802513, 0.004057146027986048),\n",
       " 'MAP@15': (0.04740085851906938, 0.003359527402347134),\n",
       " 'MAP@20': (0.044743950128338206, 0.002931008949008714),\n",
       " 'MAP@5': (0.05701658299102388, 0.005498800420458874),\n",
       " 'MAP@50': (0.036229210065942374, 0.0018910890109491262),\n",
       " 'NDCG': (0.08489767566647444, 0.0037106587556144806),\n",
       " 'Precision@10': (0.042172523961661344, 0.002787504501522014),\n",
       " 'Precision@15': (0.03879507074395253, 0.0022771241184831627),\n",
       " 'Precision@20': (0.03555454130534003, 0.0019002509290587605),\n",
       " 'Precision@5': (0.050296668188041994, 0.004168258666849642),\n",
       " 'Precision@50': (0.02735737106344135, 0.0012439499801260928),\n",
       " 'R-Precision': (0.041733866795200275, 0.0027759220013279197),\n",
       " 'Recall@10': (0.04138686214086912, 0.0029327051931329613),\n",
       " 'Recall@15': (0.056532202532316896, 0.0034058829474612855),\n",
       " 'Recall@20': (0.06920549460798729, 0.0037456497239839255),\n",
       " 'Recall@5': (0.025432825237707825, 0.0023478703305939417),\n",
       " 'Recall@50': (0.1294308432731444, 0.005081726475920628)}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# k = 100\n",
    "user_item_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unlearned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 2343/2343 [00:12<00:00, 180.76it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 2343/2343 [00:00<00:00, 2550.70it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 2343/2343 [00:00<00:00, 4449.14it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 2343/2343 [00:00<00:00, 4707.70it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 2343/2343 [00:00<00:00, 4509.40it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 2343/2343 [00:00<00:00, 4746.00it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 2343/2343 [00:00<00:00, 4670.52it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 2343/2343 [00:00<00:00, 4043.29it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'MAP@10': (0.03807290647888548, 0.0034516964720750546),\n",
       " 'MAP@15': (0.03553797209433905, 0.0028672870257672785),\n",
       " 'MAP@20': (0.03370376900344167, 0.0025074125274402795),\n",
       " 'MAP@5': (0.041119732237943095, 0.004657532891059873),\n",
       " 'MAP@50': (0.027602870159743928, 0.0016228342694287708),\n",
       " 'NDCG': (0.06511835191702671, 0.0033052172013054884),\n",
       " 'Precision@10': (0.03322683706070288, 0.002465220667665642),\n",
       " 'Precision@15': (0.0293321162330747, 0.001957297652179952),\n",
       " 'Precision@20': (0.027407576449109995, 0.0016911246343864425),\n",
       " 'Precision@5': (0.038703788224555, 0.003570729979189414),\n",
       " 'Precision@50': (0.020949338201734367, 0.001040247535464102),\n",
       " 'R-Precision': (0.03192788335932602, 0.002458395387461051),\n",
       " 'Recall@10': (0.033001237423790984, 0.0026792409055536887),\n",
       " 'Recall@15': (0.0433697047824931, 0.0030981184280090826),\n",
       " 'Recall@20': (0.05395011310626228, 0.003459003186056587),\n",
       " 'Recall@5': (0.019905087004912992, 0.0021000202554456375),\n",
       " 'Recall@50': (0.1005849841010983, 0.004588005163519814)}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity = normalize(train(U_K))\n",
    "unlearned_prediction_score = predict(rtrain, 100, similarity, item_similarity_en= False)\n",
    "unlearned_predict = prediction(unlearned_prediction_score, 50, rtrain)\n",
    "unlearned_res = evaluate(unlearned_predict, rvalid)\n",
    "unlearned_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learned with Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = normalize(U_K.todense())\n",
    "y = normalize(train(rtrain))\n",
    "# y = U_I_similarity\n",
    "clf = Ridge(alpha=0.001).fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr_similarity = clf.predict(np.array(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 2343/2343 [00:12<00:00, 184.72it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 2343/2343 [00:00<00:00, 2660.55it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 2343/2343 [00:00<00:00, 4736.44it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 2343/2343 [00:00<00:00, 4717.42it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 2343/2343 [00:00<00:00, 4794.15it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 2343/2343 [00:00<00:00, 4755.39it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 2343/2343 [00:00<00:00, 4679.83it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 2343/2343 [00:00<00:00, 4279.18it/s]\n"
     ]
    }
   ],
   "source": [
    "similarity = lr_similarity\n",
    "lr_prediction_score = predict(rtrain, 100, similarity, item_similarity_en= False)\n",
    "lr_predict = prediction(lr_prediction_score, 50, rtrain)\n",
    "lr_res = evaluate(lr_predict, rvalid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MAP@10': (0.04791011931929322, 0.003909906530540023),\n",
       " 'MAP@15': (0.04472455659356618, 0.0032453570885310626),\n",
       " 'MAP@20': (0.042183593262152395, 0.002831975800912942),\n",
       " 'MAP@5': (0.05255134641716111, 0.0053077652762159545),\n",
       " 'MAP@50': (0.03409008663773755, 0.0018206458827478736),\n",
       " 'NDCG': (0.080007877002718, 0.0036741296182457423),\n",
       " 'Precision@10': (0.04043815609310817, 0.0027488356456966574),\n",
       " 'Precision@15': (0.036969420356001835, 0.002209056993815675),\n",
       " 'Precision@20': (0.03372889091738932, 0.001865902272311573),\n",
       " 'Precision@5': (0.04801460520310361, 0.004019422218032844),\n",
       " 'Precision@50': (0.025349155636695576, 0.0011602543418718766),\n",
       " 'R-Precision': (0.03995729846245619, 0.0027870432323067475),\n",
       " 'Recall@10': (0.04015089215945651, 0.002938149676122475),\n",
       " 'Recall@15': (0.05452043367806783, 0.003360650501561797),\n",
       " 'Recall@20': (0.06574394345131794, 0.003655624471281709),\n",
       " 'Recall@5': (0.024317606292104284, 0.0023406152577752615),\n",
       " 'Recall@50': (0.12248665145198735, 0.005089844615252921)}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One-hot encoding of critiques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use one-hot encoding of critiques to project into user-similarity space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2343x235 sparse matrix of type '<class 'numpy.int32'>'\n",
       "\twith 242115 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "U_K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_critiqued_UK(user_keyphrase_frequency,user_index,critiqued_keyphrase):\n",
    "    \"\"\"\n",
    "    user_keyphrase_frequency is the U_K matrix (csr sparse matrix)\n",
    "    return the one-hot encoding of the critique\n",
    "    \"\"\"\n",
    "    U_K_cp = user_keyphrase_frequency.copy()\n",
    "    U_K_cp[user_index] = 0\n",
    "    U_K_cp[user_index,critiqued_keyphrase] = 1\n",
    "    return U_K_cp\n",
    "\n",
    "def project_one_hot_encoding(reg, user_keyphrase_frequency,user_index,critiqued_keyphrase, normalize_en = True):\n",
    "    \"\"\"\n",
    "    Return the projection on user_sim space from one-hot encoding of critiqued keyphrase\n",
    "    The res[user_index] should be target embedding row\n",
    "    \"\"\"\n",
    "    critiqued_matrix = get_critiqued_UK(user_keyphrase_frequency, user_index, critiqued_keyphrase)\n",
    "    res = reg.predict(critiqued_matrix)\n",
    "    if normalize_en:\n",
    "        res = normalize((res))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\tensorflow_cpu\\lib\\site-packages\\scipy\\sparse\\_index.py:126: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_arrayXarray(i, j, x)\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "critiqued_matrix = project_one_hot_encoding(clf, U_K, 0, 0,normalize_en = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00503134, 0.1046469 , 0.02630396, ..., 0.        , 0.00029115,\n",
       "       0.00124497])"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "critiqued_matrix[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedding of original U_U + critique projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the matrix\n",
    "modified_matrix = normalize(train(rtrain)).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.4867929 , 0.01587667, 0.01536822, ..., 0.        , 0.        ,\n",
       "       0.        ], dtype=float32)"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modified_matrix[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learn the lambdas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.4867929 , 0.01587667, 0.01536822, ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.01717785, 0.5266886 , 0.00329018, ..., 0.        , 0.01379578,\n",
       "        0.        ],\n",
       "       [0.01747107, 0.00345705, 0.55340123, ..., 0.        , 0.        ,\n",
       "        0.0229555 ],\n",
       "       ...,\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.01634563, 0.        , ..., 0.        , 0.6240353 ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.02697603, ..., 0.        , 0.        ,\n",
       "        0.6503266 ]], dtype=float32)"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modified_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.00612141, -0.02221741, -0.00579472, ...,  0.        ,\n",
       "         0.03756859, -0.0309494 ],\n",
       "       [ 0.00503134,  0.1046469 ,  0.02630396, ...,  0.        ,\n",
       "         0.00029115,  0.00124497],\n",
       "       [ 0.01630788,  0.02821016,  0.09550076, ...,  0.        ,\n",
       "         0.01960971,  0.02490069],\n",
       "       ...,\n",
       "       [ 0.00338559, -0.04381626, -0.01855125, ...,  0.        ,\n",
       "        -0.01606787,  0.03146326],\n",
       "       [ 0.01187455,  0.01655502,  0.02848183, ...,  0.        ,\n",
       "         0.15997426,  0.01094426],\n",
       "       [ 0.0025182 , -0.00189156,  0.03735052, ...,  0.        ,\n",
       "         0.03354831,  0.1618768 ]])"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "critiqued_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# AVERAGE \n",
    "\n",
    "# Combine critiqued matrix with modified directly (asumming only one critique)\n",
    "modified_matrix = modified_matrix + critiqued_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.48067148, -0.00634074,  0.00957349, ...,  0.        ,\n",
       "        0.03756859, -0.0309494 ])"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modified_matrix[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constructing the w*p matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.48067148],\n",
       "       [-0.00634074],\n",
       "       [ 0.00957349],\n",
       "       ...,\n",
       "       [ 0.        ],\n",
       "       [ 0.03756859],\n",
       "       [-0.0309494 ]])"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W.reshape(2343,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "# l = lambda, the weights we want to learn\n",
    "W = modified_matrix[0]\n",
    "P = rtrain[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_row = W*np.ravel(P.todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2343,)"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_row.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define rating targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# To define the rating targets, simply modify final prediction of U-I matrix's user_index row,\n",
    "# Make the target critiqued item's predicted rating to be 1 (out of 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "critiqued_keyphrase = 0\n",
    "user_index = 0\n",
    "affected_items = I_K[:, critiqued_keyphrase].nonzero()[user_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   2,    6,   13, ..., 7434, 7439, 7441])"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "affected_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 309)\t5.0\n",
      "  (0, 539)\t4.0\n",
      "  (0, 585)\t3.0\n",
      "  (0, 719)\t4.0\n",
      "  (0, 823)\t4.0\n",
      "  (0, 831)\t5.0\n",
      "  (0, 1438)\t4.0\n",
      "  (0, 1650)\t4.0\n",
      "  (0, 1710)\t4.0\n",
      "  (0, 1999)\t3.0\n",
      "  (0, 2075)\t4.0\n",
      "  (0, 2804)\t4.0\n",
      "  (0, 2868)\t4.0\n",
      "  (0, 3298)\t4.0\n",
      "  (0, 3623)\t3.0\n",
      "  (0, 3729)\t4.0\n",
      "  (0, 4358)\t5.0\n",
      "  (0, 4841)\t4.0\n",
      "  (0, 5081)\t4.0\n",
      "  (0, 5291)\t3.0\n",
      "  (0, 5410)\t4.0\n",
      "  (0, 5706)\t4.0\n",
      "  (0, 6099)\t4.0\n",
      "  (0, 6222)\t5.0\n",
      "  (0, 6299)\t4.0\n",
      "  (0, 6454)\t4.0\n",
      "  (0, 6940)\t5.0\n",
      "  (0, 7060)\t2.0\n"
     ]
    }
   ],
   "source": [
    "target_rating = rtrain[user_index]\n",
    "print (target_rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if affected items in the rtrain[user_index] list, set the rating to low (default = 1)\n",
    "low = 1\n",
    "updated_target_rating = np.ravel(target_rating.todense())\n",
    "updated_target_rating[affected_items] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 1., ..., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "updated_target_rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
