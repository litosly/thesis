{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-50bb0edcd41b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# TensorFlow and tf.keras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "# TensorFlow and tf.keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix, load_npz, save_npz\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import normalize\n",
    "import datetime\n",
    "import json\n",
    "import pandas as pd\n",
    "import time\n",
    "import yaml\n",
    "import scipy.sparse as sparse\n",
    "from ast import literal_eval\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.utils.extmath import randomized_svd\n",
    "\n",
    "from scipy.optimize import minimize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Original Data\n",
    "df_train = pd.read_csv('../../data/yelp/Train.csv',encoding='latin-1')\n",
    "df_valid = pd.read_csv('../../data/yelp/Valid.csv',encoding='latin-1')\n",
    "df_test = pd.read_csv('../../data/yelp/Test.csv',encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyphrases = pd.read_csv('../../data/yelp/KeyPhrases.csv')['Phrases'].tolist()\n",
    "keyphrase_popularity = np.loadtxt('../data/yelp/'+'keyphrase_popularity.txt', dtype=int)\n",
    "\n",
    "# Load U-I Data \n",
    "rtrain = load_npz(\"../../data/yelp/Rtrain.npz\")\n",
    "rvalid = load_npz(\"../../data/yelp/Rvalid.npz\")\n",
    "rtest = load_npz(\"../../data/yelp/Rtest.npz\")\n",
    "\n",
    "# Load user/item keyphrase data\n",
    "U_K = load_npz(\"../../data/yelp/U_K.npz\")\n",
    "I_K = load_npz(\"../../data/yelp/I_K.npz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "def train(matrix_train):\n",
    "    similarity = cosine_similarity(X=matrix_train, Y=None, dense_output=True)\n",
    "    return similarity\n",
    "\n",
    "def get_I_K(df, row_name = 'ItemIndex', shape = (3668,75)):\n",
    "    rows = []\n",
    "    cols = []\n",
    "    vals = []\n",
    "    for i in tqdm(range(df.shape[0])):\n",
    "        key_vector = literal_eval(df['keyVector'][i])\n",
    "        rows.extend([df[row_name][i]]*len(key_vector)) ## Item index\n",
    "        cols.extend(key_vector) ## Keyword Index\n",
    "        vals.extend(np.array([1]*len(key_vector)))\n",
    "    return csr_matrix((vals, (rows, cols)), shape=shape)\n",
    "\n",
    "\n",
    "\n",
    "def prediction(prediction_score, topK, matrix_Train):\n",
    "\n",
    "    prediction = []\n",
    "\n",
    "    for user_index in tqdm(range(matrix_Train.shape[0])):\n",
    "        vector_u = prediction_score[user_index]\n",
    "        vector_train = matrix_Train[user_index]\n",
    "        if len(vector_train.nonzero()[0]) > 0:\n",
    "            vector_predict = sub_routine(vector_u, vector_train, topK=topK)\n",
    "        else:\n",
    "            vector_predict = np.zeros(topK, dtype=np.float32)\n",
    "\n",
    "        prediction.append(vector_predict)\n",
    "\n",
    "    return np.vstack(prediction)\n",
    "\n",
    "\n",
    "def sub_routine(vector_u, vector_train, topK=500):\n",
    "\n",
    "    train_index = vector_train.nonzero()[1]\n",
    "\n",
    "    vector_u = vector_u\n",
    "\n",
    "    candidate_index = np.argpartition(-vector_u, topK+len(train_index))[:topK+len(train_index)]\n",
    "    vector_u = candidate_index[vector_u[candidate_index].argsort()[::-1]]\n",
    "    vector_u = np.delete(vector_u, np.isin(vector_u, train_index).nonzero()[0])\n",
    "\n",
    "    return vector_u[:topK]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(matrix_train, k, similarity, item_similarity_en = False):\n",
    "    \"\"\"\n",
    "    res = similarity * matrix_train    if item_similarity_en = False\n",
    "    res = similarity * matrix_train.T  if item_similarity_en = True\n",
    "    \"\"\"\n",
    "    prediction_scores = []\n",
    "    \n",
    "    if item_similarity_en:\n",
    "        matrix_train = matrix_train.transpose()\n",
    "        \n",
    "    for user_index in tqdm(range(matrix_train.shape[0])):\n",
    "        # Get user u's prediction scores to all users\n",
    "        vector_u = similarity[user_index]\n",
    "\n",
    "        # Get closest K neighbors excluding user u self\n",
    "        similar_users = vector_u.argsort()[::-1][1:k+1]\n",
    "        # Get neighbors similarity weights and ratings\n",
    "        similar_users_weights = similarity[user_index][similar_users]\n",
    "        similar_users_ratings = matrix_train[similar_users].toarray()\n",
    "\n",
    "        prediction_scores_u = similar_users_ratings * similar_users_weights[:, np.newaxis]\n",
    "\n",
    "        prediction_scores.append(np.sum(prediction_scores_u, axis=0))\n",
    "    res = np.array(prediction_scores)\n",
    "    \n",
    "    if item_similarity_en:\n",
    "        res = res.transpose()\n",
    "    \n",
    "    return res\n",
    "\n",
    "def predict_vector(user_index, matrix_train, k, similarity):\n",
    "    \"\"\"\n",
    "    res = similarity * matrix_train    if item_similarity_en = False\n",
    "    res = similarity * matrix_train.T  if item_similarity_en = True\n",
    "    get only user_index row\n",
    "    \"\"\"\n",
    "    vector_u = similarity[user_index]\n",
    "    \n",
    "    # Get closest K neighbors excluding user u self\n",
    "    similar_users = vector_u.argsort()[::-1][1:k+1]\n",
    "    # Get neighbors similarity weights and ratings\n",
    "    similar_users_weights = similarity[user_index][similar_users]\n",
    "    similar_users_ratings = matrix_train[similar_users].toarray()\n",
    "    prediction_scores_u = similar_users_ratings * similar_users_weights[:, np.newaxis]\n",
    "    \n",
    "    return np.sum(prediction_scores_u, axis=0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLREC \n",
    "def inhour(elapsed):\n",
    "    return time.strftime('%H:%M:%S', time.gmtime(elapsed))\n",
    "\n",
    "def plrec(matrix_train, iteration=4, lamb=80, rank=200, seed=1):\n",
    "    \"\"\"\n",
    "    Function used to achieve generalized projected lrec w/o item-attribute embedding\n",
    "    :param matrix_train: user-item matrix with shape m*n\n",
    "    :param iteration: number of power iterations in randomized svd\n",
    "    :param lamb: parameter of penalty\n",
    "    :param rank: latent dimension size\n",
    "    :param seed: the seed of the pseudo random number generator to use when shuffling the data\n",
    "    :return: prediction in sparse matrix\n",
    "    \"\"\"\n",
    "    print (\"Randomized SVD\")\n",
    "    start_time = time.time()\n",
    "    P, sigma, Qt = randomized_svd(matrix_train,\n",
    "                                  n_components=rank,\n",
    "                                  n_iter=iteration,\n",
    "                                  random_state=seed)\n",
    "\n",
    "    RQ = matrix_train.dot(sparse.csc_matrix(Qt.T*np.sqrt(sigma)))\n",
    "\n",
    "    print(\"Elapsed: {}\".format(inhour(time.time() - start_time)))\n",
    "\n",
    "    print (\"Closed-Form Linear Optimization\")\n",
    "    start_time = time.time()\n",
    "    pre_inv = RQ.T.dot(RQ) + lamb * sparse.identity(rank, dtype=np.float32)\n",
    "    inverse = sparse.linalg.inv(pre_inv.tocsc())\n",
    "    Y = inverse.dot(RQ.T).dot(matrix_train)\n",
    "    print(\"Elapsed: {}\".format(inhour(time.time() - start_time)))\n",
    "\n",
    "    return np.array(RQ.todense()), np.array(Y.todense()), None\n",
    "\n",
    "def predict_vector(rating_vector, train_vector, remove_train=True):\n",
    "    dim = len(rating_vector)\n",
    "    candidate_index = np.argpartition(-rating_vector, dim-1)[:dim]\n",
    "    prediction_items = candidate_index[rating_vector[candidate_index].argsort()[::-1]]\n",
    "    \n",
    "    if remove_train:\n",
    "        return np.delete(prediction_items, np.isin(prediction_items, train_vector.nonzero()[1]).nonzero()[0])\n",
    "    else:\n",
    "        return prediction_items\n",
    "\n",
    "    \n",
    "    \n",
    "def predict_scores(matrix_U, matrix_V, bias=None,\n",
    "                   penalize = False,\n",
    "                   keyphrase_freq = I_K, \n",
    "                   critiqued_keyphrase = 0, \n",
    "                   matrix_Train = rtrain,\n",
    "                   alpha = 0):\n",
    "    prediction = matrix_U.dot(matrix_V.T)\n",
    "    # Penalize\n",
    "    if penalize == True:\n",
    "        items_with_keyphrase = np.ravel(keyphrase_freq.T[critiqued_keyphrase].nonzero()[1])\n",
    "        items_without_keyphrase = np.setdiff1d(np.arange(matrix_Train.shape[1]), items_with_keyphrase)\n",
    "        prediction[items_without_keyphrase] = alpha # penalize\n",
    "    \n",
    "    return prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evluation \n",
    "def recallk(vector_true_dense, hits, **unused):\n",
    "    hits = len(hits.nonzero()[0])\n",
    "    return float(hits)/len(vector_true_dense)\n",
    "\n",
    "def precisionk(vector_predict, hits, **unused):\n",
    "    hits = len(hits.nonzero()[0])\n",
    "    return float(hits)/len(vector_predict)\n",
    "\n",
    "\n",
    "def average_precisionk(vector_predict, hits, **unused):\n",
    "    precisions = np.cumsum(hits, dtype=np.float32)/range(1, len(vector_predict)+1)\n",
    "    return np.mean(precisions)\n",
    "\n",
    "\n",
    "def r_precision(vector_true_dense, vector_predict, **unused):\n",
    "    vector_predict_short = vector_predict[:len(vector_true_dense)]\n",
    "    hits = len(np.isin(vector_predict_short, vector_true_dense).nonzero()[0])\n",
    "    return float(hits)/len(vector_true_dense)\n",
    "\n",
    "\n",
    "def _dcg_support(size):\n",
    "    arr = np.arange(1, size+1)+1\n",
    "    return 1./np.log2(arr)\n",
    "\n",
    "\n",
    "def ndcg(vector_true_dense, vector_predict, hits):\n",
    "    idcg = np.sum(_dcg_support(len(vector_true_dense)))\n",
    "    dcg_base = _dcg_support(len(vector_predict))\n",
    "    dcg_base[np.logical_not(hits)] = 0\n",
    "    dcg = np.sum(dcg_base)\n",
    "    return dcg/idcg\n",
    "\n",
    "\n",
    "def click(hits, **unused):\n",
    "    first_hit = next((i for i, x in enumerate(hits) if x), None)\n",
    "    if first_hit is None:\n",
    "        return 5\n",
    "    else:\n",
    "        return first_hit/10\n",
    "\n",
    "\n",
    "def evaluate(matrix_Predict, matrix_Test, metric_names =['R-Precision', 'NDCG', 'Precision', 'Recall', 'MAP'], atK = [5, 10, 15, 20, 50], analytical=False):\n",
    "    \"\"\"\n",
    "    :param matrix_U: Latent representations of users, for LRecs it is RQ, for ALSs it is U\n",
    "    :param matrix_V: Latent representations of items, for LRecs it is Q, for ALSs it is V\n",
    "    :param matrix_Train: Rating matrix for training, features.\n",
    "    :param matrix_Test: Rating matrix for evaluation, true labels.\n",
    "    :param k: Top K retrieval\n",
    "    :param metric_names: Evaluation metrics\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    global_metrics = {\n",
    "        \"R-Precision\": r_precision,\n",
    "        \"NDCG\": ndcg,\n",
    "        \"Clicks\": click\n",
    "    }\n",
    "\n",
    "    local_metrics = {\n",
    "        \"Precision\": precisionk,\n",
    "        \"Recall\": recallk,\n",
    "        \"MAP\": average_precisionk\n",
    "    }\n",
    "\n",
    "    output = dict()\n",
    "\n",
    "    num_users = matrix_Predict.shape[0]\n",
    "\n",
    "    for k in atK:\n",
    "\n",
    "        local_metric_names = list(set(metric_names).intersection(local_metrics.keys()))\n",
    "        results = {name: [] for name in local_metric_names}\n",
    "        topK_Predict = matrix_Predict[:, :k]\n",
    "\n",
    "        for user_index in tqdm(range(topK_Predict.shape[0])):\n",
    "            vector_predict = topK_Predict[user_index]\n",
    "            if len(vector_predict.nonzero()[0]) > 0:\n",
    "                vector_true = matrix_Test[user_index]\n",
    "                vector_true_dense = vector_true.nonzero()[1]\n",
    "                hits = np.isin(vector_predict, vector_true_dense)\n",
    "\n",
    "                if vector_true_dense.size > 0:\n",
    "                    for name in local_metric_names:\n",
    "                        results[name].append(local_metrics[name](vector_true_dense=vector_true_dense,\n",
    "                                                                 vector_predict=vector_predict,\n",
    "                                                                 hits=hits))\n",
    "\n",
    "        results_summary = dict()\n",
    "        if analytical:\n",
    "            for name in local_metric_names:\n",
    "                results_summary['{0}@{1}'.format(name, k)] = results[name]\n",
    "        else:\n",
    "            for name in local_metric_names:\n",
    "                results_summary['{0}@{1}'.format(name, k)] = (np.average(results[name]),\n",
    "                                                              1.96*np.std(results[name])/np.sqrt(num_users))\n",
    "        output.update(results_summary)\n",
    "\n",
    "    global_metric_names = list(set(metric_names).intersection(global_metrics.keys()))\n",
    "    results = {name: [] for name in global_metric_names}\n",
    "\n",
    "    topK_Predict = matrix_Predict[:]\n",
    "\n",
    "    for user_index in tqdm(range(topK_Predict.shape[0])):\n",
    "        vector_predict = topK_Predict[user_index]\n",
    "\n",
    "        if len(vector_predict.nonzero()[0]) > 0:\n",
    "            vector_true = matrix_Test[user_index]\n",
    "            vector_true_dense = vector_true.nonzero()[1]\n",
    "            hits = np.isin(vector_predict, vector_true_dense)\n",
    "\n",
    "            # if user_index == 1:\n",
    "            #     import ipdb;\n",
    "            #     ipdb.set_trace()\n",
    "\n",
    "            if vector_true_dense.size > 0:\n",
    "                for name in global_metric_names:\n",
    "                    results[name].append(global_metrics[name](vector_true_dense=vector_true_dense,\n",
    "                                                              vector_predict=vector_predict,\n",
    "                                                              hits=hits))\n",
    "\n",
    "    results_summary = dict()\n",
    "    if analytical:\n",
    "        for name in global_metric_names:\n",
    "            results_summary[name] = results[name]\n",
    "    else:\n",
    "        for name in global_metric_names:\n",
    "            results_summary[name] = (np.average(results[name]), 1.96*np.std(results[name])/np.sqrt(num_users))\n",
    "    output.update(results_summary)\n",
    "\n",
    "    return output\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single Step Critiquing Pipline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN initial Prediction\n",
    "def get_initial_prediction(user,X = normalize(U_K.todense()), y = normalize(train(rtrain)),\n",
    "                            matrix_Train = rtrain, k = 100):\n",
    "    \"\"\"\n",
    "    Get the initial knn predictions before critiquing pipelines\n",
    "    get the linear regression model for critiquing embedding (W_2)\n",
    "    get the initial user similarity matrix \n",
    "    k here is the parameter for KNN\n",
    "    \"\"\"\n",
    "    clf = Ridge(alpha=0.1).fit(X, y)\n",
    "    similarity = normalize(train(matrix_Train))\n",
    "    user_item_prediction_score = predict_vector(user, matrix_Train, k, similarity)\n",
    "    return user_item_prediction_score, clf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLREC initial Prediction\n",
    "def predict_scores(matrix_U, matrix_V, bias=None,\n",
    "                   penalize = False,\n",
    "                   keyphrase_freq = I_K, \n",
    "                   critiqued_keyphrase = 0, \n",
    "                   matrix_Train = rtrain,\n",
    "                   alpha = 0):\n",
    "    \n",
    "    prediction = matrix_U.dot(matrix_V.T)\n",
    "    # Penalize\n",
    "    if penalize == True:\n",
    "        items_with_keyphrase = np.ravel(keyphrase_freq.T[critiqued_keyphrase].nonzero()[1])\n",
    "        items_without_keyphrase = np.setdiff1d(np.arange(matrix_Train.shape[1]), items_with_keyphrase)\n",
    "        prediction[items_without_keyphrase] = alpha # penalize\n",
    "    \n",
    "    return prediction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict a single row (for single user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN\n",
    "\n",
    "def predict_vector(user_index, matrix_train, k, similarity):\n",
    "    \"\"\"\n",
    "    res = similarity * matrix_train    if item_similarity_en = False\n",
    "    res = similarity * matrix_train.T  if item_similarity_en = True\n",
    "    get only user_index row\n",
    "    \"\"\"\n",
    "    vector_u = similarity[user_index]\n",
    "    \n",
    "    # Get closest K neighbors excluding user u self\n",
    "    similar_users = vector_u.argsort()[::-1][1:k+1]\n",
    "    # Get neighbors similarity weights and ratings\n",
    "    similar_users_weights = similarity[user_index][similar_users]\n",
    "    similar_users_ratings = matrix_train[similar_users].toarray()\n",
    "    prediction_scores_u = similar_users_ratings * similar_users_weights[:, np.newaxis]\n",
    "    \n",
    "    return np.sum(prediction_scores_u, axis=0)\n",
    "    \n",
    "\n",
    "def predict_vector(user_index, matrix_train, k, similarity, with_keyphrase = False, \n",
    "                   keyphrase_freq = None, critiqued_keyphrase = None, alpha = 0):\n",
    "    \"\"\"\n",
    "    get only user_index row\n",
    "    if with_keyphrase = True, then penalize items without critiqued_keyphrase to alpha (default = 0)\n",
    "    \"\"\"\n",
    "    vector_u = similarity[user_index]\n",
    "    \n",
    "    # Get closest K neighbors excluding user u self\n",
    "    similar_users = vector_u.argsort()[::-1][1:k+1]\n",
    "    # Get neighbors similarity weights and ratings\n",
    "    similar_users_weights = similarity[user_index][similar_users]\n",
    "    similar_users_ratings = matrix_train[similar_users].toarray()\n",
    "    \n",
    "    prediction_scores_u = similar_users_ratings * similar_users_weights[:, np.newaxis]\n",
    "    \n",
    "    if with_keyphrase == False:\n",
    "        return np.sum(prediction_scores_u, axis=0)\n",
    "    \n",
    "    # Only Predict items with critiqued_keyphrase \n",
    "    else:\n",
    "        prediction_scores = np.sum(prediction_scores_u, axis=0)\n",
    "#         print (prediction_scores)\n",
    "        #penalize items without critiqued keyphrase\n",
    "        items_with_keyphrase = np.ravel(keyphrase_freq.T[critiqued_keyphrase].nonzero()[1])\n",
    "#         print (items_with_keyphrase)\n",
    "        #Return the unique values in ar1 that are not in ar2.\n",
    "        items_without_keyphrase = np.setdiff1d(np.arange(matrix_train.shape[1]), items_with_keyphrase)\n",
    "        prediction_scores[items_without_keyphrase] = alpha # penalize\n",
    "        return prediction_scores\n",
    "#         print (prediction_scores)\n",
    "#         return prediction_scores/sum(prediction_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLREC\n",
    "def predict_vector(rating_vector, train_vector, remove_train=True):\n",
    "    dim = len(rating_vector)\n",
    "    candidate_index = np.argpartition(-rating_vector, dim-1)[:dim]\n",
    "    prediction_items = candidate_index[rating_vector[candidate_index].argsort()[::-1]]\n",
    "    \n",
    "    if remove_train:\n",
    "        return np.delete(prediction_items, np.isin(prediction_items, train_vector.nonzero()[1]).nonzero()[0])\n",
    "    else:\n",
    "        return prediction_items\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keyphrase Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_valid_keyphrases(keyphrase_freq,top_recommendations,item = None,threshold=50,mutiple_keyphrases_en = False, top_items = None):\n",
    "    \"\"\"\n",
    "    Wrapper function to get either top 1 or top n keyphrases\n",
    "    \"\"\"\n",
    "    if mutiple_keyphrases_en:\n",
    "        top_keyphrases = []\n",
    "        for item in top_items:\n",
    "            top_keyphrases.extend(get_valid_keyphrases_for_one_item(keyphrase_freq,top_recommendations,item,threshold=threshold))\n",
    "        return np.ravel(list(set(top_keyphrases))) # remove duplicate and reformat to np array\n",
    "    else:\n",
    "        return get_valid_keyphrases_for_one_item(keyphrase_freq,top_recommendations,item,threshold=threshold)\n",
    "\n",
    "def get_valid_keyphrases_for_one_item(keyphrase_freq,top_recommendations, item,threshold=50):\n",
    "    \"\"\"\n",
    "    Get keyphrases of item that make sense\n",
    "    E.g. if the item has fewer than threshold=50 keyphrases, get all of them\n",
    "    otherwise get top 50 keyphrases\n",
    "    \"\"\"\n",
    "    keyphrase_length = len(keyphrase_freq[item].nonzero()[1])\n",
    "    if keyphrase_length<threshold:\n",
    "        return keyphrase_freq[item].nonzero()[1]\n",
    "    else:\n",
    "        keyphrases = np.ravel(keyphrase_freq[top_recommendations[0]].todense())\n",
    "        top_keyphrases = np.argsort(keyphrases)[::-1][:threshold]\n",
    "        return top_keyphrases\n",
    "    \n",
    "# For keyphrase selecting method # 3 \"diff\" \n",
    "def get_item_keyphrase_freq(keyphrase_freq,item):\n",
    "    \"\"\"\n",
    "    Get item's keyphrase frequency \n",
    "    \"\"\"\n",
    "    count = keyphrase_freq[item].todense()\n",
    "    return count/np.sum(count)\n",
    "\n",
    "def get_keyphrase_popularity(df,keyphrases):\n",
    "    \"\"\"\n",
    "    Get keyphrase popularity (count) from dataframe\n",
    "    \"\"\"\n",
    "    keyphrase_popularity = np.zeros(len(keyphrases)) #initialize\n",
    "    for i in range(len(df)):\n",
    "        keyphrase_vector = literal_eval(df['keyVector'][i])\n",
    "        keyphrase_popularity[keyphrase_vector] += 1 # count\n",
    "    return keyphrase_popularity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Critiquing Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# averaging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upper bound method \n",
    "def get_all_affected_items(wanted_keyphrases,keyphrase_freq):\n",
    "    res = []\n",
    "    for keyphrase in wanted_keyphrases:\n",
    "        items = np.ravel(keyphrase_freq.T[keyphrase].nonzero()[1])\n",
    "        res.extend(items)\n",
    "    return np.array(list(set(res)))\n",
    "    \n",
    "def select_only_wanted_keyphrase(top_recommendations, wanted_keyphrases, keyphrase_freq, matrix_Train = rtrain):\n",
    "    all_items_with_keyphrases = get_all_affected_items(wanted_keyphrases,keyphrase_freq)\n",
    "    affected_items = np.setdiff1d(np.arange(matrix_Train.shape[1]), all_items_with_keyphrases) # Get all other keyphrases\n",
    "    top_recommendations[~np.in1d(top_recommendations, affected_items)]\n",
    "    return top_recommendations\n",
    "\n",
    "def pruning(prediction_score, \n",
    "           wanted_keyphrases_random, \n",
    "           top_recommendations, \n",
    "           keyphrase_freq, \n",
    "           matrix_Train = rtrain,\n",
    "           alpha = 0):\n",
    "    items_with_keyphrase = get_all_affected_items(wanted_keyphrases_random, keyphrase_freq)\n",
    "    #Return the unique values in ar1 that are not in ar2.\n",
    "    items_without_keyphrase = np.setdiff1d(np.arange(matrix_Train.shape[1]), items_with_keyphrase)\n",
    "#     print (items_without_keyphrase)\n",
    "    print (sum(prediction_score[items_without_keyphrase]))\n",
    "    score = np.copy(prediction_score)\n",
    "    score[items_without_keyphrase] = alpha # penalize\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function for getting restaurant info from ItemIndex\n",
    "def get_business_df(path = \"../../data/yelp/business.json\" ):\n",
    "    with open(path,encoding=\"utf8\") as json_file:\n",
    "        data = json_file.readlines()\n",
    "        data = list(map(json.loads, data))\n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def get_restaurant_info(business_df, business_id, name = True, review_count = True, stars = True ):\n",
    "    output_list = {}\n",
    "    row_idx = int(business_df.index[business_df['business_id'] == business_id].tolist()[0])\n",
    "    if name == True:\n",
    "        output_list['name'] = business_df['name'][row_idx].encode('utf-8').strip()\n",
    "    if review_count == True:\n",
    "        output_list['review_count'] = business_df['review_count'][row_idx]\n",
    "    if stars == True:\n",
    "        output_list['stars'] = business_df['stars'][row_idx] \n",
    "    return output_list\n",
    "\n",
    "# def get_businessid_from_Itemindex(ItemIndex_list, itemindex):\n",
    "#     return ItemIndex_list['business_id'].tolist()[itemindex]\n",
    "\n",
    "def get_restaurant_name(df_train, business_df, ItemIndex):\n",
    "    rows = np.where(df_train['ItemIndex'] == ItemIndex)\n",
    "    if len(rows)!= 0:\n",
    "        business_id = df_train.loc[rows[0][0]]['business_id']\n",
    "        item_info = get_restaurant_info(business_df, business_id)\n",
    "        return item_info['name']\n",
    "    return \"NOT_FOUND\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_step_critiquing_plrec(user = 2, \n",
    "                           keyphrase_length_threshold = 150, \n",
    "                           max_iteration_threshold = 5,\n",
    "                           k = 50,\n",
    "                           df = df,\n",
    "                           row = row,\n",
    "                           business_df = business_df,\n",
    "                           keyphrases = keyphrases,\n",
    "                           keyphrase_popularity = keyphrase_popularity, \n",
    "                           keyphrase_selection_method = 'random',\n",
    "                           recommend_type = 'all',\n",
    "                           lams = [0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1],\n",
    "                           reg = reg, Y = Y, RQt = RQt, Bias = Bias\n",
    "                          ):\n",
    "    \"\"\"\n",
    "    k: HR@k \n",
    "    keyphrase_length_threshold: limit the number of keyphrases in top recommended item\n",
    "    keyphrase_selection_method: 'random': randomly select keyphrase from wanted_keyphrases\n",
    "                                'pop': always select the most popular keyphrase in wanted_keyphrases\n",
    "                                'diff': select the keyphrase with largest frequency difference between top recommended \n",
    "                                        item and target item.\n",
    "    recommend_type: 'all': recommend all items\n",
    "                    'upper' (only_with_critiqued_keyphrase): recommend items with only critiqued_keyphrase\n",
    "    lam: modified_matrix = lam*origianl_matrix + (1-lam)*critiquing_embedding \n",
    "    \"\"\"\n",
    "    \n",
    "    row['user_id'] = user\n",
    "    print ('User ID ', user)\n",
    "    \n",
    "    # Set up (move to header line later)\n",
    "    matrix_Train = rtrain\n",
    "    matrix_Test = rtest\n",
    "    keyphrase_freq = I_K\n",
    "    num_items = rtrain.shape[1]\n",
    "    max_wanted_keyphrase = 10 # for keyphrase_selection_method == \"diff\"\n",
    "    initial_user_similarity_embedding = normalize(train(matrix_Train))\n",
    "    \n",
    "    # Get wanted items \n",
    "    candidate_items = matrix_Test[user].nonzero()[1]\n",
    "    train_items = matrix_Train[user].nonzero()[1]\n",
    "    wanted_items = np.setdiff1d(candidate_items, train_items)\n",
    "    print ('wanted_items length: ',len(wanted_items))\n",
    "    \n",
    "    # Get initial forward prediction \n",
    "#     prediction_score,clf = get_initial_prediction(user, X = normalize(U_K.todense()), y = normalize(train(rtrain)),\n",
    "#                             matrix_Train = rtrain, k = 100)\n",
    "#     Y, RQt, Bias = plrec(matrix_Train,\n",
    "#                     iteration = 10,\n",
    "#                     lamb = 200,\n",
    "#                     rank = 200)\n",
    "#     RQ = RQt.T\n",
    "#     reg = LinearRegression().fit(normalize(U_K), Y)\n",
    "    prediction_score = predict_scores(matrix_U=RQ,\n",
    "                                      matrix_V=Y,\n",
    "                                      bias=Bias).T[user]\n",
    "    # Get initial top recommended item(s)\n",
    "    top_recommendations = np.argsort(prediction_score)[::-1]\n",
    "    print (\"Initial top recommendation index\",top_recommendations[0])\n",
    "    try:\n",
    "        row['top_prediction_item_name'] = get_restaurant_name(df_train, business_df, top_recommendations[0])\n",
    "    # in case we cannot get the restaurant name\n",
    "    except: \n",
    "        row['top_prediction_item_name'] = 'CANNOT_FIND'\n",
    "        print ('Cannot get restaurant name for ItemIndex: ', top_recommendations[0])\n",
    "    \n",
    "    \n",
    "    # Get top recommended item's keyphrases\n",
    "    top_item = top_recommendations[0] \n",
    "    top_recommend_keyphrases = get_valid_keyphrases(keyphrase_freq,\n",
    "                                                    top_recommendations, \n",
    "                                                    item = top_item,\n",
    "                                                    threshold=keyphrase_length_threshold,\n",
    "                                                    mutiple_keyphrases_en = False, \n",
    "                                                    top_items = None)\n",
    "    top_recommended_keyphrase_freq = get_item_keyphrase_freq(keyphrase_freq,item = top_item)\n",
    "    \n",
    "    \n",
    "    #####################################\n",
    "    # For each item, do the critiquing\n",
    "    \n",
    "    #limit the item to only 10\n",
    "    num_target_item = 0 # initialize item count\n",
    "    \n",
    "    for item in wanted_items:    \n",
    "        print ('target_item: ', item)\n",
    "        row['target_item'] = item\n",
    "        try:\n",
    "            row['item_name'] = get_restaurant_name(df_train, business_df, item)\n",
    "        except:\n",
    "            row['item_name'] = 'CANNOT_FIND'\n",
    "            print ('Cannot get restaurant name for ItemIndex: ', item)\n",
    "\n",
    "        # Get pre-critiquing rank\n",
    "        initial_rank = np.where(item == np.argsort(prediction_score)[::-1])[0][0]\n",
    "#         print ('target_item initial rank', int(initial_rank))\n",
    "        row['pre_rank'] = int(initial_rank)\n",
    "\n",
    "        # Get the target item's existing keyphrases\n",
    "        item_keyphrases = keyphrase_freq[item].nonzero()[1]\n",
    "        \n",
    "        # For diff \n",
    "        target_keyphrase_freq = get_item_keyphrase_freq(keyphrase_freq,item = item)\n",
    "        diff_keyphrase_freq = target_keyphrase_freq - top_recommended_keyphrase_freq\n",
    "        \n",
    "        wanted_keyphrases_random = np.setdiff1d(item_keyphrases,top_recommend_keyphrases)\n",
    "        wanted_keyphrases_pop = np.setdiff1d(item_keyphrases,top_recommend_keyphrases)\n",
    "        wanted_keyphrases_diff = np.argsort(np.ravel(diff_keyphrase_freq))[::-1][:max_wanted_keyphrase]\n",
    "        \n",
    "        pruned_prediction_score = pruning(prediction_score, \n",
    "                                           wanted_keyphrases_random, \n",
    "                                           top_recommendations, \n",
    "                                           keyphrase_freq, \n",
    "                                           matrix_Train = rtrain)\n",
    "        pure_pruning_rank = np.where(item == np.argsort(pruned_prediction_score)[::-1])[0][0]\n",
    "        if pure_pruning_rank>initial_rank:\n",
    "            pure_pruning_rank = initial_rank\n",
    "        row['pure_pruning_rank'] = int(pure_pruning_rank)    \n",
    "        \n",
    "        affected_items = np.array([])\n",
    "        modified_matrix = initial_user_similarity_embedding # initialize user similarity embedding\n",
    "        \n",
    "        #############################################\n",
    "        # Critiquing iteration\n",
    "        for iteration in range(max_iteration_threshold):\n",
    "            print ('cur_iter ', iteration)\n",
    "            row['iter'] = iteration\n",
    "\n",
    "            if len(wanted_keyphrases_random) == 0 or len(wanted_keyphrases_diff) == 0: \n",
    "                print ('no more keyphrase available')\n",
    "                break\n",
    "            critiqued_keyphrase_random = np.random.choice(wanted_keyphrases_random, size=1, replace=False)[0]\n",
    "            critiqued_keyphrase_pop = wanted_keyphrases_pop[np.argmin(keyphrase_popularity[wanted_keyphrases_pop])] # Select the least popular\n",
    "            critiqued_keyphrase_diff = wanted_keyphrases_diff[0]\n",
    "            \n",
    "            row['critiqued_keyphrase_random'] = critiqued_keyphrase_random\n",
    "            row['keyphrase_name_random'] = keyphrases[critiqued_keyphrase_random]\n",
    "            row['critiqued_keyphrase_pop'] = critiqued_keyphrase_pop\n",
    "            row['keyphrase_name_pop'] = keyphrases[critiqued_keyphrase_pop]\n",
    "            row['critiqued_keyphrase_diff'] = critiqued_keyphrase_diff\n",
    "            row['keyphrase_name_diff'] = keyphrases[critiqued_keyphrase_diff]\n",
    "            \n",
    "            # Do not critique this keyphrase next time\n",
    "            wanted_keyphrases_random = np.delete(wanted_keyphrases_random, np.where(critiqued_keyphrase_random == wanted_keyphrases_random))\n",
    "            wanted_keyphrases_pop = np.delete(wanted_keyphrases_pop, np.where(critiqued_keyphrase_pop == wanted_keyphrases_pop))\n",
    "            wanted_keyphrases_diff = np.delete(wanted_keyphrases_diff, np.where(critiqued_keyphrase_diff == wanted_keyphrases_diff))\n",
    "            \n",
    "            # Critiquing Embedding\n",
    "\n",
    "            # One hot encoding\n",
    "            critiqued_matrix_onehot = get_critiqued_UK(U_K,user,critiqued_keyphrase_random)\n",
    "            critiqued_matrix = reg.predict(critiqued_matrix_onehot)\n",
    "            critiqued_matrix_random =critiqued_matrix\n",
    "\n",
    "            critiqued_matrix_onehot = get_critiqued_UK(U_K,user,critiqued_keyphrase_pop)\n",
    "            critiqued_matrix = reg.predict(critiqued_matrix_onehot)\n",
    "            critiqued_matrix_pop = critiqued_matrix\n",
    "\n",
    "            critiqued_matrix_onehot = get_critiqued_UK(U_K,user,critiqued_keyphrase_diff)\n",
    "            critiqued_matrix = reg.predict(critiqued_matrix_onehot)\n",
    "            critiqued_matrix_diff = critiqued_matrix\n",
    "\n",
    "\n",
    "            # Warning!!! The following is used only for testing single step critiquing, \n",
    "            # for full average critiquing, use the above commented line \n",
    "            post_ranks_random_all = []\n",
    "            post_ranks_random_upper = []\n",
    "            post_ranks_pop_all = []\n",
    "            post_ranks_pop_upper = []\n",
    "            post_ranks_diff_all = []\n",
    "            post_ranks_diff_upper = []\n",
    "            \n",
    "            affected_items_random = keyphrase_freq[critiqued_keyphrase_random].nonzero()[0]\n",
    "            affected_items_pop = keyphrase_freq[critiqued_keyphrase_pop].nonzero()[0]\n",
    "            affected_items_diff = keyphrase_freq[critiqued_keyphrase_diff].nonzero()[0]\n",
    "            \n",
    "            for lam in lams:\n",
    "                modified_matrix_random = (1-lam)*Y + lam*critiqued_matrix_random \n",
    "                modified_matrix_pop = (1-lam)*Y + lam*critiqued_matrix_pop \n",
    "                modified_matrix_diff = (1-lam)*Y + lam*critiqued_matrix_diff \n",
    "                \n",
    "                # Random\n",
    "                prediction_scores_u = predict_scores(matrix_U=modified_matrix_random[user], \n",
    "                                     matrix_V=RQ,\n",
    "                                     )\n",
    "                prediction_items = predict_vector(rating_vector=prediction_scores_u,\n",
    "                                                  train_vector=matrix_Train[user],\n",
    "                                                  remove_train=False)\n",
    "                \n",
    "                item_rank = np.where(prediction_items == item)[0][0]\n",
    "                post_ranks_random_all.append(item_rank)\n",
    "                # Random upper \n",
    "                prediction_scores_u = predict_scores(matrix_U=modified_matrix_random[user], \n",
    "                                                     matrix_V=RQ, \n",
    "                                                     bias=None,\n",
    "                                                   penalize = True,\n",
    "                                                   keyphrase_freq = keyphrase_freq, \n",
    "                                                   critiqued_keyphrase = critiqued_keyphrase_random, \n",
    "                                                   matrix_Train = matrix_Train,\n",
    "                                                   alpha = 0)\n",
    "                prediction_items = predict_vector(rating_vector=prediction_scores_u,\n",
    "                                                  train_vector=matrix_Train[user],\n",
    "                                                  remove_train=False)\n",
    "                item_rank = np.where(prediction_items == item)[0][0]\n",
    "                post_ranks_random_upper.append(item_rank)\n",
    "                \n",
    "                # Pop\n",
    "                prediction_scores_u = predict_scores(matrix_U=modified_matrix_pop[user], \n",
    "                                     matrix_V=RQ,\n",
    "                                     )\n",
    "                prediction_items = predict_vector(rating_vector=prediction_scores_u,\n",
    "                                                  train_vector=matrix_Train[user],\n",
    "                                                  remove_train=False)\n",
    "                \n",
    "                item_rank = np.where(prediction_items == item)[0][0]\n",
    "                post_ranks_pop_all.append(item_rank)\n",
    "                # Pop upper \n",
    "                \n",
    "                prediction_scores_u = predict_scores(matrix_U=modified_matrix_pop[user], \n",
    "                                                     matrix_V=RQ, \n",
    "                                                     bias=None,\n",
    "                                                   penalize = True,\n",
    "                                                   keyphrase_freq = keyphrase_freq, \n",
    "                                                   critiqued_keyphrase = critiqued_keyphrase_pop, \n",
    "                                                   matrix_Train = matrix_Train,\n",
    "                                                   alpha = 0)\n",
    "                prediction_items = predict_vector(rating_vector=prediction_scores_u,\n",
    "                                                  train_vector=matrix_Train[user],\n",
    "                                                  remove_train=False)\n",
    "                item_rank = np.where(prediction_items == item)[0][0]\n",
    "                post_ranks_pop_upper.append(item_rank)\n",
    "                \n",
    "                # Diff\n",
    "                prediction_scores_u = predict_scores(matrix_U=modified_matrix_diff[user], \n",
    "                                     matrix_V=RQ,\n",
    "                                     )\n",
    "                prediction_items = predict_vector(rating_vector=prediction_scores_u,\n",
    "                                                  train_vector=matrix_Train[user],\n",
    "                                                  remove_train=False)\n",
    "                \n",
    "                item_rank = np.where(prediction_items == item)[0][0]\n",
    "                post_ranks_diff_all.append(item_rank)\n",
    "                # Diff upper \n",
    "                prediction_scores_u = predict_scores(matrix_U=modified_matrix_diff[user], \n",
    "                                                     matrix_V=RQ, \n",
    "                                                     bias=None,\n",
    "                                                   penalize = True,\n",
    "                                                   keyphrase_freq = keyphrase_freq, \n",
    "                                                   critiqued_keyphrase = critiqued_keyphrase_diff, \n",
    "                                                   matrix_Train = matrix_Train,\n",
    "                                                   alpha = 0)\n",
    "                prediction_items = predict_vector(rating_vector=prediction_scores_u,\n",
    "                                                  train_vector=matrix_Train[user],\n",
    "                                                  remove_train=False)\n",
    "                item_rank = np.where(prediction_items == item)[0][0]\n",
    "                post_ranks_diff_upper.append(item_rank)\n",
    "                \n",
    "                \n",
    "            row['post_rank_random_all'] = post_ranks_random_all\n",
    "            row['post_rank_random_upper'] = post_ranks_random_upper\n",
    "            row['post_rank_pop_all'] = post_ranks_pop_all\n",
    "            row['post_rank_pop_upper'] = post_ranks_pop_upper\n",
    "            row['post_rank_diff_all'] = post_ranks_diff_all\n",
    "            row['post_rank_diff_upper'] = post_ranks_diff_upper\n",
    "            df = df.append(row, ignore_index=True)\n",
    "            \n",
    "\n",
    "        # break after got 10 target items \n",
    "        num_target_item += 1\n",
    "        if num_target_item >10: # only want max 10 items per user\n",
    "            break\n",
    "            \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN Forward \n",
    "similarity = normalize(train(rtrain))\n",
    "user_item_prediction_score = predict(rtrain, 100, similarity, item_similarity_en= False)\n",
    "user_item_predict = prediction(user_item_prediction_score, 50, rtrain)\n",
    "user_item_res = evaluate(user_item_predict, rtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation result with k = 100\n",
    "user_item_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLREC Forward\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLREC \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learn User-Keyphrase matrix to Latent Embedding\n",
    "# Training \n",
    "X = normalize(U_K.todense())\n",
    "y = normalize(train(rtrain))\n",
    "clf = Ridge(alpha=0.1).fit(X, y) # Optimality at L2 regularization = 0.1\n",
    "lr_similarity = clf.predict(np.array(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
