{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/litos/opt/anaconda3/envs/tensorflow_cpu/lib/python36.zip',\n",
       " '/Users/litos/opt/anaconda3/envs/tensorflow_cpu/lib/python3.6',\n",
       " '/Users/litos/opt/anaconda3/envs/tensorflow_cpu/lib/python3.6/lib-dynload',\n",
       " '',\n",
       " '/Users/litos/opt/anaconda3/envs/tensorflow_cpu/lib/python3.6/site-packages',\n",
       " '/Users/litos/opt/anaconda3/envs/tensorflow_cpu/lib/python3.6/site-packages/IPython/extensions',\n",
       " '/Users/litos/.ipython']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gurobipy import *\n",
    "\n",
    "from scipy.sparse import csr_matrix, load_npz, save_npz\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import normalize\n",
    "from collections import *\n",
    "import datetime\n",
    "import json\n",
    "import pandas as pd\n",
    "import time\n",
    "# import yaml\n",
    "import scipy.sparse as sparse\n",
    "from ast import literal_eval\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.utils.extmath import randomized_svd\n",
    "\n",
    "from scipy.optimize import minimize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_dataframe_csv(df, path, name):\n",
    "    df.to_csv(path+name, index=False)\n",
    "\n",
    "\n",
    "def load_dataframe_csv(path, name, index_col=None):\n",
    "    return pd.read_csv(path+name, index_col=index_col)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Original Data\n",
    "df_train = pd.read_csv('../../data/yelp/Train.csv',encoding='latin-1')\n",
    "# df_valid = pd.read_csv('../../data/yelp/Valid.csv',encoding='latin-1')\n",
    "# df_test = pd.read_csv('../../data/yelp/Test.csv',encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyphrases = pd.read_csv('../../data/yelp/KeyPhrases.csv')['Phrases'].tolist()\n",
    "keyphrase_popularity = np.loadtxt('../data/yelp/'+'keyphrase_popularity.txt', dtype=int)\n",
    "\n",
    "# Load U-I Data \n",
    "rtrain = load_npz(\"../../data/yelp/Rtrain.npz\")\n",
    "rvalid = load_npz(\"../../data/yelp/Rvalid.npz\")\n",
    "rtest = load_npz(\"../../data/yelp/Rtest.npz\")\n",
    "\n",
    "# Load user/item keyphrase data\n",
    "U_K = load_npz(\"../../data/yelp/U_K.npz\")\n",
    "I_K = load_npz(\"../../data/yelp/I_K.npz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_I_K(df, row_name = 'ItemIndex', shape = (3668,75)):\n",
    "    rows = []\n",
    "    cols = []\n",
    "    vals = []\n",
    "    for i in tqdm(range(df.shape[0])):\n",
    "        key_vector = literal_eval(df['keyVector'][i])\n",
    "        rows.extend([df[row_name][i]]*len(key_vector)) ## Item index\n",
    "        cols.extend(key_vector) ## Keyword Index\n",
    "        vals.extend(np.array([1]*len(key_vector)))\n",
    "    return csr_matrix((vals, (rows, cols)), shape=shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLREC \n",
    "def inhour(elapsed):\n",
    "    return time.strftime('%H:%M:%S', time.gmtime(elapsed))\n",
    "\n",
    "def plrec(matrix_train, iteration=4, lamb=80, rank=200, seed=1):\n",
    "    \"\"\"\n",
    "    Function used to achieve generalized projected lrec w/o item-attribute embedding\n",
    "    :param matrix_train: user-item matrix with shape m*n\n",
    "    :param iteration: number of power iterations in randomized svd\n",
    "    :param lamb: parameter of penalty\n",
    "    :param rank: latent dimension size\n",
    "    :param seed: the seed of the pseudo random number generator to use when shuffling the data\n",
    "    :return: prediction in sparse matrix\n",
    "    \"\"\"\n",
    "    print (\"Randomized SVD\")\n",
    "    start_time = time.time()\n",
    "    P, sigma, Qt = randomized_svd(matrix_train,\n",
    "                                  n_components=rank,\n",
    "                                  n_iter=iteration,\n",
    "                                  random_state=seed)\n",
    "\n",
    "    RQ = matrix_train.dot(sparse.csc_matrix(Qt.T*np.sqrt(sigma)))\n",
    "\n",
    "    print(\"Elapsed: {}\".format(inhour(time.time() - start_time)))\n",
    "\n",
    "    print (\"Closed-Form Linear Optimization\")\n",
    "    start_time = time.time()\n",
    "    pre_inv = RQ.T.dot(RQ) + lamb * sparse.identity(rank, dtype=np.float32)\n",
    "    inverse = sparse.linalg.inv(pre_inv.tocsc())\n",
    "    Y = inverse.dot(RQ.T).dot(matrix_train)\n",
    "    print(\"Elapsed: {}\".format(inhour(time.time() - start_time)))\n",
    "\n",
    "    return np.array(RQ.todense()), np.array(Y.todense()), None\n",
    "\n",
    "# def predict_vector(rating_vector, train_vector, remove_train=True):\n",
    "#     dim = len(rating_vector)\n",
    "#     candidate_index = np.argpartition(-rating_vector, dim-1)[:dim]\n",
    "#     prediction_items = candidate_index[rating_vector[candidate_index].argsort()[::-1]]\n",
    "    \n",
    "#     if remove_train:\n",
    "#         return np.delete(prediction_items, np.isin(prediction_items, train_vector.nonzero()[1]).nonzero()[0])\n",
    "#     else:\n",
    "#         return prediction_items\n",
    "\n",
    "    \n",
    "def predict_scores(matrix_U, matrix_V, bias=None,\n",
    "                   penalize = False,\n",
    "                   keyphrase_freq = I_K, \n",
    "                   critiqued_keyphrase = 0, \n",
    "                   matrix_Train = rtrain,\n",
    "                   alpha = 0):\n",
    "    prediction = matrix_U.dot(matrix_V.T)\n",
    "    # Penalize\n",
    "    if penalize == True:\n",
    "        items_with_keyphrase = np.ravel(keyphrase_freq.T[critiqued_keyphrase].nonzero()[1])\n",
    "        items_without_keyphrase = np.setdiff1d(np.arange(matrix_Train.shape[1]), items_with_keyphrase)\n",
    "        prediction[items_without_keyphrase] = alpha # penalize\n",
    "    \n",
    "    return prediction\n",
    "\n",
    "def predict_vector(rating_vector, train_vector, remove_train=True):\n",
    "    dim = len(rating_vector)\n",
    "    candidate_index = np.argpartition(-rating_vector, dim-1)[:dim]\n",
    "    prediction_items = candidate_index[rating_vector[candidate_index].argsort()[::-1]]\n",
    "    \n",
    "    if remove_train:\n",
    "        return np.delete(prediction_items, np.isin(prediction_items, train_vector.nonzero()[1]).nonzero()[0])\n",
    "    else:\n",
    "        return prediction_items\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial Prediction\n",
    "def predict_scores(matrix_U, matrix_V, bias=None,\n",
    "                   penalize = False,\n",
    "                   keyphrase_freq = I_K, \n",
    "                   critiqued_keyphrase = 0, \n",
    "                   matrix_Train = rtrain,\n",
    "                   alpha = 0):\n",
    "    \n",
    "    prediction = matrix_U.dot(matrix_V.T)\n",
    "    # Penalize\n",
    "    if penalize == True:\n",
    "        items_with_keyphrase = np.ravel(keyphrase_freq.T[critiqued_keyphrase].nonzero()[1])\n",
    "        items_without_keyphrase = np.setdiff1d(np.arange(matrix_Train.shape[1]), items_with_keyphrase)\n",
    "        prediction[items_without_keyphrase] = alpha # penalize\n",
    "    \n",
    "    return prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keyphrase Selection Helpers\n",
    "def get_valid_keyphrases(keyphrase_freq,top_recommendations,item = None,threshold=50,mutiple_keyphrases_en = False, top_items = None):\n",
    "    \"\"\"\n",
    "    Wrapper function to get either top 1 or top n keyphrases\n",
    "    \"\"\"\n",
    "    if mutiple_keyphrases_en:\n",
    "        top_keyphrases = []\n",
    "        for item in top_items:\n",
    "            top_keyphrases.extend(get_valid_keyphrases_for_one_item(keyphrase_freq,top_recommendations,item,threshold=threshold))\n",
    "        return np.ravel(list(set(top_keyphrases))) # remove duplicate and reformat to np array\n",
    "    else:\n",
    "        return get_valid_keyphrases_for_one_item(keyphrase_freq,top_recommendations,item,threshold=threshold)\n",
    "\n",
    "def get_valid_keyphrases_for_one_item(keyphrase_freq,top_recommendations, item,threshold=50):\n",
    "    \"\"\"\n",
    "    Get keyphrases of item that make sense\n",
    "    E.g. if the item has fewer than threshold=50 keyphrases, get all of them\n",
    "    otherwise get top 50 keyphrases\n",
    "    \"\"\"\n",
    "    keyphrase_length = len(keyphrase_freq[item].nonzero()[1])\n",
    "    if keyphrase_length<threshold:\n",
    "        return keyphrase_freq[item].nonzero()[1]\n",
    "    else:\n",
    "        keyphrases = np.ravel(keyphrase_freq[top_recommendations[0]].todense())\n",
    "        top_keyphrases = np.argsort(keyphrases)[::-1][:threshold]\n",
    "        return top_keyphrases\n",
    "    \n",
    "# For keyphrase selecting method # 3 \"diff\" \n",
    "def get_item_keyphrase_freq(keyphrase_freq,item):\n",
    "    \"\"\"\n",
    "    Get item's keyphrase frequency \n",
    "    \"\"\"\n",
    "    count = keyphrase_freq[item].todense()\n",
    "    return count/np.sum(count)\n",
    "\n",
    "def get_keyphrase_popularity(df,keyphrases):\n",
    "    \"\"\"\n",
    "    Get keyphrase popularity (count) from dataframe\n",
    "    \"\"\"\n",
    "    keyphrase_popularity = np.zeros(len(keyphrases)) #initialize\n",
    "    for i in range(len(df)):\n",
    "        keyphrase_vector = literal_eval(df['keyVector'][i])\n",
    "        keyphrase_popularity[keyphrase_vector] += 1 # count\n",
    "    return keyphrase_popularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One hot encoding of critiquing\n",
    "def get_critiqued_UK(user_keyphrase_frequency,user_index,critiqued_keyphrase):\n",
    "    \"\"\"\n",
    "    user_keyphrase_frequency is the U_K matrix (csr sparse matrix)\n",
    "    return the one-hot encoding of the critique\n",
    "    \"\"\"\n",
    "    U_K_cp = user_keyphrase_frequency.copy()\n",
    "    U_K_cp[user_index] = 0\n",
    "    U_K_cp[user_index,critiqued_keyphrase] = 1\n",
    "    return U_K_cp\n",
    "\n",
    "def project_one_hot_encoding(reg, user_keyphrase_frequency,user_index = 0,critiqued_keyphrase = 0, normalize_en = True):\n",
    "    \"\"\"\n",
    "    Return the projection on user_sim space from one-hot encoding of critiqued keyphrase\n",
    "    The res[user_index] should be target embedding row\n",
    "    \"\"\"\n",
    "    critiqued_matrix = get_critiqued_UK(user_keyphrase_frequency, user_index, critiqued_keyphrase)\n",
    "    res = reg.predict(critiqued_matrix)\n",
    "    if normalize_en:\n",
    "        res = normalize((res))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upper bound method \n",
    "def get_all_affected_items(wanted_keyphrases,keyphrase_freq):\n",
    "    res = []\n",
    "    for keyphrase in wanted_keyphrases:\n",
    "        items = np.ravel(keyphrase_freq.T[keyphrase].nonzero()[1])\n",
    "        res.extend(items)\n",
    "    return np.array(list(set(res)))\n",
    "    \n",
    "def select_only_wanted_keyphrase(top_recommendations, wanted_keyphrases, keyphrase_freq, matrix_Train = rtrain):\n",
    "    all_items_with_keyphrases = get_all_affected_items(wanted_keyphrases,keyphrase_freq)\n",
    "    affected_items = np.setdiff1d(np.arange(matrix_Train.shape[1]), all_items_with_keyphrases) # Get all other keyphrases\n",
    "    top_recommendations[~np.in1d(top_recommendations, affected_items)]\n",
    "    return top_recommendations\n",
    "\n",
    "def pruning(prediction_score, \n",
    "           wanted_keyphrases_random, \n",
    "           top_recommendations, \n",
    "           keyphrase_freq, \n",
    "           matrix_Train = rtrain,\n",
    "           alpha = 0):\n",
    "    items_with_keyphrase = get_all_affected_items(wanted_keyphrases_random, keyphrase_freq)\n",
    "    #Return the unique values in ar1 that are not in ar2.\n",
    "    items_without_keyphrase = np.setdiff1d(np.arange(matrix_Train.shape[1]), items_with_keyphrase)\n",
    "#     print (items_without_keyphrase)\n",
    "    print (sum(prediction_score[items_without_keyphrase]))\n",
    "    score = np.copy(prediction_score)\n",
    "    score[items_without_keyphrase] = alpha # penalize\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function for getting restaurant info from ItemIndex\n",
    "def get_business_df(path = \"../../data/yelp/business.json\" ):\n",
    "    with open(path,encoding=\"utf8\") as json_file:\n",
    "        data = json_file.readlines()\n",
    "        data = list(map(json.loads, data))\n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def get_restaurant_info(business_df, business_id, name = True, review_count = True, stars = True ):\n",
    "    output_list = {}\n",
    "    row_idx = int(business_df.index[business_df['business_id'] == business_id].tolist()[0])\n",
    "    if name == True:\n",
    "        output_list['name'] = business_df['name'][row_idx].encode('utf-8').strip()\n",
    "    if review_count == True:\n",
    "        output_list['review_count'] = business_df['review_count'][row_idx]\n",
    "    if stars == True:\n",
    "        output_list['stars'] = business_df['stars'][row_idx] \n",
    "    return output_list\n",
    "\n",
    "# def get_businessid_from_Itemindex(ItemIndex_list, itemindex):\n",
    "#     return ItemIndex_list['business_id'].tolist()[itemindex]\n",
    "\n",
    "def get_restaurant_name(df_train, business_df, ItemIndex):\n",
    "    rows = np.where(df_train['ItemIndex'] == ItemIndex)\n",
    "    if len(rows)!= 0:\n",
    "        business_id = df_train.loc[rows[0][0]]['business_id']\n",
    "        item_info = get_restaurant_info(business_df, business_id)\n",
    "        return item_info['name']\n",
    "    return \"NOT_FOUND\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evluation \n",
    "def recallk(vector_true_dense, hits, **unused):\n",
    "    hits = len(hits.nonzero()[0])\n",
    "    return float(hits)/len(vector_true_dense)\n",
    "\n",
    "def precisionk(vector_predict, hits, **unused):\n",
    "    hits = len(hits.nonzero()[0])\n",
    "    return float(hits)/len(vector_predict)\n",
    "\n",
    "\n",
    "def average_precisionk(vector_predict, hits, **unused):\n",
    "    precisions = np.cumsum(hits, dtype=np.float32)/range(1, len(vector_predict)+1)\n",
    "    return np.mean(precisions)\n",
    "\n",
    "\n",
    "def r_precision(vector_true_dense, vector_predict, **unused):\n",
    "    vector_predict_short = vector_predict[:len(vector_true_dense)]\n",
    "    hits = len(np.isin(vector_predict_short, vector_true_dense).nonzero()[0])\n",
    "    return float(hits)/len(vector_true_dense)\n",
    "\n",
    "\n",
    "def _dcg_support(size):\n",
    "    arr = np.arange(1, size+1)+1\n",
    "    return 1./np.log2(arr)\n",
    "\n",
    "\n",
    "def ndcg(vector_true_dense, vector_predict, hits):\n",
    "    idcg = np.sum(_dcg_support(len(vector_true_dense)))\n",
    "    dcg_base = _dcg_support(len(vector_predict))\n",
    "    dcg_base[np.logical_not(hits)] = 0\n",
    "    dcg = np.sum(dcg_base)\n",
    "    return dcg/idcg\n",
    "\n",
    "\n",
    "def click(hits, **unused):\n",
    "    first_hit = next((i for i, x in enumerate(hits) if x), None)\n",
    "    if first_hit is None:\n",
    "        return 5\n",
    "    else:\n",
    "        return first_hit/10\n",
    "\n",
    "\n",
    "def evaluate(matrix_Predict, matrix_Test, metric_names =['R-Precision', 'NDCG', 'Precision', 'Recall', 'MAP'], atK = [5, 10, 15, 20, 50], analytical=False):\n",
    "    \"\"\"\n",
    "    :param matrix_U: Latent representations of users, for LRecs it is RQ, for ALSs it is U\n",
    "    :param matrix_V: Latent representations of items, for LRecs it is Q, for ALSs it is V\n",
    "    :param matrix_Train: Rating matrix for training, features.\n",
    "    :param matrix_Test: Rating matrix for evaluation, true labels.\n",
    "    :param k: Top K retrieval\n",
    "    :param metric_names: Evaluation metrics\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    global_metrics = {\n",
    "        \"R-Precision\": r_precision,\n",
    "        \"NDCG\": ndcg,\n",
    "        \"Clicks\": click\n",
    "    }\n",
    "\n",
    "    local_metrics = {\n",
    "        \"Precision\": precisionk,\n",
    "        \"Recall\": recallk,\n",
    "        \"MAP\": average_precisionk\n",
    "    }\n",
    "\n",
    "    output = dict()\n",
    "\n",
    "    num_users = matrix_Predict.shape[0]\n",
    "\n",
    "    for k in atK:\n",
    "\n",
    "        local_metric_names = list(set(metric_names).intersection(local_metrics.keys()))\n",
    "        results = {name: [] for name in local_metric_names}\n",
    "        topK_Predict = matrix_Predict[:, :k]\n",
    "\n",
    "        for user_index in tqdm(range(topK_Predict.shape[0])):\n",
    "            vector_predict = topK_Predict[user_index]\n",
    "            if len(vector_predict.nonzero()[0]) > 0:\n",
    "                vector_true = matrix_Test[user_index]\n",
    "                vector_true_dense = vector_true.nonzero()[1]\n",
    "                hits = np.isin(vector_predict, vector_true_dense)\n",
    "\n",
    "                if vector_true_dense.size > 0:\n",
    "                    for name in local_metric_names:\n",
    "                        results[name].append(local_metrics[name](vector_true_dense=vector_true_dense,\n",
    "                                                                 vector_predict=vector_predict,\n",
    "                                                                 hits=hits))\n",
    "\n",
    "        results_summary = dict()\n",
    "        if analytical:\n",
    "            for name in local_metric_names:\n",
    "                results_summary['{0}@{1}'.format(name, k)] = results[name]\n",
    "        else:\n",
    "            for name in local_metric_names:\n",
    "                results_summary['{0}@{1}'.format(name, k)] = (np.average(results[name]),\n",
    "                                                              1.96*np.std(results[name])/np.sqrt(num_users))\n",
    "        output.update(results_summary)\n",
    "\n",
    "    global_metric_names = list(set(metric_names).intersection(global_metrics.keys()))\n",
    "    results = {name: [] for name in global_metric_names}\n",
    "\n",
    "    topK_Predict = matrix_Predict[:]\n",
    "\n",
    "    for user_index in tqdm(range(topK_Predict.shape[0])):\n",
    "        vector_predict = topK_Predict[user_index]\n",
    "\n",
    "        if len(vector_predict.nonzero()[0]) > 0:\n",
    "            vector_true = matrix_Test[user_index]\n",
    "            vector_true_dense = vector_true.nonzero()[1]\n",
    "            hits = np.isin(vector_predict, vector_true_dense)\n",
    "\n",
    "            # if user_index == 1:\n",
    "            #     import ipdb;\n",
    "            #     ipdb.set_trace()\n",
    "\n",
    "            if vector_true_dense.size > 0:\n",
    "                for name in global_metric_names:\n",
    "                    results[name].append(global_metrics[name](vector_true_dense=vector_true_dense,\n",
    "                                                              vector_predict=vector_predict,\n",
    "                                                              hits=hits))\n",
    "\n",
    "    results_summary = dict()\n",
    "    if analytical:\n",
    "        for name in global_metric_names:\n",
    "            results_summary[name] = results[name]\n",
    "    else:\n",
    "        for name in global_metric_names:\n",
    "            results_summary[name] = (np.average(results[name]), 1.96*np.std(results[name])/np.sqrt(num_users))\n",
    "    output.update(results_summary)\n",
    "\n",
    "    return output\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Critiquing Pipline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "business_df = get_business_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyphrase_popularity = np.loadtxt('../data/yelp/'+'keyphrase_popularity.txt', dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Randomized SVD\n",
      "Elapsed: 00:00:00\n",
      "Closed-Form Linear Optimization\n",
      "Elapsed: 00:00:00\n"
     ]
    }
   ],
   "source": [
    "Y, RQt, Bias = plrec(rtrain,\n",
    "                    iteration = 10,\n",
    "                    lamb = 200,\n",
    "                    rank = 200)\n",
    "RQ = RQt.T\n",
    "reg = LinearRegression().fit(normalize(U_K), Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up dataframe \n",
    "\n",
    "# post_ranki is post rank with different lambda ratio for combining pre-post User similarity matrix \n",
    "\n",
    "columns = ['user_id', 'target_item', 'item_name', 'iter', 'pre_rank', \n",
    "           'top_prediction_item_name',\n",
    "           'post_rank_random_all',\n",
    "           'post_rank_random_upper',\n",
    "           'random_scores',\n",
    "           'post_rank_pop_all',\n",
    "           'post_rank_pop_upper',\n",
    "           'pop_scores',\n",
    "           'post_rank_diff_all',\n",
    "           'post_rank_diff_upper',\n",
    "           'diff_scores',\n",
    "           'critiqued_keyphrase_random',\n",
    "           'keyphrase_name_random',\n",
    "           'critiqued_keyphrase_pop',\n",
    "           'keyphrase_name_pop',\n",
    "           'critiqued_keyphrase_diff',\n",
    "           'keyphrase_name_diff',\n",
    "           'num_existing_keyphrases',\n",
    "           'pure_pruning_rank'] \n",
    "df = pd.DataFrame(columns=columns)\n",
    "row = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LP Objectives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Average(initial_prediction_u, keyphrase_freq, affected_items, unaffected_items, num_keyphrases, query, test_user, item_latent, reg, all_equal = True):\n",
    "    critiqued_vector = np.zeros(keyphrase_freq.shape[1])\n",
    "    \n",
    "    for q in query:\n",
    "        critiqued_vector[q] = 1\n",
    "#         critiqued_vector[q] = keyphrase_freq[test_user,q]\n",
    "        \n",
    "    num_critiques = len(query)\n",
    "    \n",
    "    # Get item latent for updating prediction\n",
    "    W2 = reg.coef_\n",
    "    W = item_latent.dot(W2)\n",
    "    \n",
    "    optimal_lambda = 1 # weight all critiquing equally\n",
    "    lambdas = [optimal_lambda]*num_critiques\n",
    "    \n",
    "    # Record lambda values \n",
    "    for k in range(num_critiques):\n",
    "        critiqued_vector[query[k]] *= optimal_lambda\n",
    "\n",
    "    critique_score = predict_scores(matrix_U=reg.predict(critiqued_vector.reshape(1, -1)),\n",
    "                                    matrix_V=item_latent)\n",
    "\n",
    "    if all_equal:\n",
    "        # weight initial and each critiquing equally \n",
    "        new_prediction = initial_prediction_u/(num_critiques) + critique_score.flatten()\n",
    "    else:\n",
    "        # weight intial and combined critiquing equally\n",
    "        new_prediction = initial_prediction_u + critique_score.flatten() \n",
    "#     print (len(new_prediction))\n",
    "    return new_prediction, lambdas   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LP1SimplifiedOptimize(initial_prediction_u, keyphrase_freq, affected_items, unaffected_items, num_keyphrases, query, test_user, item_latent, reg):\n",
    "\n",
    "    critiqued_vector = np.zeros(keyphrase_freq.shape[1])\n",
    "\n",
    "    for q in query:\n",
    "        critiqued_vector[q] = 1 # set critiqued/boosted keyphrase to 1\n",
    "#         critiqued_vector[q] = -keyphrase_freq[test_user][q]\n",
    "\n",
    "    num_critiques = len(query)\n",
    "\n",
    "    W2 = reg.coef_\n",
    "    W = item_latent.dot(W2)\n",
    "\n",
    "    num_affected_items = len(affected_items)\n",
    "    num_unaffected_items = len(unaffected_items)\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Model\n",
    "    m = Model(\"LP1Simplified\") # Create gurobi model with name\n",
    "\n",
    "    # Assignment variables\n",
    "    lambs = []\n",
    "\n",
    "    for k in range(num_critiques):\n",
    "        lambs.append(m.addVar(lb=-1,\n",
    "                              ub=1,\n",
    "                              vtype=GRB.CONTINUOUS,\n",
    "                              name=\"lamb%d\" % query[k]))\n",
    "\n",
    "    m.setObjective(quicksum(initial_prediction_u[affected_item] * num_unaffected_items + quicksum(lambs[k] * critiqued_vector[query[k]] * W[affected_item][query[k]] * num_unaffected_items for k in range(num_critiques)) for affected_item in affected_items) - quicksum(initial_prediction_u[unaffected_item] * num_affected_items + quicksum(lambs[k] * critiqued_vector[query[k]] * W[unaffected_item][query[k]] * num_affected_items for k in range(num_critiques)) for unaffected_item in unaffected_items), GRB.MINIMIZE)\n",
    "\n",
    "    # Optimize\n",
    "    m.optimize()\n",
    "\n",
    "    print(\"Elapsed: {}\".format(inhour(time.time() - start_time)))\n",
    "\n",
    "    lambdas = []\n",
    "    for k in range(num_critiques):\n",
    "        optimal_lambda = m.getVars()[k].X\n",
    "        lambdas.append(optimal_lambda)\n",
    "        critiqued_vector[query[k]] *= optimal_lambda\n",
    "\n",
    "    modified_user_laten = reg.predict(critiqued_vector.reshape(1, -1)) + self.Y\n",
    "    new_prediction = predict_scores(matrix_U=modified_user_laten,\n",
    "                                    matrix_V=item_latent)\n",
    "#     critique_score = predict_scores(matrix_U=reg.predict(critiqued_vector.reshape(1, -1)),\n",
    "#                                     matrix_V=item_latent)\n",
    "#     new_prediction = initial_prediction_u + critique_score.flatten()\n",
    "\n",
    "    return new_prediction, lambdas\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LP1SumToOneOptimize(initial_prediction_u, keyphrase_freq, affected_items, unaffected_items, num_keyphrases, query, test_user, item_latent, reg):\n",
    "\n",
    "    critiqued_vector = np.zeros(keyphrase_freq.shape[1])\n",
    "\n",
    "    for q in query:\n",
    "        critiqued_vector[q] = 1 # set critiqued/boosted keyphrase to 1\n",
    "#         critiqued_vector[q] = -keyphrase_freq[test_user][q]\n",
    "\n",
    "    num_critiques = len(query)\n",
    "\n",
    "    W2 = reg.coef_\n",
    "    W = item_latent.dot(W2)\n",
    "\n",
    "    num_affected_items = len(affected_items)\n",
    "    num_unaffected_items = len(unaffected_items)\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Model\n",
    "    m = Model(\"LP1SumToOneOptimize\")\n",
    "\n",
    "    # Assignment variables\n",
    "    lambs = []\n",
    "    for k in range(1+num_critiques):\n",
    "        lambs.append(m.addVar(lb=0,\n",
    "                              ub=1,\n",
    "                              vtype=GRB.CONTINUOUS,\n",
    "                              name=\"lamb%d\" % k))\n",
    "\n",
    "    m.addConstr((sum(lambs[k] for k in range(1+num_critiques)) == 1), name=\"sum_to_one\")\n",
    "\n",
    "    m.setObjective(quicksum(lambs[0] * initial_prediction_u[affected_item] * num_unaffected_items + quicksum(lambs[k+1] * critiqued_vector[query[k]] * W[affected_item][query[k]] * num_unaffected_items for k in range(num_critiques)) for affected_item in affected_items) - quicksum(lambs[0] * initial_prediction_u[unaffected_item] * num_affected_items + quicksum(lambs[k+1] * critiqued_vector[query[k]] * W[unaffected_item][query[k]] * num_affected_items for k in range(num_critiques)) for unaffected_item in unaffected_items), GRB.MINIMIZE)\n",
    "\n",
    "    # Optimize\n",
    "    m.optimize()\n",
    "\n",
    "    print(\"Elapsed: {}\".format(inhour(time.time() - start_time)))\n",
    "\n",
    "    lambdas = []\n",
    "    for k in range(1+num_critiques):\n",
    "        optimal_lambda = m.getVars()[k].X\n",
    "        lambdas.append(optimal_lambda)\n",
    "\n",
    "    for k in range(num_critiques):\n",
    "        critiqued_vector[query[k]] *= lambdas[k+1]\n",
    "\n",
    "    critique_score = predict_scores(matrix_U=reg.predict(critiqued_vector.reshape(1, -1)),\n",
    "                                    matrix_V=item_latent)\n",
    "    new_prediction = lambdas[0]*initial_prediction_u + critique_score.flatten()\n",
    "\n",
    "    return new_prediction, lambdas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rankSVM(initial_prediction_u, keyphrase_freq, affected_items, unaffected_items, num_keyphrases, query, test_user, item_latent, reg):\n",
    "    critiqued_vector = np.zeros(keyphrase_freq.shape[1])\n",
    "\n",
    "    for q in query:\n",
    "        critiqued_vector[q] = 1 # set critiqued/boosted keyphrase to 1\n",
    "#         critiqued_vector[q] = -keyphrase_freq[test_user][q]\n",
    "\n",
    "    num_critiques = len(query)\n",
    "\n",
    "    W2 = reg.coef_\n",
    "    W = item_latent.dot(W2)\n",
    "\n",
    "    num_affected_items = len(affected_items)\n",
    "    num_unaffected_items = len(unaffected_items)\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Model\n",
    "    m = Model(\"LP2RankSVM\")\n",
    "    \n",
    "    # Assignment variables\n",
    "    lambs = []\n",
    "    for k in range(num_critiques):\n",
    "        lambs.append(m.addVar(lb=-1,\n",
    "                              ub=1,\n",
    "                              vtype=GRB.CONTINUOUS,\n",
    "                              name=\"lamb%d\" % k))\n",
    "\n",
    "#     m.addConstr((sum(lambs[k] for k in range(1+num_critiques)) == 1), name=\"sum_to_one\")\n",
    "    m.addConstr( (sum(lambs[k] for k in range(1+num_critiques)) == 1), name=\"\" )\n",
    "\n",
    "    m.setObjective(quicksum(lambs[0] * initial_prediction_u[affected_item] * num_unaffected_items + quicksum(lambs[k+1] * critiqued_vector[query[k]] * W[affected_item][query[k]] * num_unaffected_items for k in range(num_critiques)) for affected_item in affected_items) - quicksum(lambs[0] * initial_prediction_u[unaffected_item] * num_affected_items + quicksum(lambs[k+1] * critiqued_vector[query[k]] * W[unaffected_item][query[k]] * num_affected_items for k in range(num_critiques)) for unaffected_item in unaffected_items), GRB.MINIMIZE)\n",
    "\n",
    "    # Optimize\n",
    "    m.optimize()\n",
    "\n",
    "    print(\"Elapsed: {}\".format(inhour(time.time() - start_time)))\n",
    "\n",
    "    lambdas = []\n",
    "    for k in range(1+num_critiques):\n",
    "        optimal_lambda = m.getVars()[k].X\n",
    "        lambdas.append(optimal_lambda)\n",
    "\n",
    "    for k in range(num_critiques):\n",
    "        critiqued_vector[query[k]] *= lambdas[k+1]\n",
    "\n",
    "    critique_score = predict_scores(matrix_U=reg.predict(critiqued_vector.reshape(1, -1)),\n",
    "                                    matrix_V=item_latent)\n",
    "    new_prediction = lambdas[0]*initial_prediction_u + critique_score.flatten()\n",
    "\n",
    "    return new_prediction, lambdas\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3998,  8488,  2849, 11795,  7484,  9557,  8458,  9716, 10042,\n",
       "        9189,   160,  1958,  1030,  1159,  1007,  1568,  1866,  1795,\n",
       "        1399,  1197,  1992,  2217,  1823,  2490,  2376,  2288,  3409,\n",
       "        3064,  3021,  2930,  3184,  3390,  2471,  3416,  4653,  5419,\n",
       "        4604,  6193,  4284,  2672,  3698,  4964,  5091,  7967,  4243,\n",
       "       11005,  6876,  6117,  4761,  9379,  8885,  8387,  9135, 17725,\n",
       "        7919, 11369, 16049,  1519,  1998,  4678,  1025,   933,   759,\n",
       "         636,  1142,  1049,   992,   860,  1109,   932,  1376,  1270,\n",
       "        1171,   800,  1060,  1425,  1525,  6077,  1301,  2221,  1503,\n",
       "        1584,  1711,  1349,  1357,  1344,  1490,  9284,  2114,  1050,\n",
       "        4752,  2738,  2451,  1468,  1762,  4843,  1509,  2435,  1887,\n",
       "        1635,  1457,     0,  1445,  2732,  2040,  4156,  1628,  1820,\n",
       "        1914,  2203,  2082,  2281,  2378,  2542,  3178,  1793,  3011,\n",
       "        6766,  2020,  4952,  5922,  2139,  4295,  3140,  3338,  3058,\n",
       "        4556,  2199,  1506,  1445,  1321,  1425,  1392,  1466,   607,\n",
       "        4842,  5755,  1112,   698,   749,  1078,  1759,  2013,  1813,\n",
       "        2006,  1969,  2028,  2417, 19268, 10056,  7390,  9311, 16002,\n",
       "       14803,  1824,  1924,  1334,  1355,  1637,  1464,  1429,  1502,\n",
       "        1576,  1057,  1815,  1876,  1876,  2993,  4774,  1942,  1963,\n",
       "        1918,  2683,  2317,  2453,  2577,  2605,  2456,  2551,  3049,\n",
       "        3162,  2987,  3155,  3824,  3651, 19979,  2169,  7787,  1282,\n",
       "        1264,  1998,  1173,  1339,  1549,  1093,  1530,  1972,  1735,\n",
       "        1678,  1430,  1887,  3510,  1483,  1667,  2589,  1026,  5929,\n",
       "        1786,  2949,  1567,  1749,  1988,  2143, 15468,  2234,  2816,\n",
       "        2424,  2911,  3075,  1940,    81,   114,    65,    94,    66,\n",
       "         300,    46,    61,    91,   100,    85,   273,   484,   138,\n",
       "          56])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keyphrase_popularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0.        , 0.07843137, 0.        , 0.        , 0.01960784,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.07843137,\n",
       "         0.        , 0.01960784, 0.        , 0.        , 0.        ,\n",
       "         0.01960784, 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.01960784, 0.03921569, 0.        ,\n",
       "         0.05882353, 0.        , 0.        , 0.        , 0.01960784,\n",
       "         0.01960784, 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.01960784, 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.03921569, 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.03921569,\n",
       "         0.        , 0.        , 0.03921569, 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.07843137, 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.01960784, 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.01960784, 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.01960784, 0.01960784,\n",
       "         0.01960784, 0.        , 0.01960784, 0.03921569, 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.01960784,\n",
       "         0.        , 0.        , 0.01960784, 0.01960784, 0.        ,\n",
       "         0.        , 0.01960784, 0.        , 0.        , 0.01960784,\n",
       "         0.        , 0.        , 0.01960784, 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.01960784, 0.01960784,\n",
       "         0.01960784, 0.01960784, 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.03921569, 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.01960784, 0.        ]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_item_keyphrase_freq(I_K, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LP1Simplified(object):\n",
    "    def __init__(self, keyphrase_freq, item_keyphrase_freq, row, matrix_Train, matrix_Test, test_users,\n",
    "                 target_ranks, num_items_sampled, num_keyphrases, df,\n",
    "                 max_iteration_threshold, keyphrase_popularity, dataset_name,\n",
    "                 model, parameters_row, keyphrases_names, keyphrase_selection_method, max_wanted_keyphrase, **unused):\n",
    "        self.keyphrase_freq = keyphrase_freq\n",
    "        self.item_keyphrase_freq = item_keyphrase_freq\n",
    "        self.row = row\n",
    "        self.matrix_Train = matrix_Train\n",
    "        self.num_users, self.num_items = matrix_Train.shape\n",
    "        self.matrix_Test = matrix_Test\n",
    "        self.test_users = test_users\n",
    "        self.target_ranks = target_ranks\n",
    "        self.num_items_sampled = num_items_sampled\n",
    "        self.num_keyphrases = num_keyphrases\n",
    "        self.df = df\n",
    "        self.max_iteration_threshold = max_iteration_threshold\n",
    "        self.keyphrase_popularity = keyphrase_popularity\n",
    "        self.dataset_name = dataset_name\n",
    "        self.model = model\n",
    "        self.parameters_row = parameters_row\n",
    "        self.keyphrase_selection_method = keyphrase_selection_method\n",
    "        self.max_wanted_keyphrase = max_wanted_keyphrase\n",
    "        \n",
    "        \n",
    "        self.keyphrases_names = keyphrases_names\n",
    "\n",
    "    def start_critiquing(self):\n",
    "#         self.get_initial_predictions() # No need to do it every time\n",
    "        self.RQ = RQ\n",
    "        Yt = Y.T \n",
    "        self.Y = Y\n",
    "\n",
    "        self.reg = reg\n",
    "\n",
    "        self.prediction_scores = predict_scores(matrix_U=self.RQ,\n",
    "                                                matrix_V=self.Y,\n",
    "                                                bias=Bias).T\n",
    "        \n",
    "        for user in self.test_users:\n",
    "            # User id starts from 0\n",
    "            self.row['user_id'] = user\n",
    "            \n",
    "            initial_prediction_items = predict_vector(rating_vector=self.prediction_scores[user],\n",
    "                                                            train_vector=self.matrix_Train[user],\n",
    "                                                            remove_train=True)\n",
    "            # For keyphrase selection method 'diff' \n",
    "            top_recommended_keyphrase_freq = get_item_keyphrase_freq(self.item_keyphrase_freq,item = initial_prediction_items[0])\n",
    "            \n",
    "            # The iteration will stop if the wanted item is in top n\n",
    "            for target_rank in self.target_ranks:\n",
    "                self.row['target_rank'] = target_rank\n",
    "                \n",
    "                # Pick wanted items in test items\n",
    "                candidate_items = self.matrix_Test[user].nonzero()[1]\n",
    "                train_items = self.matrix_Train[user].nonzero()[1]\n",
    "                wanted_items = np.setdiff1d(candidate_items, train_items)\n",
    "                \n",
    "\n",
    "                \n",
    "                for item in wanted_items:\n",
    "                    # Item id starts from 0\n",
    "                    self.row['item_id'] = item\n",
    "                    try:\n",
    "                        self.row['item_name'] = get_restaurant_name(df_train, business_df,item)\n",
    "                    except:\n",
    "                        self.row['item_name'] = 'NOT_FOUND'\n",
    "                    # Set the wanted item's initial rank as None\n",
    "                    self.row['item_rank'] = None\n",
    "                    # Set the wanted item's initial prediction score as None\n",
    "                    self.row['item_score'] = None\n",
    "                    \n",
    "                    if self.keyphrase_selection_method == \"random\" or self.keyphrase_selection_method == \"pop\":\n",
    "                        # Get the item's existing keyphrases (we can boost)\n",
    "                        remaining_keyphrases = self.item_keyphrase_freq[item].nonzero()[1]\n",
    "                    if self.keyphrase_selection_method == \"diff\":\n",
    "                        # For keyphrase selection method 'diff' \n",
    "                        target_keyphrase_freq = get_item_keyphrase_freq(self.item_keyphrase_freq,item = item)\n",
    "                        diff_keyphrase_freq = target_keyphrase_freq - top_recommended_keyphrase_freq\n",
    "                        remaining_keyphrases = np.argsort(np.ravel(diff_keyphrase_freq))[::-1][:self.max_wanted_keyphrase]\n",
    "                        \n",
    "#                    print(\"The number of remaining_keyphrases is {}. remaining_keyphrases are: {}\".format(len(remaining_keyphrases), remaining_keyphrases))\n",
    "                    self.row['num_existing_keyphrases'] = len(remaining_keyphrases)\n",
    "                    if len(remaining_keyphrases) == 0:\n",
    "                        break\n",
    "                    self.row['iteration'] = 0\n",
    "                    self.row['critiqued_keyphrase'] = None\n",
    "                    self.row['result'] = None\n",
    "                    self.df = self.df.append(self.row, ignore_index=True)\n",
    "\n",
    "                    query = []\n",
    "                    affected_items = np.array([])\n",
    "\n",
    "                    for iteration in range(self.max_iteration_threshold):\n",
    "                        self.row['iteration'] = iteration + 1\n",
    "                        \n",
    "                        if self.keyphrase_selection_method == \"pop\":\n",
    "                            # Always critique the most popular keyphrase\n",
    "                            critiqued_keyphrase = remaining_keyphrases[np.argmax(self.keyphrase_popularity[remaining_keyphrases])]\n",
    "    #                        print(\"remaining keyphrases popularity: {}\".format(self.keyphrase_popularity[remaining_keyphrases]))\n",
    "                        elif self.keyphrase_selection_method == \"random\":\n",
    "                            critiqued_keyphrase = np.random.choice(remaining_keyphrases, size=1, replace=False)[0]\n",
    "            \n",
    "                        elif self.keyphrase_selection_method == \"diff\":\n",
    "                            critiqued_keyphrase = remaining_keyphrases[0]\n",
    "#                             print ('critiqued_keyphrase', critiqued_keyphrase)\n",
    "                        \n",
    "                        self.row['critiqued_keyphrase'] = critiqued_keyphrase\n",
    "                        self.row['critiqued_keyphrase_name'] = keyphrases_names[critiqued_keyphrase]\n",
    "                        query.append(critiqued_keyphrase)\n",
    "\n",
    "                        # Get affected items (items have critiqued keyphrase)\n",
    "                        current_affected_items = self.item_keyphrase_freq[:, critiqued_keyphrase].nonzero()[0]\n",
    "                        affected_items = np.unique(np.concatenate((affected_items, current_affected_items))).astype(int)\n",
    "                        unaffected_items = np.setdiff1d(range(self.num_items), affected_items)\n",
    "\n",
    "                        if iteration == 0:\n",
    "                            prediction_items = initial_prediction_items #calculated once for each user\n",
    "\n",
    "                        affected_items_mask = np.in1d(prediction_items, affected_items)\n",
    "                        affected_items_index_rank = np.where(affected_items_mask == True)\n",
    "                        unaffected_items_index_rank = np.where(affected_items_mask == False)\n",
    "\n",
    "                        import copy\n",
    "#                         prediction_scores_u, lambdas = LP1SimplifiedOptimize(initial_prediction_u=self.prediction_scores[user],\n",
    "#                                                                              keyphrase_freq=copy.deepcopy(self.keyphrase_freq),\n",
    "#                                                                              affected_items=np.intersect1d(affected_items, prediction_items[affected_items_index_rank[0][:100]]),\n",
    "#                                                                              unaffected_items=np.intersect1d(unaffected_items, prediction_items[unaffected_items_index_rank[0][:100]]),\n",
    "#                                                                              num_keyphrases=self.num_keyphrases,\n",
    "#                                                                              query=query,\n",
    "#                                                                              test_user=user,\n",
    "#                                                                              item_latent=self.RQ,\n",
    "#                                                                              reg=self.reg)\n",
    "#                         prediction_scores_u, lambdas = LP1SumToOneOptimize(initial_prediction_u=self.prediction_scores[user],\n",
    "#                                                                            keyphrase_freq=copy.deepcopy(self.keyphrase_freq),\n",
    "#                                                                            affected_items=np.intersect1d(affected_items, prediction_items[affected_items_index_rank[0][:100]]),\n",
    "#                                                                            unaffected_items=np.intersect1d(unaffected_items, prediction_items[unaffected_items_index_rank[0][:100]]),\n",
    "#                                                                            num_keyphrases=self.num_keyphrases,\n",
    "#                                                                            query=query,\n",
    "#                                                                            test_user=user,\n",
    "#                                                                            item_latent=self.RQ,\n",
    "#                                                                            reg=self.reg)\n",
    "                        prediction_scores_u, lambdas = Average(initial_prediction_u=self.prediction_scores[user],\n",
    "                                                                             keyphrase_freq=copy.deepcopy(self.keyphrase_freq),\n",
    "                                                                             affected_items=np.intersect1d(affected_items, prediction_items[affected_items_index_rank[0][:100]]),\n",
    "                                                                             unaffected_items=np.intersect1d(unaffected_items, prediction_items[unaffected_items_index_rank[0][:100]]),\n",
    "                                                                             num_keyphrases=self.num_keyphrases,\n",
    "                                                                             query=query,\n",
    "                                                                             test_user=user,\n",
    "                                                                             item_latent=self.RQ,\n",
    "                                                                             reg=self.reg)\n",
    "\n",
    "                        self.row['lambda'] = lambdas\n",
    "                        prediction_items = predict_vector(rating_vector=prediction_scores_u,\n",
    "                                                          train_vector=self.matrix_Train[user],\n",
    "                                                          remove_train=False)\n",
    "                        recommended_items = prediction_items\n",
    "                        \n",
    "                        # Current item rank\n",
    "                        item_rank = np.where(recommended_items == item)[0][0]\n",
    "\n",
    "                        self.row['item_rank'] = item_rank\n",
    "                        self.row['item_score'] = prediction_scores_u[item]\n",
    "\n",
    "                        if item_rank + 1 <= target_rank:\n",
    "                            # Items is ranked within target rank\n",
    "                            self.row['result'] = 'successful'\n",
    "                            self.df = self.df.append(self.row, ignore_index=True)\n",
    "                            break\n",
    "                        else:\n",
    "                            remaining_keyphrases = np.setdiff1d(remaining_keyphrases, critiqued_keyphrase)\n",
    "                            # Continue if more keyphrases and iterations remained\n",
    "                            if len(remaining_keyphrases) > 0 and self.row['iteration'] < self.max_iteration_threshold:\n",
    "                                self.row['result'] = None\n",
    "                                self.df = self.df.append(self.row, ignore_index=True)\n",
    "                            else:\n",
    "                                # Otherwise, mark fail\n",
    "                                self.row['result'] = 'fail'\n",
    "                                self.df = self.df.append(self.row, ignore_index=True)\n",
    "                                break\n",
    "        return self.df\n",
    "\n",
    "\n",
    "    def get_initial_predictions(self):\n",
    "        self.RQ, Yt, Bias = plrec(self.matrix_Train,\n",
    "                                       iteration=self.parameters_row['iter'],\n",
    "                                       lamb=self.parameters_row['lambda'],\n",
    "                                       rank=self.parameters_row['rank'])\n",
    "        self.Y = Yt.T\n",
    "\n",
    "        self.reg = LinearRegression().fit(self.keyphrase_freq, self.RQ)\n",
    "\n",
    "        self.prediction_scores = predict_scores(matrix_U=self.RQ,\n",
    "                                                matrix_V=self.Y,\n",
    "                                                bias=Bias)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "critiqued_keyphrase 2\n",
      "critiqued_keyphrase 48\n",
      "critiqued_keyphrase 4\n",
      "critiqued_keyphrase 5\n",
      "critiqued_keyphrase 8\n",
      "critiqued_keyphrase 25\n",
      "critiqued_keyphrase 27\n",
      "critiqued_keyphrase 49\n",
      "critiqued_keyphrase 52\n",
      "critiqued_keyphrase 56\n",
      "critiqued_keyphrase 80\n",
      "critiqued_keyphrase 85\n",
      "critiqued_keyphrase 96\n",
      "critiqued_keyphrase 113\n",
      "critiqued_keyphrase 119\n",
      "critiqued_keyphrase 126\n",
      "critiqued_keyphrase 182\n",
      "critiqued_keyphrase 193\n",
      "critiqued_keyphrase 204\n",
      "critiqued_keyphrase 206\n",
      "critiqued_keyphrase 217\n",
      "critiqued_keyphrase 46\n",
      "critiqued_keyphrase 5\n",
      "critiqued_keyphrase 16\n",
      "critiqued_keyphrase 25\n",
      "critiqued_keyphrase 36\n",
      "critiqued_keyphrase 49\n",
      "critiqued_keyphrase 50\n",
      "critiqued_keyphrase 52\n",
      "critiqued_keyphrase 56\n",
      "critiqued_keyphrase 80\n",
      "critiqued_keyphrase 122\n",
      "critiqued_keyphrase 148\n",
      "critiqued_keyphrase 152\n",
      "critiqued_keyphrase 153\n",
      "critiqued_keyphrase 174\n",
      "critiqued_keyphrase 182\n",
      "critiqued_keyphrase 203\n",
      "critiqued_keyphrase 208\n",
      "critiqued_keyphrase 212\n",
      "critiqued_keyphrase 215\n",
      "critiqued_keyphrase 41\n",
      "critiqued_keyphrase 3\n",
      "critiqued_keyphrase 4\n",
      "critiqued_keyphrase 37\n",
      "critiqued_keyphrase 48\n",
      "critiqued_keyphrase 56\n",
      "critiqued_keyphrase 90\n",
      "critiqued_keyphrase 96\n",
      "critiqued_keyphrase 113\n",
      "critiqued_keyphrase 114\n",
      "critiqued_keyphrase 117\n",
      "critiqued_keyphrase 120\n",
      "critiqued_keyphrase 147\n",
      "critiqued_keyphrase 148\n",
      "critiqued_keyphrase 181\n",
      "critiqued_keyphrase 187\n",
      "critiqued_keyphrase 194\n",
      "critiqued_keyphrase 204\n",
      "critiqued_keyphrase 206\n",
      "critiqued_keyphrase 209\n",
      "critiqued_keyphrase 29\n",
      "critiqued_keyphrase 1\n",
      "critiqued_keyphrase 4\n",
      "critiqued_keyphrase 5\n",
      "critiqued_keyphrase 43\n",
      "critiqued_keyphrase 45\n",
      "critiqued_keyphrase 47\n",
      "critiqued_keyphrase 77\n",
      "critiqued_keyphrase 97\n",
      "critiqued_keyphrase 107\n",
      "critiqued_keyphrase 113\n",
      "critiqued_keyphrase 114\n",
      "critiqued_keyphrase 117\n",
      "critiqued_keyphrase 148\n",
      "critiqued_keyphrase 149\n",
      "critiqued_keyphrase 171\n",
      "critiqued_keyphrase 195\n",
      "critiqued_keyphrase 203\n",
      "critiqued_keyphrase 208\n",
      "critiqued_keyphrase 209\n",
      "critiqued_keyphrase 56\n",
      "critiqued_keyphrase 1\n",
      "critiqued_keyphrase 3\n",
      "critiqued_keyphrase 4\n",
      "critiqued_keyphrase 5\n",
      "critiqued_keyphrase 21\n",
      "critiqued_keyphrase 29\n",
      "critiqued_keyphrase 42\n",
      "critiqued_keyphrase 48\n",
      "critiqued_keyphrase 49\n",
      "critiqued_keyphrase 96\n",
      "critiqued_keyphrase 113\n",
      "critiqued_keyphrase 118\n",
      "critiqued_keyphrase 126\n",
      "critiqued_keyphrase 127\n",
      "critiqued_keyphrase 180\n",
      "critiqued_keyphrase 182\n",
      "critiqued_keyphrase 193\n",
      "critiqued_keyphrase 194\n",
      "critiqued_keyphrase 203\n",
      "critiqued_keyphrase 48\n",
      "critiqued_keyphrase 1\n",
      "critiqued_keyphrase 4\n",
      "critiqued_keyphrase 76\n",
      "critiqued_keyphrase 85\n",
      "critiqued_keyphrase 96\n",
      "critiqued_keyphrase 114\n",
      "critiqued_keyphrase 119\n",
      "critiqued_keyphrase 148\n",
      "critiqued_keyphrase 149\n",
      "critiqued_keyphrase 150\n",
      "critiqued_keyphrase 152\n",
      "critiqued_keyphrase 176\n",
      "critiqued_keyphrase 180\n",
      "critiqued_keyphrase 182\n",
      "critiqued_keyphrase 193\n",
      "critiqued_keyphrase 194\n",
      "critiqued_keyphrase 206\n",
      "critiqued_keyphrase 209\n",
      "critiqued_keyphrase 217\n",
      "critiqued_keyphrase 58\n",
      "critiqued_keyphrase 3\n",
      "critiqued_keyphrase 16\n",
      "critiqued_keyphrase 41\n",
      "critiqued_keyphrase 77\n",
      "critiqued_keyphrase 85\n",
      "critiqued_keyphrase 95\n",
      "critiqued_keyphrase 98\n",
      "critiqued_keyphrase 113\n",
      "critiqued_keyphrase 116\n",
      "critiqued_keyphrase 148\n",
      "critiqued_keyphrase 149\n",
      "critiqued_keyphrase 150\n",
      "critiqued_keyphrase 151\n",
      "critiqued_keyphrase 165\n",
      "critiqued_keyphrase 174\n",
      "critiqued_keyphrase 181\n",
      "critiqued_keyphrase 208\n",
      "critiqued_keyphrase 213\n",
      "critiqued_keyphrase 225\n",
      "critiqued_keyphrase 136\n",
      "critiqued_keyphrase 21\n",
      "critiqued_keyphrase 26\n",
      "critiqued_keyphrase 95\n",
      "critiqued_keyphrase 137\n",
      "critiqued_keyphrase 140\n",
      "critiqued_keyphrase 141\n",
      "critiqued_keyphrase 143\n",
      "critiqued_keyphrase 144\n",
      "critiqued_keyphrase 151\n",
      "critiqued_keyphrase 153\n",
      "critiqued_keyphrase 158\n",
      "critiqued_keyphrase 161\n",
      "critiqued_keyphrase 164\n",
      "critiqued_keyphrase 169\n",
      "critiqued_keyphrase 175\n",
      "critiqued_keyphrase 185\n",
      "critiqued_keyphrase 190\n",
      "critiqued_keyphrase 196\n",
      "critiqued_keyphrase 214\n",
      "critiqued_keyphrase 3\n",
      "critiqued_keyphrase 1\n",
      "critiqued_keyphrase 4\n",
      "critiqued_keyphrase 5\n",
      "critiqued_keyphrase 26\n",
      "critiqued_keyphrase 41\n",
      "critiqued_keyphrase 48\n",
      "critiqued_keyphrase 56\n",
      "critiqued_keyphrase 76\n",
      "critiqued_keyphrase 91\n",
      "critiqued_keyphrase 117\n",
      "critiqued_keyphrase 119\n",
      "critiqued_keyphrase 120\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-2d686a5dfe84>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     37\u001b[0m                                 \u001b[0mkeyphrase_selection_method\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeyphrase_selection_method\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m                                 max_wanted_keyphrase = max_wanted_keyphrase)\n\u001b[0;32m---> 39\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcritiquing_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_critiquing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-34-029b9fb85366>\u001b[0m in \u001b[0;36mstart_critiquing\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    153\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lambda'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlambdas\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m                         prediction_items = predict_vector(rating_vector=prediction_scores_u,\n\u001b[0;32m--> 155\u001b[0;31m                                                           \u001b[0mtrain_vector\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatrix_Train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0muser\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m                                                           remove_train=False)\n\u001b[1;32m    157\u001b[0m                         \u001b[0mrecommended_items\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprediction_items\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tensorflow_cpu/lib/python3.6/site-packages/scipy/sparse/_index.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mThis\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mprovides\u001b[0m \u001b[0mcommon\u001b[0m \u001b[0mdispatching\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mvalidation\u001b[0m \u001b[0mlogic\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mindexing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \"\"\"\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m         \u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;31m# Dispatch to specialized methods.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "row = {}\n",
    "matrix_Train = rtrain\n",
    "matrix_Test = rtest\n",
    "test_users = [1] #np.arange(50)\n",
    "target_ranks = [20,50]\n",
    "num_items_sampled = 5\n",
    "num_keyphrases = 10\n",
    "df = pd.DataFrame(row)\n",
    "max_iteration_threshold = 20\n",
    "keyphrase_popularity = keyphrase_popularity\n",
    "dataset_name = \"yelp\"\n",
    "model = \"plrec\"\n",
    "parameters_row = {'iter': 10,\n",
    "                  'lambda':200,\n",
    "                  'rank':200}\n",
    "keyphrases_names = keyphrases\n",
    "keyphrase_selection_method = 'diff'\n",
    "max_wanted_keyphrase = 20\n",
    "\n",
    "\n",
    "critiquing_model = LP1Simplified(keyphrase_freq=U_K,\n",
    "                                item_keyphrase_freq=I_K,\n",
    "                                row=row,\n",
    "                                matrix_Train=matrix_Train,\n",
    "                                matrix_Test=matrix_Test,\n",
    "                                test_users=test_users,\n",
    "                                target_ranks=target_ranks,\n",
    "                                num_items_sampled=num_items_sampled,\n",
    "                                num_keyphrases=num_keyphrases,\n",
    "                                df=df,\n",
    "                                max_iteration_threshold=max_iteration_threshold,\n",
    "                                keyphrase_popularity=keyphrase_popularity,\n",
    "                                dataset_name=dataset_name,\n",
    "                                model=model,\n",
    "                                parameters_row=parameters_row,\n",
    "                                keyphrases_names = keyphrases_names,\n",
    "                                keyphrase_selection_method = keyphrase_selection_method,\n",
    "                                max_wanted_keyphrase = max_wanted_keyphrase)\n",
    "df = critiquing_model.start_critiquing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_path = '../tables/critiquing/multi_step_critiquing/yelp/avg/'\n",
    "name = 'test_result_for_plotting_1user.csv'\n",
    "save_dataframe_csv(df, table_path, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>critiqued_keyphrase</th>\n",
       "      <th>item_id</th>\n",
       "      <th>item_name</th>\n",
       "      <th>item_rank</th>\n",
       "      <th>item_score</th>\n",
       "      <th>iteration</th>\n",
       "      <th>num_existing_keyphrases</th>\n",
       "      <th>result</th>\n",
       "      <th>target_rank</th>\n",
       "      <th>user_id</th>\n",
       "      <th>critiqued_keyphrase_name</th>\n",
       "      <th>lambda</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>75.0</td>\n",
       "      <td>b'Salad King Restaurant'</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>None</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>75.0</td>\n",
       "      <td>b'Salad King Restaurant'</td>\n",
       "      <td>3</td>\n",
       "      <td>4.43009</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>successful</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>thai</td>\n",
       "      <td>[1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>None</td>\n",
       "      <td>78.0</td>\n",
       "      <td>b'The Works Gourmet Burger Bistro'</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>None</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>thai</td>\n",
       "      <td>[1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>48</td>\n",
       "      <td>78.0</td>\n",
       "      <td>b'The Works Gourmet Burger Bistro'</td>\n",
       "      <td>7343</td>\n",
       "      <td>-0.502279</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>None</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>burger</td>\n",
       "      <td>[1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>78.0</td>\n",
       "      <td>b'The Works Gourmet Burger Bistro'</td>\n",
       "      <td>5525</td>\n",
       "      <td>-0.0278124</td>\n",
       "      <td>2.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>None</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>fry</td>\n",
       "      <td>[1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1589</th>\n",
       "      <td>121</td>\n",
       "      <td>7354.0</td>\n",
       "      <td>b'Spectacle'</td>\n",
       "      <td>2008</td>\n",
       "      <td>0.150263</td>\n",
       "      <td>16.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>None</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>dumpling</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1590</th>\n",
       "      <td>136</td>\n",
       "      <td>7354.0</td>\n",
       "      <td>b'Spectacle'</td>\n",
       "      <td>2001</td>\n",
       "      <td>0.168824</td>\n",
       "      <td>17.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>None</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>store</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1591</th>\n",
       "      <td>150</td>\n",
       "      <td>7354.0</td>\n",
       "      <td>b'Spectacle'</td>\n",
       "      <td>2135</td>\n",
       "      <td>0.146572</td>\n",
       "      <td>18.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>None</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>clean</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1592</th>\n",
       "      <td>157</td>\n",
       "      <td>7354.0</td>\n",
       "      <td>b'Spectacle'</td>\n",
       "      <td>2304</td>\n",
       "      <td>0.123868</td>\n",
       "      <td>19.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>None</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>greeted</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1593</th>\n",
       "      <td>233</td>\n",
       "      <td>7354.0</td>\n",
       "      <td>b'Spectacle'</td>\n",
       "      <td>3197</td>\n",
       "      <td>0.0371462</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>fail</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>english muffin</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1594 rows  12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     critiqued_keyphrase  item_id                           item_name  \\\n",
       "0                   None     75.0            b'Salad King Restaurant'   \n",
       "1                      2     75.0            b'Salad King Restaurant'   \n",
       "2                   None     78.0  b'The Works Gourmet Burger Bistro'   \n",
       "3                     48     78.0  b'The Works Gourmet Burger Bistro'   \n",
       "4                      4     78.0  b'The Works Gourmet Burger Bistro'   \n",
       "...                  ...      ...                                 ...   \n",
       "1589                 121   7354.0                        b'Spectacle'   \n",
       "1590                 136   7354.0                        b'Spectacle'   \n",
       "1591                 150   7354.0                        b'Spectacle'   \n",
       "1592                 157   7354.0                        b'Spectacle'   \n",
       "1593                 233   7354.0                        b'Spectacle'   \n",
       "\n",
       "     item_rank item_score  iteration  num_existing_keyphrases      result  \\\n",
       "0         None       None        0.0                     20.0        None   \n",
       "1            3    4.43009        1.0                     20.0  successful   \n",
       "2         None       None        0.0                     20.0        None   \n",
       "3         7343  -0.502279        1.0                     20.0        None   \n",
       "4         5525 -0.0278124        2.0                     20.0        None   \n",
       "...        ...        ...        ...                      ...         ...   \n",
       "1589      2008   0.150263       16.0                     20.0        None   \n",
       "1590      2001   0.168824       17.0                     20.0        None   \n",
       "1591      2135   0.146572       18.0                     20.0        None   \n",
       "1592      2304   0.123868       19.0                     20.0        None   \n",
       "1593      3197  0.0371462       20.0                     20.0        fail   \n",
       "\n",
       "      target_rank  user_id critiqued_keyphrase_name  \\\n",
       "0            20.0      1.0                      NaN   \n",
       "1            20.0      1.0                     thai   \n",
       "2            20.0      1.0                     thai   \n",
       "3            20.0      1.0                   burger   \n",
       "4            20.0      1.0                      fry   \n",
       "...           ...      ...                      ...   \n",
       "1589         50.0      1.0                 dumpling   \n",
       "1590         50.0      1.0                    store   \n",
       "1591         50.0      1.0                    clean   \n",
       "1592         50.0      1.0                  greeted   \n",
       "1593         50.0      1.0           english muffin   \n",
       "\n",
       "                                                 lambda  \n",
       "0                                                   NaN  \n",
       "1                                                   [1]  \n",
       "2                                                   [1]  \n",
       "3                                                   [1]  \n",
       "4                                                [1, 1]  \n",
       "...                                                 ...  \n",
       "1589   [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]  \n",
       "1590  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "1591  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "1592  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "1593  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "\n",
       "[1594 rows x 12 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_step_critiquing_plrec(user = 2, \n",
    "                           keyphrase_length_threshold = 150, \n",
    "                           max_iteration_threshold = 5,\n",
    "                           k = 50,\n",
    "                           df = df,\n",
    "                           row = row,\n",
    "                           business_df = business_df,\n",
    "                           keyphrases = keyphrases,\n",
    "                           keyphrase_popularity = keyphrase_popularity, \n",
    "                           keyphrase_selection_method = 'random',\n",
    "                           recommend_type = 'all',\n",
    "                           lams = [0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1],\n",
    "                           reg = reg, Y = Y, RQt = RQt, Bias = Bias,\n",
    "                           top_k_rec = 20, affected_weight = 1, unaffected_weight = -1,\n",
    "                                 w1 = 1, w2 = 1,\n",
    "                            matrix_Train = rtrain,\n",
    "                            matrix_Test = rtest,\n",
    "                            keyphrase_freq = I_K,\n",
    "                            num_items = rtrain.shape[1],\n",
    "                            max_wanted_keyphrase = 10,\n",
    "                          ):\n",
    "    \"\"\"\n",
    "    k: HR@k \n",
    "    keyphrase_length_threshold: limit the number of keyphrases in top recommended item\n",
    "    keyphrase_selection_method: 'random': randomly select keyphrase from wanted_keyphrases\n",
    "                                'pop': always select the most popular keyphrase in wanted_keyphrases\n",
    "                                'diff': select the keyphrase with largest frequency difference between top recommended \n",
    "                                        item and target item.\n",
    "    recommend_type: 'all': recommend all items\n",
    "                    'upper' (only_with_critiqued_keyphrase): recommend items with only critiqued_keyphrase\n",
    "    lam: modified_matrix = lam*origianl_matrix + (1-lam)*critiquing_embedding \n",
    "    \"\"\"\n",
    "    \n",
    "    row['user_id'] = user\n",
    "    print ('User ID ', user)\n",
    "    \n",
    "    # Get wanted items \n",
    "    candidate_items = matrix_Test[user].nonzero()[1]\n",
    "    train_items = matrix_Train[user].nonzero()[1]\n",
    "    wanted_items = np.setdiff1d(candidate_items, train_items)\n",
    "    print ('wanted_items length: ',len(wanted_items))\n",
    "    \n",
    "    # Get initial forward prediction \n",
    "    prediction_score = predict_scores(matrix_U=RQ,\n",
    "                                      matrix_V=Y,\n",
    "                                      bias=Bias).T[user]\n",
    "    prediction_items = predict_vector(rating_vector=prediction_score,\n",
    "                                                              train_vector=matrix_Train[user],\n",
    "                                                              remove_train=True)\n",
    "    # Get initial top recommended item(s)\n",
    "    top_recommendations = np.argsort(prediction_score)[::-1]\n",
    "    print (\"Initial top recommendation index\",top_recommendations[0])\n",
    "    try:\n",
    "        row['top_prediction_item_name'] = get_restaurant_name(df_train, business_df, top_recommendations[0])\n",
    "    except: \n",
    "        row['top_prediction_item_name'] = 'CANNOT_FIND'\n",
    "        print ('Cannot get restaurant name for ItemIndex: ', top_recommendations[0])\n",
    "    \n",
    "    \n",
    "    # Get top recommended item's keyphrases\n",
    "    top_item = top_recommendations[0] \n",
    "    top_recommend_keyphrases = get_valid_keyphrases(keyphrase_freq,\n",
    "                                                    top_recommendations, \n",
    "                                                    item = top_item,\n",
    "                                                    threshold=keyphrase_length_threshold,\n",
    "                                                    mutiple_keyphrases_en = False, \n",
    "                                                    top_items = None)\n",
    "    top_recommended_keyphrase_freq = get_item_keyphrase_freq(keyphrase_freq,item = top_item)\n",
    "    \n",
    "    \n",
    "    #####################################\n",
    "    # For each item, do the critiquing\n",
    "    \n",
    "    #limit the item to only 10\n",
    "    num_target_item = 0 # initialize item count\n",
    "    \n",
    "    for item in wanted_items:    \n",
    "        print ('target_item: ', item)\n",
    "        row['target_item'] = item\n",
    "        try:\n",
    "            row['item_name'] = get_restaurant_name(df_train, business_df, item)\n",
    "        except:\n",
    "            row['item_name'] = 'CANNOT_FIND'\n",
    "            print ('Cannot get restaurant name for ItemIndex: ', item)\n",
    "\n",
    "        # Get pre-critiquing rank\n",
    "        initial_rank = np.where(item == np.argsort(prediction_score)[::-1])[0][0]\n",
    "        row['pre_rank'] = int(initial_rank)\n",
    "\n",
    "        # Get the target item's existing keyphrases\n",
    "        item_keyphrases = keyphrase_freq[item].nonzero()[1]\n",
    "        \n",
    "        # For diff \n",
    "        target_keyphrase_freq = get_item_keyphrase_freq(keyphrase_freq,item = item)\n",
    "        diff_keyphrase_freq = target_keyphrase_freq - top_recommended_keyphrase_freq\n",
    "        \n",
    "        wanted_keyphrases_random = np.setdiff1d(item_keyphrases,top_recommend_keyphrases)\n",
    "        wanted_keyphrases_pop = np.setdiff1d(item_keyphrases,top_recommend_keyphrases)\n",
    "        wanted_keyphrases_diff = np.argsort(np.ravel(diff_keyphrase_freq))[::-1][:max_wanted_keyphrase]\n",
    "        \n",
    "        pruned_prediction_score = pruning(prediction_score, \n",
    "                                           wanted_keyphrases_random, \n",
    "                                           top_recommendations, \n",
    "                                           keyphrase_freq, \n",
    "                                           matrix_Train = rtrain)\n",
    "        pure_pruning_rank = np.where(item == np.argsort(pruned_prediction_score)[::-1])[0][0]\n",
    "        if pure_pruning_rank>initial_rank:\n",
    "            pure_pruning_rank = initial_rank\n",
    "        row['pure_pruning_rank'] = int(pure_pruning_rank)    \n",
    "        \n",
    "        affected_items = np.array([])\n",
    "        modified_matrix = initial_user_similarity_embedding # initialize user similarity embedding\n",
    "        \n",
    "        #############################################\n",
    "        # Critiquing iteration\n",
    "        for iteration in range(max_iteration_threshold):\n",
    "            print ('cur_iter ', iteration)\n",
    "            row['iter'] = iteration\n",
    "\n",
    "            if len(wanted_keyphrases_random) == 0 or len(wanted_keyphrases_diff) == 0: \n",
    "                print ('no more keyphrase available')\n",
    "                break\n",
    "            critiqued_keyphrase_random = np.random.choice(wanted_keyphrases_random, size=1, replace=False)[0]\n",
    "            critiqued_keyphrase_pop = wanted_keyphrases_pop[np.argmin(keyphrase_popularity[wanted_keyphrases_pop])] # Select the least popular\n",
    "            critiqued_keyphrase_diff = wanted_keyphrases_diff[0]\n",
    "            \n",
    "            row['critiqued_keyphrase_random'] = critiqued_keyphrase_random\n",
    "            row['keyphrase_name_random'] = keyphrases[critiqued_keyphrase_random]\n",
    "            row['critiqued_keyphrase_pop'] = critiqued_keyphrase_pop\n",
    "            row['keyphrase_name_pop'] = keyphrases[critiqued_keyphrase_pop]\n",
    "            row['critiqued_keyphrase_diff'] = critiqued_keyphrase_diff\n",
    "            row['keyphrase_name_diff'] = keyphrases[critiqued_keyphrase_diff]\n",
    "            \n",
    "            # Do not critique this keyphrase next time\n",
    "            wanted_keyphrases_random = np.delete(wanted_keyphrases_random, np.where(critiqued_keyphrase_random == wanted_keyphrases_random))\n",
    "            wanted_keyphrases_pop = np.delete(wanted_keyphrases_pop, np.where(critiqued_keyphrase_pop == wanted_keyphrases_pop))\n",
    "            wanted_keyphrases_diff = np.delete(wanted_keyphrases_diff, np.where(critiqued_keyphrase_diff == wanted_keyphrases_diff))\n",
    "            \n",
    "            # Critiquing Embedding\n",
    "\n",
    "            # One hot encoding\n",
    "            critiqued_matrix_onehot = get_critiqued_UK(U_K,user,critiqued_keyphrase_random)\n",
    "            critiqued_matrix = reg.predict(critiqued_matrix_onehot)\n",
    "            critiqued_matrix_random =critiqued_matrix\n",
    "\n",
    "            critiqued_matrix_onehot = get_critiqued_UK(U_K,user,critiqued_keyphrase_pop)\n",
    "            critiqued_matrix = reg.predict(critiqued_matrix_onehot)\n",
    "            critiqued_matrix_pop = critiqued_matrix\n",
    "\n",
    "            critiqued_matrix_onehot = get_critiqued_UK(U_K,user,critiqued_keyphrase_diff)\n",
    "            critiqued_matrix = reg.predict(critiqued_matrix_onehot)\n",
    "            critiqued_matrix_diff = critiqued_matrix\n",
    "\n",
    "\n",
    "            # Warning!!! The following is used only for testing single step critiquing, \n",
    "            # for full average critiquing, use the above commented line \n",
    "            post_ranks_random_all = []\n",
    "            post_ranks_random_upper = []\n",
    "            random_scores = []\n",
    "            random_ratings = []\n",
    "            post_ranks_pop_all = []\n",
    "            post_ranks_pop_upper = []\n",
    "            pop_scores = []\n",
    "            pop_ratings = []\n",
    "            post_ranks_diff_all = []\n",
    "            post_ranks_diff_upper = []\n",
    "            diff_scores = []\n",
    "            diff_ratings = []\n",
    "            \n",
    "            num_items = matrix_Train.shape[1]\n",
    "            affected_items_random = keyphrase_freq[:,critiqued_keyphrase_random].nonzero()[0]\n",
    "            affected_items_pop = keyphrase_freq[:,critiqued_keyphrase_pop].nonzero()[0]\n",
    "            affected_items_diff = keyphrase_freq[:,critiqued_keyphrase_diff].nonzero()[0]\n",
    "            \n",
    "            unaffected_items_random = np.setdiff1d(range(num_items), affected_items_random)\n",
    "            unaffected_items_pop = np.setdiff1d(range(num_items), affected_items_pop)\n",
    "            unaffected_items_diff = np.setdiff1d(range(num_items), affected_items_diff)\n",
    "            \n",
    "            for lam in lams:\n",
    "                modified_matrix_random = (1-lam)*Y + lam*critiqued_matrix_random \n",
    "                modified_matrix_pop = (1-lam)*Y + lam*critiqued_matrix_pop \n",
    "                modified_matrix_diff = (1-lam)*Y + lam*critiqued_matrix_diff \n",
    "                \n",
    "                # Random\n",
    "                prediction_scores_u = predict_scores(matrix_U=modified_matrix_random[user], \n",
    "                                     matrix_V=RQ,\n",
    "                                     )\n",
    "                prediction_items = predict_vector(rating_vector=prediction_scores_u,\n",
    "                                                  train_vector=matrix_Train[user],\n",
    "                                                  remove_train=False)\n",
    "                \n",
    "                item_rank = np.where(prediction_items == item)[0][0]\n",
    "                post_ranks_random_all.append(item_rank)\n",
    "                \n",
    "                # Random scores\n",
    "                affected_hit = sum(np.in1d(prediction_items[:top_k_rec],affected_items_random))\n",
    "                unaffected_hit = sum(np.in1d(prediction_items[:top_k_rec],unaffected_items_random))\n",
    "                score = affected_weight*affected_hit + unaffected_weight*unaffected_hit\n",
    "                random_scores.append(score)\n",
    "                \n",
    "                # Random Rating\n",
    "                latent_diff = modified_matrix_random - Y #post-pre\n",
    "                rating_diff = predict_scores(matrix_U=latent_diff[user], \n",
    "                                     matrix_V=RQ,\n",
    "                                     )\n",
    "                affected_items_mask = np.in1d(prediction_items, affected_items_random)\n",
    "                affected_items_index_rank = np.where(affected_items_mask == True)\n",
    "                unaffected_items_index_rank = np.where(affected_items_mask == False)\n",
    "                \n",
    "                rating_diff_sum_unaffected = np.sum(np.abs(rating_diff), \n",
    "                                                    where = np.in1d(range(num_items),np.intersect1d(unaffected_items_random, prediction_items[unaffected_items_index_rank[0][:100]])))\n",
    "                rating_diff_sum_affected = np.sum(rating_diff, where = np.in1d(range(num_items), \n",
    "                                                                               np.intersect1d(affected_items_random, prediction_items[affected_items_index_rank[0][:100]])))\n",
    "                rating_score = w1*rating_diff_sum_unaffected - w2*rating_diff_sum_affected\n",
    "#                 print (rating_score)\n",
    "                random_ratings.append(rating_score)\n",
    "    \n",
    "                # Random upper \n",
    "                prediction_scores_u = predict_scores(matrix_U=modified_matrix_random[user], \n",
    "                                                     matrix_V=RQ, \n",
    "                                                     bias=None,\n",
    "                                                   penalize = True,\n",
    "                                                   keyphrase_freq = keyphrase_freq, \n",
    "                                                   critiqued_keyphrase = critiqued_keyphrase_random, \n",
    "                                                   matrix_Train = matrix_Train,\n",
    "                                                   alpha = 0)\n",
    "                prediction_items = predict_vector(rating_vector=prediction_scores_u,\n",
    "                                                  train_vector=matrix_Train[user],\n",
    "                                                  remove_train=False)\n",
    "                item_rank = np.where(prediction_items == item)[0][0]\n",
    "                post_ranks_random_upper.append(item_rank)\n",
    "                \n",
    "                # Pop\n",
    "                prediction_scores_u = predict_scores(matrix_U=modified_matrix_pop[user], \n",
    "                                     matrix_V=RQ,\n",
    "                                     )\n",
    "                prediction_items = predict_vector(rating_vector=prediction_scores_u,\n",
    "                                                  train_vector=matrix_Train[user],\n",
    "                                                  remove_train=False)\n",
    "                \n",
    "                item_rank = np.where(prediction_items == item)[0][0]\n",
    "                post_ranks_pop_all.append(item_rank)\n",
    "                \n",
    "                \n",
    "                # pop scores\n",
    "                affected_hit = sum(np.in1d(prediction_items[:top_k_rec],affected_items_pop))\n",
    "                unaffected_hit = sum(np.in1d(prediction_items[:top_k_rec],unaffected_items_pop))\n",
    "                score = affected_weight*affected_hit + unaffected_weight*unaffected_hit\n",
    "                pop_scores.append(score)\n",
    "            \n",
    "                # Pop Rating\n",
    "                latent_diff = modified_matrix_pop - Y #post-pre\n",
    "                rating_diff = predict_scores(matrix_U=latent_diff[user], \n",
    "                                     matrix_V=RQ,\n",
    "                                     )\n",
    "                affected_items_mask = np.in1d(prediction_items, affected_items_pop)\n",
    "                affected_items_index_rank = np.where(affected_items_mask == True)\n",
    "                unaffected_items_index_rank = np.where(affected_items_mask == False)\n",
    "                \n",
    "                rating_diff_sum_unaffected = np.sum(np.abs(rating_diff), where = np.in1d(range(num_items),np.intersect1d(unaffected_items_pop, prediction_items[unaffected_items_index_rank[0][:100]])))\n",
    "                rating_diff_sum_affected = np.sum(rating_diff, where = np.in1d(range(num_items), np.intersect1d(affected_items_pop, prediction_items[affected_items_index_rank[0][:100]])))\n",
    "                rating_score = w1*rating_diff_sum_unaffected - w2*rating_diff_sum_affected\n",
    "                pop_ratings.append(rating_score)\n",
    "                \n",
    "                # Pop upper \n",
    "                \n",
    "                prediction_scores_u = predict_scores(matrix_U=modified_matrix_pop[user], \n",
    "                                                     matrix_V=RQ, \n",
    "                                                     bias=None,\n",
    "                                                   penalize = True,\n",
    "                                                   keyphrase_freq = keyphrase_freq, \n",
    "                                                   critiqued_keyphrase = critiqued_keyphrase_pop, \n",
    "                                                   matrix_Train = matrix_Train,\n",
    "                                                   alpha = 0)\n",
    "                prediction_items = predict_vector(rating_vector=prediction_scores_u,\n",
    "                                                  train_vector=matrix_Train[user],\n",
    "                                                  remove_train=False)\n",
    "                item_rank = np.where(prediction_items == item)[0][0]\n",
    "                post_ranks_pop_upper.append(item_rank)\n",
    "                \n",
    "                # Diff\n",
    "                prediction_scores_u = predict_scores(matrix_U=modified_matrix_diff[user], \n",
    "                                     matrix_V=RQ,\n",
    "                                     )\n",
    "                prediction_items = predict_vector(rating_vector=prediction_scores_u,\n",
    "                                                  train_vector=matrix_Train[user],\n",
    "                                                  remove_train=False)\n",
    "                \n",
    "                item_rank = np.where(prediction_items == item)[0][0]\n",
    "                post_ranks_diff_all.append(item_rank)\n",
    "                \n",
    "                # Diff scores\n",
    "                affected_hit = sum(np.in1d(prediction_items[:top_k_rec],affected_items_diff))\n",
    "                unaffected_hit = sum(np.in1d(prediction_items[:top_k_rec],unaffected_items_diff))\n",
    "                score = affected_weight*affected_hit + unaffected_weight*unaffected_hit\n",
    "                diff_scores.append(score)\n",
    "                \n",
    "                # Diff Rating\n",
    "                latent_diff = modified_matrix_diff - Y #post-pre\n",
    "                rating_diff = predict_scores(matrix_U=latent_diff[user], \n",
    "                                     matrix_V=RQ,\n",
    "                                     )\n",
    "                affected_items_mask = np.in1d(prediction_items, affected_items_diff)\n",
    "                affected_items_index_rank = np.where(affected_items_mask == True)\n",
    "                unaffected_items_index_rank = np.where(affected_items_mask == False)\n",
    "                \n",
    "                rating_diff_sum_unaffected = np.sum(np.abs(rating_diff), where = np.in1d(range(num_items),np.intersect1d(unaffected_items_diff, prediction_items[unaffected_items_index_rank[0][:100]])))\n",
    "                rating_diff_sum_affected = np.sum(rating_diff, where = np.in1d(range(num_items), np.intersect1d(affected_items_diff, prediction_items[affected_items_index_rank[0][:100]])))\n",
    "                rating_score = w1*rating_diff_sum_unaffected - w2*rating_diff_sum_affected\n",
    "                diff_ratings.append(rating_score)\n",
    "                # Diff upper \n",
    "                prediction_scores_u = predict_scores(matrix_U=modified_matrix_diff[user], \n",
    "                                                     matrix_V=RQ, \n",
    "                                                     bias=None,\n",
    "                                                   penalize = True,\n",
    "                                                   keyphrase_freq = keyphrase_freq, \n",
    "                                                   critiqued_keyphrase = critiqued_keyphrase_diff, \n",
    "                                                   matrix_Train = matrix_Train,\n",
    "                                                   alpha = 0)\n",
    "                prediction_items = predict_vector(rating_vector=prediction_scores_u,\n",
    "                                                  train_vector=matrix_Train[user],\n",
    "                                                  remove_train=False)\n",
    "                item_rank = np.where(prediction_items == item)[0][0]\n",
    "                post_ranks_diff_upper.append(item_rank)\n",
    "            \n",
    "            ######################################################\n",
    "            # optimal predicted lambda from ranking obj \n",
    "            random_ranking_opti_predicted = lams[np.argmax(random_scores)]\n",
    "            pop_ranking_opti_predicted = lams[np.argmax(pop_scores)]\n",
    "            diff_ranking_opti_predicted = lams[np.argmax(diff_scores)]\n",
    "            \n",
    "            # optimal predicted lambda from rating obj \n",
    "            random_rating_opti_predicted = lams[np.argmin(random_ratings)]\n",
    "            pop_rating_opti_predicted = lams[np.argmin(pop_ratings)]\n",
    "            diff_rating_opti_predicted = lams[np.argmin(diff_ratings)]\n",
    "            \n",
    "            ####################################################\n",
    "            # Get optimal post_ranking predicted\n",
    "            modified_matrix_random_opti_predicted = (1-random_ranking_opti_predicted)*Y + random_ranking_opti_predicted*critiqued_matrix_random \n",
    "            modified_matrix_pop_opti_predicted = (1-random_ranking_opti_predicted)*Y + random_ranking_opti_predicted*critiqued_matrix_pop \n",
    "            modified_matrix_diff_opti_predicted = (1-random_ranking_opti_predicted)*Y + random_ranking_opti_predicted*critiqued_matrix_diff \n",
    "            # Random\n",
    "            prediction_scores_u = predict_scores(matrix_U=modified_matrix_random_opti_predicted[user], \n",
    "                                     matrix_V=RQ,\n",
    "                                     )\n",
    "            prediction_items = predict_vector(rating_vector=prediction_scores_u,\n",
    "                                              train_vector=matrix_Train[user],\n",
    "                                              remove_train=False)\n",
    "\n",
    "            item_rank = np.where(prediction_items == item)[0][0]\n",
    "            row['random_opti_ranking'] = item_rank\n",
    "            \n",
    "            modified_matrix_random_opti_predicted = (1-random_rating_opti_predicted)*Y + random_rating_opti_predicted*critiqued_matrix_random \n",
    "            prediction_scores_u = predict_scores(matrix_U=modified_matrix_random_opti_predicted[user], \n",
    "                                     matrix_V=RQ,\n",
    "                                     )\n",
    "            prediction_items = predict_vector(rating_vector=prediction_scores_u,\n",
    "                                              train_vector=matrix_Train[user],\n",
    "                                              remove_train=False)\n",
    "\n",
    "            item_rank = np.where(prediction_items == item)[0][0]\n",
    "            row['random_opti_rating'] = item_rank\n",
    "            \n",
    "            # Pop\n",
    "            prediction_scores_u = predict_scores(matrix_U=modified_matrix_pop_opti_predicted[user], \n",
    "                                     matrix_V=RQ,\n",
    "                                     )\n",
    "            prediction_items = predict_vector(rating_vector=prediction_scores_u,\n",
    "                                              train_vector=matrix_Train[user],\n",
    "                                              remove_train=False)\n",
    "\n",
    "            item_rank = np.where(prediction_items == item)[0][0]\n",
    "            row['pop_opti_ranking'] = item_rank\n",
    "            \n",
    "            modified_matrix_pop_opti_predicted = (1-pop_rating_opti_predicted)*Y + pop_rating_opti_predicted*critiqued_matrix_pop \n",
    "            prediction_scores_u = predict_scores(matrix_U=modified_matrix_pop_opti_predicted[user], \n",
    "                                     matrix_V=RQ,\n",
    "                                     )\n",
    "            prediction_items = predict_vector(rating_vector=prediction_scores_u,\n",
    "                                              train_vector=matrix_Train[user],\n",
    "                                              remove_train=False)\n",
    "\n",
    "            item_rank = np.where(prediction_items == item)[0][0]\n",
    "            row['pop_opti_rating'] = item_rank\n",
    "            \n",
    "            # Diff\n",
    "            prediction_scores_u = predict_scores(matrix_U=modified_matrix_diff_opti_predicted[user], \n",
    "                                     matrix_V=RQ,\n",
    "                                     )\n",
    "            prediction_items = predict_vector(rating_vector=prediction_scores_u,\n",
    "                                              train_vector=matrix_Train[user],\n",
    "                                              remove_train=False)\n",
    "\n",
    "            item_rank = np.where(prediction_items == item)[0][0]\n",
    "            row['diff_opti_ranking'] = item_rank\n",
    "#             print ('diff_opti_ranking ', item_rank)\n",
    "            \n",
    "            modified_matrix_diff_opti_predicted = (1-diff_rating_opti_predicted)*Y + diff_rating_opti_predicted*critiqued_matrix_diff \n",
    "            prediction_scores_u = predict_scores(matrix_U=modified_matrix_diff_opti_predicted[user], \n",
    "                                     matrix_V=RQ,\n",
    "                                     )\n",
    "            prediction_items = predict_vector(rating_vector=prediction_scores_u,\n",
    "                                              train_vector=matrix_Train[user],\n",
    "                                              remove_train=False)\n",
    "\n",
    "            item_rank = np.where(prediction_items == item)[0][0]\n",
    "            row['diff_opti_rating'] = item_rank\n",
    "            \n",
    "            row['post_rank_random_all'] = post_ranks_random_all\n",
    "            row['post_rank_random_upper'] = post_ranks_random_upper\n",
    "            row['random_scores'] = random_scores\n",
    "            row['random_ratings'] = random_ratings\n",
    "            \n",
    "            row['post_rank_pop_all'] = post_ranks_pop_all\n",
    "            row['post_rank_pop_upper'] = post_ranks_pop_upper\n",
    "            row['pop_scores'] = pop_scores\n",
    "            row['pop_ratings'] = pop_ratings\n",
    "            \n",
    "            row['post_rank_diff_all'] = post_ranks_diff_all\n",
    "            row['post_rank_diff_upper'] = post_ranks_diff_upper\n",
    "            row['diff_scores'] = diff_scores\n",
    "            row['diff_ratings'] = diff_ratings\n",
    "            \n",
    "            df = df.append(row, ignore_index=True)\n",
    "            \n",
    "\n",
    "        # break after got 10 target items \n",
    "        num_target_item += 1\n",
    "        if num_target_item >10: # only want max 10 items per user\n",
    "            break\n",
    "            \n",
    "    return df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
