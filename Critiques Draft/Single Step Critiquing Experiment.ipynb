{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Env Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys \n",
    "# sys.path.clear()\n",
    "sys.path.insert(0, 'D:\\\\Anaconda\\\\envs\\\\tensorflow_cpu\\\\python36.zip')\n",
    "sys.path.insert(0, 'D:\\\\Anaconda\\\\envs\\\\tensorflow_cpu\\\\DLLs')\n",
    "sys.path.insert(0, 'D:\\\\Anaconda\\\\envs\\\\tensorflow_cpu\\\\lib')\n",
    "sys.path.insert(0, 'D:\\\\Anaconda\\\\envs\\\\tensorflow_cpu')\n",
    "sys.path.insert(0, 'D:\\\\Anaconda\\\\envs\\\\tensorflow_cpu\\\\lib\\\\site-packages')\n",
    "sys.path.insert(0, '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "# TensorFlow and tf.keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# Helper libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix, load_npz, save_npz\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import normalize\n",
    "import datetime\n",
    "import json\n",
    "import pandas as pd\n",
    "import time\n",
    "import yaml\n",
    "import scipy.sparse as sparse\n",
    "from ast import literal_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load Original Data\n",
    "df_train = pd.read_csv('../../data/yelp/Train.csv',encoding='latin-1')\n",
    "df_valid = pd.read_csv('../../data/yelp/Valid.csv',encoding='latin-1')\n",
    "df_test = pd.read_csv('../../data/yelp/Test.csv',encoding='latin-1')\n",
    "keyphrases = pd.read_csv('../../data/yelp/KeyPhrases.csv')['Phrases'].tolist()\n",
    "keyphrase_popularity = np.loadtxt('../data/yelp/'+'keyphrase_popularity.txt', dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load U-I Data \n",
    "rtrain = load_npz(\"../../data/yelp/Rtrain.npz\")\n",
    "rvalid = load_npz(\"../../data/yelp/Rvalid.npz\")\n",
    "rtest = load_npz(\"../../data/yelp/Rtest.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load user/item keyphrase data\n",
    "U_K = load_npz(\"../../data/yelp/U_K.npz\")\n",
    "I_K = load_npz(\"../../data/yelp/I_K.npz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forward Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Models\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "def train(matrix_train):\n",
    "    similarity = cosine_similarity(X=matrix_train, Y=None, dense_output=True)\n",
    "    return similarity\n",
    "\n",
    "def get_I_K(df, row_name = 'ItemIndex', shape = (3668,75)):\n",
    "    rows = []\n",
    "    cols = []\n",
    "    vals = []\n",
    "    for i in tqdm(range(df.shape[0])):\n",
    "        key_vector = literal_eval(df['keyVector'][i])\n",
    "        rows.extend([df[row_name][i]]*len(key_vector)) ## Item index\n",
    "        cols.extend(key_vector) ## Keyword Index\n",
    "        vals.extend(np.array([1]*len(key_vector)))\n",
    "    return csr_matrix((vals, (rows, cols)), shape=shape)\n",
    "\n",
    "\n",
    "\n",
    "def prediction(prediction_score, topK, matrix_Train):\n",
    "\n",
    "    prediction = []\n",
    "\n",
    "    for user_index in tqdm(range(matrix_Train.shape[0])):\n",
    "        vector_u = prediction_score[user_index]\n",
    "        vector_train = matrix_Train[user_index]\n",
    "        if len(vector_train.nonzero()[0]) > 0:\n",
    "            vector_predict = sub_routine(vector_u, vector_train, topK=topK)\n",
    "        else:\n",
    "            vector_predict = np.zeros(topK, dtype=np.float32)\n",
    "\n",
    "        prediction.append(vector_predict)\n",
    "\n",
    "    return np.vstack(prediction)\n",
    "\n",
    "\n",
    "def sub_routine(vector_u, vector_train, topK=500):\n",
    "\n",
    "    train_index = vector_train.nonzero()[1]\n",
    "\n",
    "    vector_u = vector_u\n",
    "\n",
    "    candidate_index = np.argpartition(-vector_u, topK+len(train_index))[:topK+len(train_index)]\n",
    "    vector_u = candidate_index[vector_u[candidate_index].argsort()[::-1]]\n",
    "    vector_u = np.delete(vector_u, np.isin(vector_u, train_index).nonzero()[0])\n",
    "\n",
    "    return vector_u[:topK]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(matrix_train, k, similarity, item_similarity_en = False):\n",
    "    \"\"\"\n",
    "    res = similarity * matrix_train    if item_similarity_en = False\n",
    "    res = similarity * matrix_train.T  if item_similarity_en = True\n",
    "    \"\"\"\n",
    "    prediction_scores = []\n",
    "    \n",
    "    if item_similarity_en:\n",
    "        matrix_train = matrix_train.transpose()\n",
    "        \n",
    "    for user_index in tqdm(range(matrix_train.shape[0])):\n",
    "        # Get user u's prediction scores to all users\n",
    "        vector_u = similarity[user_index]\n",
    "\n",
    "        # Get closest K neighbors excluding user u self\n",
    "        similar_users = vector_u.argsort()[::-1][1:k+1]\n",
    "        # Get neighbors similarity weights and ratings\n",
    "        similar_users_weights = similarity[user_index][similar_users]\n",
    "        similar_users_ratings = matrix_train[similar_users].toarray()\n",
    "\n",
    "        prediction_scores_u = similar_users_ratings * similar_users_weights[:, np.newaxis]\n",
    "\n",
    "        prediction_scores.append(np.sum(prediction_scores_u, axis=0))\n",
    "    res = np.array(prediction_scores)\n",
    "    \n",
    "    if item_similarity_en:\n",
    "        res = res.transpose()\n",
    "    \n",
    "    return res\n",
    "\n",
    "def predict_vector(user_index, matrix_train, k, similarity):\n",
    "    \"\"\"\n",
    "    res = similarity * matrix_train    if item_similarity_en = False\n",
    "    res = similarity * matrix_train.T  if item_similarity_en = True\n",
    "    get only user_index row\n",
    "    \"\"\"\n",
    "    vector_u = similarity[user_index]\n",
    "    \n",
    "    # Get closest K neighbors excluding user u self\n",
    "    similar_users = vector_u.argsort()[::-1][1:k+1]\n",
    "    # Get neighbors similarity weights and ratings\n",
    "    similar_users_weights = similarity[user_index][similar_users]\n",
    "    similar_users_ratings = matrix_train[similar_users].toarray()\n",
    "    prediction_scores_u = similar_users_ratings * similar_users_weights[:, np.newaxis]\n",
    "    \n",
    "    return np.sum(prediction_scores_u, axis=0)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eval Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Evluation \n",
    "def recallk(vector_true_dense, hits, **unused):\n",
    "    hits = len(hits.nonzero()[0])\n",
    "    return float(hits)/len(vector_true_dense)\n",
    "\n",
    "def precisionk(vector_predict, hits, **unused):\n",
    "    hits = len(hits.nonzero()[0])\n",
    "    return float(hits)/len(vector_predict)\n",
    "\n",
    "\n",
    "def average_precisionk(vector_predict, hits, **unused):\n",
    "    precisions = np.cumsum(hits, dtype=np.float32)/range(1, len(vector_predict)+1)\n",
    "    return np.mean(precisions)\n",
    "\n",
    "\n",
    "def r_precision(vector_true_dense, vector_predict, **unused):\n",
    "    vector_predict_short = vector_predict[:len(vector_true_dense)]\n",
    "    hits = len(np.isin(vector_predict_short, vector_true_dense).nonzero()[0])\n",
    "    return float(hits)/len(vector_true_dense)\n",
    "\n",
    "\n",
    "def _dcg_support(size):\n",
    "    arr = np.arange(1, size+1)+1\n",
    "    return 1./np.log2(arr)\n",
    "\n",
    "\n",
    "def ndcg(vector_true_dense, vector_predict, hits):\n",
    "    idcg = np.sum(_dcg_support(len(vector_true_dense)))\n",
    "    dcg_base = _dcg_support(len(vector_predict))\n",
    "    dcg_base[np.logical_not(hits)] = 0\n",
    "    dcg = np.sum(dcg_base)\n",
    "    return dcg/idcg\n",
    "\n",
    "\n",
    "def click(hits, **unused):\n",
    "    first_hit = next((i for i, x in enumerate(hits) if x), None)\n",
    "    if first_hit is None:\n",
    "        return 5\n",
    "    else:\n",
    "        return first_hit/10\n",
    "\n",
    "\n",
    "def evaluate(matrix_Predict, matrix_Test, metric_names =['R-Precision', 'NDCG', 'Precision', 'Recall', 'MAP'], atK = [5, 10, 15, 20, 50], analytical=False):\n",
    "    \"\"\"\n",
    "    :param matrix_U: Latent representations of users, for LRecs it is RQ, for ALSs it is U\n",
    "    :param matrix_V: Latent representations of items, for LRecs it is Q, for ALSs it is V\n",
    "    :param matrix_Train: Rating matrix for training, features.\n",
    "    :param matrix_Test: Rating matrix for evaluation, true labels.\n",
    "    :param k: Top K retrieval\n",
    "    :param metric_names: Evaluation metrics\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    global_metrics = {\n",
    "        \"R-Precision\": r_precision,\n",
    "        \"NDCG\": ndcg,\n",
    "        \"Clicks\": click\n",
    "    }\n",
    "\n",
    "    local_metrics = {\n",
    "        \"Precision\": precisionk,\n",
    "        \"Recall\": recallk,\n",
    "        \"MAP\": average_precisionk\n",
    "    }\n",
    "\n",
    "    output = dict()\n",
    "\n",
    "    num_users = matrix_Predict.shape[0]\n",
    "\n",
    "    for k in atK:\n",
    "\n",
    "        local_metric_names = list(set(metric_names).intersection(local_metrics.keys()))\n",
    "        results = {name: [] for name in local_metric_names}\n",
    "        topK_Predict = matrix_Predict[:, :k]\n",
    "\n",
    "        for user_index in tqdm(range(topK_Predict.shape[0])):\n",
    "            vector_predict = topK_Predict[user_index]\n",
    "            if len(vector_predict.nonzero()[0]) > 0:\n",
    "                vector_true = matrix_Test[user_index]\n",
    "                vector_true_dense = vector_true.nonzero()[1]\n",
    "                hits = np.isin(vector_predict, vector_true_dense)\n",
    "\n",
    "                if vector_true_dense.size > 0:\n",
    "                    for name in local_metric_names:\n",
    "                        results[name].append(local_metrics[name](vector_true_dense=vector_true_dense,\n",
    "                                                                 vector_predict=vector_predict,\n",
    "                                                                 hits=hits))\n",
    "\n",
    "        results_summary = dict()\n",
    "        if analytical:\n",
    "            for name in local_metric_names:\n",
    "                results_summary['{0}@{1}'.format(name, k)] = results[name]\n",
    "        else:\n",
    "            for name in local_metric_names:\n",
    "                results_summary['{0}@{1}'.format(name, k)] = (np.average(results[name]),\n",
    "                                                              1.96*np.std(results[name])/np.sqrt(num_users))\n",
    "        output.update(results_summary)\n",
    "\n",
    "    global_metric_names = list(set(metric_names).intersection(global_metrics.keys()))\n",
    "    results = {name: [] for name in global_metric_names}\n",
    "\n",
    "    topK_Predict = matrix_Predict[:]\n",
    "\n",
    "    for user_index in tqdm(range(topK_Predict.shape[0])):\n",
    "        vector_predict = topK_Predict[user_index]\n",
    "\n",
    "        if len(vector_predict.nonzero()[0]) > 0:\n",
    "            vector_true = matrix_Test[user_index]\n",
    "            vector_true_dense = vector_true.nonzero()[1]\n",
    "            hits = np.isin(vector_predict, vector_true_dense)\n",
    "\n",
    "            # if user_index == 1:\n",
    "            #     import ipdb;\n",
    "            #     ipdb.set_trace()\n",
    "\n",
    "            if vector_true_dense.size > 0:\n",
    "                for name in global_metric_names:\n",
    "                    results[name].append(global_metrics[name](vector_true_dense=vector_true_dense,\n",
    "                                                              vector_predict=vector_predict,\n",
    "                                                              hits=hits))\n",
    "\n",
    "    results_summary = dict()\n",
    "    if analytical:\n",
    "        for name in global_metric_names:\n",
    "            results_summary[name] = results[name]\n",
    "    else:\n",
    "        for name in global_metric_names:\n",
    "            results_summary[name] = (np.average(results[name]), 1.96*np.std(results[name])/np.sqrt(num_users))\n",
    "    output.update(results_summary)\n",
    "\n",
    "    return output\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forward Initial Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User-Item KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 2343/2343 [00:07<00:00, 311.58it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 2343/2343 [00:00<00:00, 2780.01it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 2343/2343 [00:00<00:00, 4753.36it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 2343/2343 [00:00<00:00, 4859.68it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 2343/2343 [00:00<00:00, 4776.34it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 2343/2343 [00:00<00:00, 4886.99it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 2343/2343 [00:00<00:00, 4836.14it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 2343/2343 [00:00<00:00, 4166.57it/s]\n"
     ]
    }
   ],
   "source": [
    "similarity = normalize(train(rtrain))\n",
    "user_item_prediction_score = predict(rtrain, 100, similarity, item_similarity_en= False)\n",
    "user_item_predict = prediction(user_item_prediction_score, 50, rtrain)\n",
    "user_item_res = evaluate(user_item_predict, rtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MAP@10': (0.06333952750429245, 0.00455145183026277),\n",
       " 'MAP@15': (0.05872249612550844, 0.0038121823597348156),\n",
       " 'MAP@20': (0.055196280875748356, 0.003345258771111864),\n",
       " 'MAP@5': (0.06940666362391602, 0.0060646277121995185),\n",
       " 'MAP@50': (0.04436838784245958, 0.0022020570312340938),\n",
       " 'NDCG': (0.09071795198195, 0.003803970590016347),\n",
       " 'Precision@10': (0.05330899132816066, 0.0032544740534870857),\n",
       " 'Precision@15': (0.04698006998326487, 0.0025622684368576416),\n",
       " 'Precision@20': (0.043336376083979916, 0.002222006808632301),\n",
       " 'Precision@5': (0.06462802373345505, 0.004754606217931856),\n",
       " 'Precision@50': (0.032889091738931994, 0.0014317314500480152),\n",
       " 'R-Precision': (0.048464138894968055, 0.0027869069242192506),\n",
       " 'Recall@10': (0.04269615369598775, 0.0027831077562657665),\n",
       " 'Recall@15': (0.05562887733868642, 0.0031389991916236284),\n",
       " 'Recall@20': (0.0677664821917642, 0.003424484045821138),\n",
       " 'Recall@5': (0.026408137823500974, 0.002191309117794643),\n",
       " 'Recall@50': (0.12696642809611336, 0.0048241883971306436)}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# k = 100 \n",
    "user_item_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Latent Similarity Matrix Learned with Linear Regression¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Training \n",
    "X = normalize(U_K.todense())\n",
    "y = normalize(train(rtrain))\n",
    "clf = Ridge(alpha=0.1).fit(X, y) # Optimality at L2 regularization = 0.1\n",
    "lr_similarity = clf.predict(np.array(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Prediciting\n",
    "similarity = lr_similarity\n",
    "lr_prediction_score = predict(rtrain, 100, similarity, item_similarity_en= False)\n",
    "lr_predict = prediction(lr_prediction_score, 50, rtrain)\n",
    "lr_res = evaluate(lr_predict, rtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# k = 100\n",
    "lr_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Critiquing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# One hot encoding of critiquing\n",
    "def get_critiqued_UK(user_keyphrase_frequency,user_index,critiqued_keyphrase):\n",
    "    \"\"\"\n",
    "    user_keyphrase_frequency is the U_K matrix (csr sparse matrix)\n",
    "    return the one-hot encoding of the critique\n",
    "    \"\"\"\n",
    "    U_K_cp = user_keyphrase_frequency.copy()\n",
    "    U_K_cp[user_index] = 0\n",
    "    U_K_cp[user_index,critiqued_keyphrase] = 1\n",
    "    return U_K_cp\n",
    "\n",
    "def project_one_hot_encoding(reg, user_keyphrase_frequency,user_index = 0,critiqued_keyphrase = 0, normalize_en = True):\n",
    "    \"\"\"\n",
    "    Return the projection on user_sim space from one-hot encoding of critiqued keyphrase\n",
    "    The res[user_index] should be target embedding row\n",
    "    \"\"\"\n",
    "    critiqued_matrix = get_critiqued_UK(user_keyphrase_frequency, user_index, critiqued_keyphrase)\n",
    "    res = reg.predict(critiqued_matrix)\n",
    "    if normalize_en:\n",
    "        res = normalize((res))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_initial_predictions(X = normalize(U_K.todense()), y = normalize(train(rtrain)),\n",
    "                            matrix_Train = rtrain, k = 100):\n",
    "    clf = Ridge(alpha=0.1).fit(X, y)\n",
    "    similarity = normalize(train(matrix_Train))\n",
    "    user_item_prediction_score = predict(matrix_Train, k, similarity, item_similarity_en= False)\n",
    "    return user_item_prediction_score, clf\n",
    "def get_valid_keyphrases(keyphrase_freq,top_recommendations,item = None,threshold=50,mutiple_keyphrases_en = False, top_items = None):\n",
    "    \"\"\"\n",
    "    Wrapper function to get either top 1 or top n keyphrases\n",
    "    \"\"\"\n",
    "    if mutiple_keyphrases_en:\n",
    "        top_keyphrases = []\n",
    "        for item in top_items:\n",
    "            top_keyphrases.extend(get_valid_keyphrases_for_one_item(keyphrase_freq,top_recommendations,item,threshold=threshold))\n",
    "        return np.ravel(list(set(top_keyphrases))) # remove duplicate and reformat to np array\n",
    "    else:\n",
    "        return get_valid_keyphrases_for_one_item(keyphrase_freq,top_recommendations,item,threshold=threshold)\n",
    "\n",
    "def get_valid_keyphrases_for_one_item(keyphrase_freq,top_recommendations, item,threshold=50):\n",
    "    \"\"\"\n",
    "    Get keyphrases of item that make sense\n",
    "    E.g. if the item has fewer than threshold=50 keyphrases, get all of them\n",
    "    otherwise get top 50 keyphrases\n",
    "    \"\"\"\n",
    "    keyphrase_length = len(keyphrase_freq[item].nonzero()[1])\n",
    "    if keyphrase_length<threshold:\n",
    "        return keyphrase_freq[item].nonzero()[1]\n",
    "    else:\n",
    "        keyphrases = np.ravel(keyphrase_freq[top_recommendations[0]].todense())\n",
    "        top_keyphrases = np.argsort(keyphrases)[::-1][:threshold]\n",
    "        return top_keyphrases\n",
    "    \n",
    "def predict_vector(user_index, matrix_train, k, similarity, with_keyphrase = False, \n",
    "                   keyphrase_freq = None, critiqued_keyphrase = None, alpha = 0):\n",
    "    \"\"\"\n",
    "    get only user_index row\n",
    "    if with_keyphrase = True, then penalize items without critiqued_keyphrase to alpha (default = 0)\n",
    "    \"\"\"\n",
    "    vector_u = similarity[user_index]\n",
    "    \n",
    "    # Get closest K neighbors excluding user u self\n",
    "    similar_users = vector_u.argsort()[::-1][1:k+1]\n",
    "    # Get neighbors similarity weights and ratings\n",
    "    similar_users_weights = similarity[user_index][similar_users]\n",
    "    similar_users_ratings = matrix_train[similar_users].toarray()\n",
    "    \n",
    "    prediction_scores_u = similar_users_ratings * similar_users_weights[:, np.newaxis]\n",
    "    \n",
    "    if with_keyphrase == False:\n",
    "        return np.sum(prediction_scores_u, axis=0)\n",
    "    \n",
    "    # Only Predict items with critiqued_keyphrase \n",
    "    else:\n",
    "        prediction_scores = np.sum(prediction_scores_u, axis=0)\n",
    "#         print (prediction_scores)\n",
    "        #penalize items without critiqued keyphrase\n",
    "        items_with_keyphrase = np.ravel(keyphrase_freq.T[critiqued_keyphrase].nonzero()[1])\n",
    "#         print (items_with_keyphrase)\n",
    "        #Return the unique values in ar1 that are not in ar2.\n",
    "        items_without_keyphrase = np.setdiff1d(np.arange(matrix_train.shape[1]), items_with_keyphrase)\n",
    "        prediction_scores[items_without_keyphrase] = alpha # penalize\n",
    "        return prediction_scores\n",
    "#         print (prediction_scores)\n",
    "#         return prediction_scores/sum(prediction_scores)\n",
    "\n",
    "    \n",
    "def get_initial_prediction(user,X = normalize(U_K.todense()), y = normalize(train(rtrain)),\n",
    "                            matrix_Train = rtrain, k = 100):\n",
    "    \"\"\"\n",
    "    Get the initial knn predictions before critiquing pipelines\n",
    "    get the linear regression model for critiquing embedding (W_2)\n",
    "    get the initial user similarity matrix \n",
    "    k here is the parameter for KNN\n",
    "    \"\"\"\n",
    "    clf = Ridge(alpha=0.1).fit(X, y)\n",
    "    similarity = normalize(train(matrix_Train))\n",
    "    user_item_prediction_score = predict_vector(user, matrix_Train, k, similarity)\n",
    "    return user_item_prediction_score, clf\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For keyphrase selecting method # 3 \"diff\" \n",
    "def get_item_keyphrase_freq(keyphrase_freq,item):\n",
    "    \"\"\"\n",
    "    Get item's keyphrase frequency \n",
    "    \"\"\"\n",
    "    count = keyphrase_freq[item].todense()\n",
    "    return count/np.sum(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Utility function for getting restaurant info from ItemIndex\n",
    "def get_business_df(path = \"../../data/yelp/business.json\" ):\n",
    "    with open(path,encoding=\"utf8\") as json_file:\n",
    "        data = json_file.readlines()\n",
    "        data = list(map(json.loads, data))\n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def get_restaurant_info(business_df, business_id, name = True, review_count = True, stars = True ):\n",
    "    output_list = {}\n",
    "    row_idx = int(business_df.index[business_df['business_id'] == business_id].tolist()[0])\n",
    "    if name == True:\n",
    "        output_list['name'] = business_df['name'][row_idx].encode('utf-8').strip()\n",
    "    if review_count == True:\n",
    "        output_list['review_count'] = business_df['review_count'][row_idx]\n",
    "    if stars == True:\n",
    "        output_list['stars'] = business_df['stars'][row_idx] \n",
    "    return output_list\n",
    "\n",
    "# def get_businessid_from_Itemindex(ItemIndex_list, itemindex):\n",
    "#     return ItemIndex_list['business_id'].tolist()[itemindex]\n",
    "\n",
    "def get_restaurant_name(df_train, business_df, ItemIndex):\n",
    "    rows = np.where(df_train['ItemIndex'] == ItemIndex)\n",
    "    if len(rows)!= 0:\n",
    "        business_id = df_train.loc[rows[0][0]]['business_id']\n",
    "        item_info = get_restaurant_info(business_df, business_id)\n",
    "        return item_info['name']\n",
    "    return \"NOT_FOUND\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_keyphrase_popularity(df,keyphrases):\n",
    "    \"\"\"\n",
    "    Get keyphrase popularity (count) from dataframe\n",
    "    \"\"\"\n",
    "    keyphrase_popularity = np.zeros(len(keyphrases)) #initialize\n",
    "    for i in range(len(df)):\n",
    "        keyphrase_vector = literal_eval(df['keyVector'][i])\n",
    "        keyphrase_popularity[keyphrase_vector] += 1 # count\n",
    "    return keyphrase_popularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# keyphrase_popularity = get_keyphrase_popularity(df_train,keyphrases)\n",
    "\n",
    "# Save and load\n",
    "# np.savetxt('../data/yelp/'+'keyphrase_popularity.txt', keyphrase_popularity, fmt='%d')\n",
    "keyphrase_popularity = np.loadtxt('../data/yelp/'+'keyphrase_popularity.txt', dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "business_df = get_business_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Initialize df for storing the experiment\n",
    "\n",
    "# post_ranki is post rank with different lambda ratio for combining pre-post User similarity matrix \n",
    "columns = ['user_id', 'target_item', 'item_name', 'iter', 'pre_rank', \n",
    "           'top_prediction_item_name','critiqued_keyphrase', 'keyphrase_name', \n",
    "           'post_rank0', \n",
    "           'post_rank1', \n",
    "           'post_rank2', \n",
    "           'post_rank3', \n",
    "           'post_rank4', \n",
    "           'post_rank5', \n",
    "           'post_rank6', \n",
    "           'post_rank7', \n",
    "           'post_rank8',\n",
    "           'post_rank9',\n",
    "           'post_rank10',\n",
    "           'num_existing_keyphrases'] \n",
    "df = pd.DataFrame(columns=columns)\n",
    "row = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def single_step_critiquing_experiment(user = 2, \n",
    "                           keyphrase_length_threshold = 150, \n",
    "                           max_iteration_threshold = 5,\n",
    "                           k = 50,\n",
    "                           df = df,\n",
    "                           row = row,\n",
    "                           business_df = business_df,\n",
    "                           keyphrases = keyphrases,\n",
    "                           keyphrase_popularity = keyphrase_popularity, \n",
    "                           keyphrase_selection_method = 'random',\n",
    "                           recommend_type = 'all',\n",
    "                           lams = [0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1] \n",
    "                          ):\n",
    "    \"\"\"\n",
    "    k: HR@k \n",
    "    keyphrase_length_threshold: limit the number of keyphrases in top recommended item\n",
    "    keyphrase_selection_method: 'random': randomly select keyphrase from wanted_keyphrases\n",
    "                                'pop': always select the most popular keyphrase in wanted_keyphrases\n",
    "                                'diff': select the keyphrase with largest frequency difference between top recommended \n",
    "                                        item and target item.\n",
    "    recommend_type: 'all': recommend all items\n",
    "                    'upper' (only_with_critiqued_keyphrase): recommend items with only critiqued_keyphrase\n",
    "    lam: modified_matrix = lam*origianl_matrix + (1-lam)*critiquing_embedding \n",
    "    \"\"\"\n",
    "    \n",
    "    row['user_id'] = user\n",
    "    print ('User ID ', user)\n",
    "    \n",
    "    # Set up (move to header line later)\n",
    "    matrix_Train = rtrain\n",
    "    matrix_Test = rtest\n",
    "    keyphrase_freq = I_K\n",
    "    num_items = rtrain.shape[1]\n",
    "    max_wanted_keyphrase = 10 # for keyphrase_selection_method == \"diff\"\n",
    "    initial_user_similarity_embedding = normalize(train(matrix_Train))\n",
    "    \n",
    "    # Get wanted items \n",
    "    candidate_items = matrix_Test[user].nonzero()[1]\n",
    "    train_items = matrix_Train[user].nonzero()[1]\n",
    "    wanted_items = np.setdiff1d(candidate_items, train_items)\n",
    "    print ('wanted_items length: ',len(wanted_items))\n",
    "    \n",
    "    # Get initial forward prediction \n",
    "    prediction_score,clf = get_initial_prediction(user, X = normalize(U_K.todense()), y = normalize(train(rtrain)),\n",
    "                            matrix_Train = rtrain, k = 100)\n",
    "    \n",
    "    # Get initial top recommended item(s)\n",
    "    top_recommendations = np.argsort(prediction_score)[::-1]\n",
    "    print (\"Initial top recommendation index\",top_recommendations[0])\n",
    "    try:\n",
    "        row['top_prediction_item_name'] = get_restaurant_name(df_train, business_df, top_recommendations[0])\n",
    "    # in case we cannot get the restaurant name\n",
    "    except: \n",
    "        row['top_prediction_item_name'] = 'CANNOT_FIND'\n",
    "        print ('Cannot get restaurant name for ItemIndex: ', top_recommendations[0])\n",
    "    \n",
    "    \n",
    "    # Get top recommended item's keyphrases\n",
    "    top_item = top_recommendations[0] \n",
    "    top_recommend_keyphrases = get_valid_keyphrases(keyphrase_freq,\n",
    "                                                    top_recommendations, \n",
    "                                                    item = top_item,\n",
    "                                                    threshold=keyphrase_length_threshold,\n",
    "                                                    mutiple_keyphrases_en = False, \n",
    "                                                    top_items = None)\n",
    "    print ('num_top_recommended_keyphrases ',len(top_recommend_keyphrases))\n",
    "\n",
    "    if keyphrase_selection_method == 'diff':\n",
    "        top_recommended_keyphrase_freq = get_item_keyphrase_freq(keyphrase_freq,item = top_item)\n",
    "    \n",
    "    \n",
    "    #####################################\n",
    "    # For each item, do the critiquing\n",
    "    \n",
    "    #limit the item to only 10\n",
    "    num_target_item = 0 # initialize item count\n",
    "    \n",
    "    for item in wanted_items:    \n",
    "        print ('target_item: ', item)\n",
    "        row['target_item'] = item\n",
    "        try:\n",
    "            row['item_name'] = get_restaurant_name(df_train, business_df, item)\n",
    "        except:\n",
    "            row['item_name'] = 'CANNOT_FIND'\n",
    "            print ('Cannot get restaurant name for ItemIndex: ', item)\n",
    "\n",
    "        # Get pre-critiquing rank\n",
    "        initial_rank = np.where(item == np.argsort(prediction_score)[::-1])[0][0]\n",
    "#         print ('target_item initial rank', int(initial_rank))\n",
    "        row['pre_rank'] = int(initial_rank)\n",
    "\n",
    "        # Get the target item's existing keyphrases\n",
    "        item_keyphrases = keyphrase_freq[item].nonzero()[1]\n",
    "#         print ('num_existing_keyphrases ',len(item_keyphrases))\n",
    "        \n",
    "        if keyphrase_selection_method == 'diff':\n",
    "            target_keyphrase_freq = get_item_keyphrase_freq(keyphrase_freq,item = item)\n",
    "            # indicate the keyphrase with large freq in target_item but small_keyphrase in top_recommended items\n",
    "            diff_keyphrase_freq = target_keyphrase_freq - top_recommended_keyphrase_freq\n",
    "            \n",
    "        # Get wanted keyphrases\n",
    "        if keyphrase_selection_method != 'diff':\n",
    "            # Get keyphrases that is not in the top recommended items but in the target item (we can select)\n",
    "            wanted_keyphrases = np.setdiff1d(item_keyphrases,top_recommend_keyphrases)\n",
    "\n",
    "            if len(wanted_keyphrases) == 0:\n",
    "                print (\"wanted_keyphrases is empty\")\n",
    "                break\n",
    "            row['num_existing_keyphrases'] = len(wanted_keyphrases)\n",
    "            \n",
    "        # For 'diff'\n",
    "        else:\n",
    "            wanted_keyphrases = np.argsort(np.ravel(diff_keyphrase_freq))[::-1][:max_wanted_keyphrase]\n",
    "            row['num_existing_keyphrases'] = len(wanted_keyphrases)\n",
    "\n",
    "        affected_items = np.array([])\n",
    "        modified_matrix = initial_user_similarity_embedding # initialize user similarity embedding\n",
    "        \n",
    "        #############################################\n",
    "        # Critiquing iteration\n",
    "        for iteration in range(max_iteration_threshold):\n",
    "            print ('cur_iter ', iteration)\n",
    "            row['iter'] = iteration\n",
    "            if keyphrase_selection_method == 'random':\n",
    "                # Randomly critique one keyphrase\n",
    "                critiqued_keyphrase = np.random.choice(wanted_keyphrases, size=1, replace=False)[0]\n",
    "            elif keyphrase_selection_method == 'pop':\n",
    "                # Always critique the most popular keyphrase\n",
    "                critiqued_keyphrase = wanted_keyphrases[np.argmax(keyphrase_popularity[wanted_keyphrases])]\n",
    "            elif keyphrase_selection_method == 'diff':\n",
    "                # critique the keyphrase with largest freq diff between top recommended_item and target_item\n",
    "                critiqued_keyphrase = wanted_keyphrases[0]\n",
    "#                 print (critiqued_keyphrase)\n",
    "            \n",
    "#             print ('critiqued_keyphrase ,',critiqued_keyphrase, keyphrases[critiqued_keyphrase])\n",
    "            row['critiqued_keyphrase'] = critiqued_keyphrase\n",
    "            row['keyphrase_name'] = keyphrases[critiqued_keyphrase]\n",
    "            \n",
    "            # Do not critique this keyphrase next time\n",
    "            wanted_keyphrases = np.delete(wanted_keyphrases, np.where(critiqued_keyphrase == wanted_keyphrases))\n",
    "            if len(wanted_keyphrases) == 0: \n",
    "                print ('no more keyphrase available')\n",
    "                break\n",
    "            \n",
    "            # Get affected items (items have critiqued keyphrase)\n",
    "            current_affected_items = keyphrase_freq[:, critiqued_keyphrase].nonzero()[0]\n",
    "            affected_items = np.unique(np.concatenate((affected_items, current_affected_items))).astype(int) \n",
    "            unaffected_items = np.setdiff1d(range(num_items), affected_items)\n",
    "\n",
    "            # Critiquing Embedding\n",
    "\n",
    "            # One hot encoding\n",
    "            critiqued_matrix_onehot = get_critiqued_UK(U_K,user,critiqued_keyphrase)\n",
    "            critiqued_matrix = clf.predict(critiqued_matrix_onehot)\n",
    "            critiqued_matrix = normalize(critiqued_matrix)\n",
    "            \n",
    "#             critiqued_matrix = project_one_hot_encoding(clf, \n",
    "#                                                         U_K,\n",
    "#                                                         user_index = user,\n",
    "#                                                         critiqued_keyphrase = critiqued_keyphrase, \n",
    "#                                                         normalize_en = True)\n",
    "\n",
    "#             modified_matrix = modified_matrix + critiqued_matrix # averaging user-item embedding and critiquing embeeding\n",
    "            \n",
    "            # Warning!!! The following is used only for testing single step critiquing, \n",
    "            # for full average critiquing, use the above commented line \n",
    "            post_ranks = []\n",
    "            for lam in lams:\n",
    "                modified_matrix = (1-lam)*normalize(train(matrix_Train)) + lam*critiqued_matrix \n",
    "#                 modified_matrix = normalize(modified_matrix)\n",
    "                if lam == 0:\n",
    "                    print (modified_matrix == initial_user_similarity_embedding)\n",
    "            \n",
    "                # Get new predictions from modified embedding\n",
    "                if recommend_type == 'all':\n",
    "                    prediction_scores_u = predict_vector(user, matrix_Train, 100, modified_matrix)\n",
    "                if recommend_type == 'upper':\n",
    "                    prediction_scores_u = predict_vector(user, matrix_Train, 100, modified_matrix, \n",
    "                                                         with_keyphrase = True, \n",
    "                                                         keyphrase_freq = keyphrase_freq, \n",
    "                                                         critiqued_keyphrase = critiqued_keyphrase, \n",
    "                                                         alpha = 0)\n",
    "                post_critique_rank = np.where(item == np.argsort(prediction_scores_u)[::-1])[0][0]\n",
    "                print ('target_item post-critique rank with lambda '+str(lam), int(post_critique_rank))\n",
    "                post_rank = int(post_critique_rank)\n",
    "                post_ranks.append(post_rank)\n",
    "            row['post_rank'] = post_ranks\n",
    "            row['post_rank0'] = post_ranks[0]\n",
    "            row['post_rank1'] = post_ranks[1]\n",
    "            row['post_rank2'] = post_ranks[2]\n",
    "            row['post_rank3'] = post_ranks[3]\n",
    "            row['post_rank4'] = post_ranks[4]\n",
    "            row['post_rank5'] = post_ranks[5]\n",
    "            row['post_rank6'] = post_ranks[6]\n",
    "            row['post_rank7'] = post_ranks[7]\n",
    "            row['post_rank8'] = post_ranks[8]\n",
    "            row['post_rank9'] = post_ranks[9]\n",
    "            row['post_rank10'] = post_ranks[10]\n",
    "            df = df.append(row, ignore_index=True)\n",
    "            \n",
    "\n",
    "        # break after got 10 target items \n",
    "        num_target_item += 1\n",
    "        if num_target_item >10: # only want max 10 items per user\n",
    "            break\n",
    "            \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\tensorflow_cpu\\lib\\site-packages\\scipy\\sparse\\_index.py:126: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_arrayXarray(i, j, x)\n"
     ]
    }
   ],
   "source": [
    "lam = 0\n",
    "\n",
    "critiqued_matrix_onehot = get_critiqued_UK(U_K,0,0)\n",
    "critiqued_matrix = clf.predict(critiqued_matrix_onehot)\n",
    "critiqued_matrix = normalize(critiqued_matrix)\n",
    "a = (1-lam)*normalize(train(rtrain)) + lam*critiqued_matrix "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "single_step_with_avg_path = \"../tables/critiquing/single_step_lam_0105/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID  300\n",
      "wanted_items length:  14\n",
      "Initial top recommendation index 4443\n",
      "num_top_recommended_keyphrases  157\n",
      "target_item:  101\n",
      "cur_iter  0\n",
      "no more keyphrase available\n",
      "target_item:  886\n",
      "cur_iter  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\tensorflow_cpu\\lib\\site-packages\\scipy\\sparse\\_index.py:126: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_arrayXarray(i, j, x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]\n",
      " ...\n",
      " [ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]]\n",
      "target_item post-critique rank with lambda 0 755\n",
      "target_item post-critique rank with lambda 0.1 765\n",
      "target_item post-critique rank with lambda 0.2 773\n",
      "target_item post-critique rank with lambda 0.3 371\n",
      "target_item post-critique rank with lambda 0.4 268\n",
      "target_item post-critique rank with lambda 0.5 246\n",
      "target_item post-critique rank with lambda 0.6 301\n",
      "target_item post-critique rank with lambda 0.7 249\n",
      "target_item post-critique rank with lambda 0.8 224\n",
      "target_item post-critique rank with lambda 0.9 196\n",
      "target_item post-critique rank with lambda 1 176\n",
      "cur_iter  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\tensorflow_cpu\\lib\\site-packages\\scipy\\sparse\\_index.py:126: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_arrayXarray(i, j, x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]\n",
      " ...\n",
      " [ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]]\n",
      "target_item post-critique rank with lambda 0 755\n",
      "target_item post-critique rank with lambda 0.1 795\n",
      "target_item post-critique rank with lambda 0.2 473\n",
      "target_item post-critique rank with lambda 0.3 424\n",
      "target_item post-critique rank with lambda 0.4 445\n",
      "target_item post-critique rank with lambda 0.5 873\n",
      "target_item post-critique rank with lambda 0.6 811\n",
      "target_item post-critique rank with lambda 0.7 815\n",
      "target_item post-critique rank with lambda 0.8 830\n",
      "target_item post-critique rank with lambda 0.9 847\n",
      "target_item post-critique rank with lambda 1 866\n",
      "cur_iter  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\tensorflow_cpu\\lib\\site-packages\\scipy\\sparse\\_index.py:126: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_arrayXarray(i, j, x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]\n",
      " ...\n",
      " [ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]]\n",
      "target_item post-critique rank with lambda 0 755\n",
      "target_item post-critique rank with lambda 0.1 784\n",
      "target_item post-critique rank with lambda 0.2 783\n",
      "target_item post-critique rank with lambda 0.3 756\n",
      "target_item post-critique rank with lambda 0.4 885\n",
      "target_item post-critique rank with lambda 0.5 1874\n",
      "target_item post-critique rank with lambda 0.6 2967\n",
      "target_item post-critique rank with lambda 0.7 2934\n",
      "target_item post-critique rank with lambda 0.8 2901\n",
      "target_item post-critique rank with lambda 0.9 2919\n",
      "target_item post-critique rank with lambda 1 2903\n",
      "cur_iter  3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\tensorflow_cpu\\lib\\site-packages\\scipy\\sparse\\_index.py:126: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_arrayXarray(i, j, x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]\n",
      " ...\n",
      " [ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]]\n",
      "target_item post-critique rank with lambda 0 755\n",
      "target_item post-critique rank with lambda 0.1 774\n",
      "target_item post-critique rank with lambda 0.2 780\n",
      "target_item post-critique rank with lambda 0.3 765\n",
      "target_item post-critique rank with lambda 0.4 816\n",
      "target_item post-critique rank with lambda 0.5 939\n",
      "target_item post-critique rank with lambda 0.6 1076\n",
      "target_item post-critique rank with lambda 0.7 1842\n",
      "target_item post-critique rank with lambda 0.8 2024\n",
      "target_item post-critique rank with lambda 0.9 4499\n",
      "target_item post-critique rank with lambda 1 3288\n",
      "cur_iter  4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\tensorflow_cpu\\lib\\site-packages\\scipy\\sparse\\_index.py:126: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_arrayXarray(i, j, x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]\n",
      " ...\n",
      " [ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]]\n",
      "target_item post-critique rank with lambda 0 755\n",
      "target_item post-critique rank with lambda 0.1 819\n",
      "target_item post-critique rank with lambda 0.2 906\n",
      "target_item post-critique rank with lambda 0.3 944\n",
      "target_item post-critique rank with lambda 0.4 1364\n",
      "target_item post-critique rank with lambda 0.5 2166\n",
      "target_item post-critique rank with lambda 0.6 2105\n",
      "target_item post-critique rank with lambda 0.7 1946\n",
      "target_item post-critique rank with lambda 0.8 1955\n",
      "target_item post-critique rank with lambda 0.9 1933\n",
      "target_item post-critique rank with lambda 1 1923\n",
      "cur_iter  5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\tensorflow_cpu\\lib\\site-packages\\scipy\\sparse\\_index.py:126: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_arrayXarray(i, j, x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]\n",
      " ...\n",
      " [ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]]\n",
      "target_item post-critique rank with lambda 0 755\n",
      "target_item post-critique rank with lambda 0.1 830\n",
      "target_item post-critique rank with lambda 0.2 928\n",
      "target_item post-critique rank with lambda 0.3 2045\n",
      "target_item post-critique rank with lambda 0.4 1916\n",
      "target_item post-critique rank with lambda 0.5 1962\n",
      "target_item post-critique rank with lambda 0.6 4303\n",
      "target_item post-critique rank with lambda 0.7 3101\n",
      "target_item post-critique rank with lambda 0.8 3083\n",
      "target_item post-critique rank with lambda 0.9 3054\n",
      "target_item post-critique rank with lambda 1 3098\n",
      "cur_iter  6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\tensorflow_cpu\\lib\\site-packages\\scipy\\sparse\\_index.py:126: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_arrayXarray(i, j, x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]\n",
      " ...\n",
      " [ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]]\n",
      "target_item post-critique rank with lambda 0 755\n",
      "target_item post-critique rank with lambda 0.1 784\n",
      "target_item post-critique rank with lambda 0.2 875\n",
      "target_item post-critique rank with lambda 0.3 945\n",
      "target_item post-critique rank with lambda 0.4 2129\n",
      "target_item post-critique rank with lambda 0.5 2197\n",
      "target_item post-critique rank with lambda 0.6 2027\n",
      "target_item post-critique rank with lambda 0.7 3059\n",
      "target_item post-critique rank with lambda 0.8 4151\n",
      "target_item post-critique rank with lambda 0.9 4140\n",
      "target_item post-critique rank with lambda 1 2975\n",
      "cur_iter  7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\tensorflow_cpu\\lib\\site-packages\\scipy\\sparse\\_index.py:126: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_arrayXarray(i, j, x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]\n",
      " ...\n",
      " [ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]]\n",
      "target_item post-critique rank with lambda 0 755\n",
      "target_item post-critique rank with lambda 0.1 865\n",
      "target_item post-critique rank with lambda 0.2 1044\n",
      "target_item post-critique rank with lambda 0.3 1116\n",
      "target_item post-critique rank with lambda 0.4 2032\n",
      "target_item post-critique rank with lambda 0.5 3756\n",
      "target_item post-critique rank with lambda 0.6 3720\n",
      "target_item post-critique rank with lambda 0.7 3065\n",
      "target_item post-critique rank with lambda 0.8 3047\n",
      "target_item post-critique rank with lambda 0.9 3055\n",
      "target_item post-critique rank with lambda 1 3023\n",
      "cur_iter  8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\tensorflow_cpu\\lib\\site-packages\\scipy\\sparse\\_index.py:126: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_arrayXarray(i, j, x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]\n",
      " ...\n",
      " [ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]]\n",
      "target_item post-critique rank with lambda 0 755\n",
      "target_item post-critique rank with lambda 0.1 837\n",
      "target_item post-critique rank with lambda 0.2 906\n",
      "target_item post-critique rank with lambda 0.3 1024\n",
      "target_item post-critique rank with lambda 0.4 1097\n",
      "target_item post-critique rank with lambda 0.5 1511\n",
      "target_item post-critique rank with lambda 0.6 1428\n",
      "target_item post-critique rank with lambda 0.7 1404\n",
      "target_item post-critique rank with lambda 0.8 1497\n",
      "target_item post-critique rank with lambda 0.9 1555\n",
      "target_item post-critique rank with lambda 1 2936\n",
      "cur_iter  9\n",
      "no more keyphrase available\n",
      "target_item:  968\n",
      "cur_iter  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\tensorflow_cpu\\lib\\site-packages\\scipy\\sparse\\_index.py:126: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_arrayXarray(i, j, x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]\n",
      " ...\n",
      " [ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]]\n",
      "target_item post-critique rank with lambda 0 574\n",
      "target_item post-critique rank with lambda 0.1 372\n",
      "target_item post-critique rank with lambda 0.2 387\n",
      "target_item post-critique rank with lambda 0.3 430\n",
      "target_item post-critique rank with lambda 0.4 738\n",
      "target_item post-critique rank with lambda 0.5 1889\n",
      "target_item post-critique rank with lambda 0.6 3329\n",
      "target_item post-critique rank with lambda 0.7 3220\n",
      "target_item post-critique rank with lambda 0.8 3385\n",
      "target_item post-critique rank with lambda 0.9 2510\n",
      "target_item post-critique rank with lambda 1 3322\n",
      "cur_iter  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\tensorflow_cpu\\lib\\site-packages\\scipy\\sparse\\_index.py:126: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_arrayXarray(i, j, x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]\n",
      " ...\n",
      " [ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]]\n",
      "target_item post-critique rank with lambda 0 574\n",
      "target_item post-critique rank with lambda 0.1 569\n",
      "target_item post-critique rank with lambda 0.2 566\n",
      "target_item post-critique rank with lambda 0.3 368\n",
      "target_item post-critique rank with lambda 0.4 272\n",
      "target_item post-critique rank with lambda 0.5 273\n",
      "target_item post-critique rank with lambda 0.6 203\n",
      "target_item post-critique rank with lambda 0.7 143\n",
      "target_item post-critique rank with lambda 0.8 175\n",
      "target_item post-critique rank with lambda 0.9 165\n",
      "target_item post-critique rank with lambda 1 146\n",
      "cur_iter  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\tensorflow_cpu\\lib\\site-packages\\scipy\\sparse\\_index.py:126: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_arrayXarray(i, j, x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]\n",
      " ...\n",
      " [ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]]\n",
      "target_item post-critique rank with lambda 0 574\n",
      "target_item post-critique rank with lambda 0.1 559\n",
      "target_item post-critique rank with lambda 0.2 548\n",
      "target_item post-critique rank with lambda 0.3 550\n",
      "target_item post-critique rank with lambda 0.4 492\n",
      "target_item post-critique rank with lambda 0.5 501\n",
      "target_item post-critique rank with lambda 0.6 533\n",
      "target_item post-critique rank with lambda 0.7 255\n",
      "target_item post-critique rank with lambda 0.8 254\n",
      "target_item post-critique rank with lambda 0.9 319\n",
      "target_item post-critique rank with lambda 1 320\n",
      "cur_iter  3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\tensorflow_cpu\\lib\\site-packages\\scipy\\sparse\\_index.py:126: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_arrayXarray(i, j, x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]\n",
      " ...\n",
      " [ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]]\n",
      "target_item post-critique rank with lambda 0 574\n",
      "target_item post-critique rank with lambda 0.1 586\n",
      "target_item post-critique rank with lambda 0.2 623\n",
      "target_item post-critique rank with lambda 0.3 686\n",
      "target_item post-critique rank with lambda 0.4 588\n",
      "target_item post-critique rank with lambda 0.5 607\n",
      "target_item post-critique rank with lambda 0.6 866\n",
      "target_item post-critique rank with lambda 0.7 818\n",
      "target_item post-critique rank with lambda 0.8 794\n",
      "target_item post-critique rank with lambda 0.9 797\n",
      "target_item post-critique rank with lambda 1 393\n",
      "cur_iter  4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\tensorflow_cpu\\lib\\site-packages\\scipy\\sparse\\_index.py:126: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_arrayXarray(i, j, x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]\n",
      " ...\n",
      " [ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]]\n",
      "target_item post-critique rank with lambda 0 574\n",
      "target_item post-critique rank with lambda 0.1 600\n",
      "target_item post-critique rank with lambda 0.2 614\n",
      "target_item post-critique rank with lambda 0.3 547\n",
      "target_item post-critique rank with lambda 0.4 443\n",
      "target_item post-critique rank with lambda 0.5 311\n",
      "target_item post-critique rank with lambda 0.6 694\n",
      "target_item post-critique rank with lambda 0.7 620\n",
      "target_item post-critique rank with lambda 0.8 581\n",
      "target_item post-critique rank with lambda 0.9 534\n",
      "target_item post-critique rank with lambda 1 498\n",
      "cur_iter  5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\tensorflow_cpu\\lib\\site-packages\\scipy\\sparse\\_index.py:126: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_arrayXarray(i, j, x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]\n",
      " ...\n",
      " [ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]]\n",
      "target_item post-critique rank with lambda 0 574\n",
      "target_item post-critique rank with lambda 0.1 403\n",
      "target_item post-critique rank with lambda 0.2 416\n",
      "target_item post-critique rank with lambda 0.3 470\n",
      "target_item post-critique rank with lambda 0.4 1107\n",
      "target_item post-critique rank with lambda 0.5 2310\n",
      "target_item post-critique rank with lambda 0.6 2154\n",
      "target_item post-critique rank with lambda 0.7 2094\n",
      "target_item post-critique rank with lambda 0.8 3137\n",
      "target_item post-critique rank with lambda 0.9 3141\n",
      "target_item post-critique rank with lambda 1 3106\n",
      "cur_iter  6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\tensorflow_cpu\\lib\\site-packages\\scipy\\sparse\\_index.py:126: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_arrayXarray(i, j, x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]\n",
      " ...\n",
      " [ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]]\n",
      "target_item post-critique rank with lambda 0 574\n",
      "target_item post-critique rank with lambda 0.1 380\n",
      "target_item post-critique rank with lambda 0.2 406\n",
      "target_item post-critique rank with lambda 0.3 328\n",
      "target_item post-critique rank with lambda 0.4 282\n",
      "target_item post-critique rank with lambda 0.5 70\n",
      "target_item post-critique rank with lambda 0.6 44\n",
      "target_item post-critique rank with lambda 0.7 40\n",
      "target_item post-critique rank with lambda 0.8 32\n",
      "target_item post-critique rank with lambda 0.9 42\n",
      "target_item post-critique rank with lambda 1 40\n",
      "cur_iter  7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\tensorflow_cpu\\lib\\site-packages\\scipy\\sparse\\_index.py:126: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_arrayXarray(i, j, x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]\n",
      " ...\n",
      " [ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]]\n",
      "target_item post-critique rank with lambda 0 574\n",
      "target_item post-critique rank with lambda 0.1 407\n",
      "target_item post-critique rank with lambda 0.2 281\n",
      "target_item post-critique rank with lambda 0.3 136\n",
      "target_item post-critique rank with lambda 0.4 113\n",
      "target_item post-critique rank with lambda 0.5 154\n",
      "target_item post-critique rank with lambda 0.6 94\n",
      "target_item post-critique rank with lambda 0.7 105\n",
      "target_item post-critique rank with lambda 0.8 84\n",
      "target_item post-critique rank with lambda 0.9 75\n",
      "target_item post-critique rank with lambda 1 71\n",
      "cur_iter  8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\tensorflow_cpu\\lib\\site-packages\\scipy\\sparse\\_index.py:126: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_arrayXarray(i, j, x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]\n",
      " ...\n",
      " [ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]]\n",
      "target_item post-critique rank with lambda 0 574\n",
      "target_item post-critique rank with lambda 0.1 625\n",
      "target_item post-critique rank with lambda 0.2 383\n",
      "target_item post-critique rank with lambda 0.3 436\n",
      "target_item post-critique rank with lambda 0.4 439\n",
      "target_item post-critique rank with lambda 0.5 420\n",
      "target_item post-critique rank with lambda 0.6 256\n",
      "target_item post-critique rank with lambda 0.7 263\n",
      "target_item post-critique rank with lambda 0.8 155\n",
      "target_item post-critique rank with lambda 0.9 133\n",
      "target_item post-critique rank with lambda 1 133\n",
      "cur_iter  9\n",
      "no more keyphrase available\n",
      "target_item:  1620\n",
      "wanted_keyphrases is empty\n"
     ]
    }
   ],
   "source": [
    "# Initialize df for storing the experiment\n",
    "\n",
    "# post_ranki is post rank with different lambda ratio for combining pre-post User similarity matrix \n",
    "columns = ['user_id', 'target_item', 'item_name', 'iter', 'pre_rank', \n",
    "           'top_prediction_item_name','critiqued_keyphrase', 'keyphrase_name', \n",
    "           'post_rank0', \n",
    "           'post_rank1', \n",
    "           'post_rank2', \n",
    "           'post_rank3', \n",
    "           'post_rank4', \n",
    "           'post_rank5', \n",
    "           'post_rank6', \n",
    "           'post_rank7', \n",
    "           'post_rank8',\n",
    "           'post_rank9',\n",
    "           'post_rank10',\n",
    "           'num_existing_keyphrases'] \n",
    "df = pd.DataFrame(columns=columns)\n",
    "row = {}\n",
    "\n",
    "#only_with_critiqued_keyphrase\n",
    "for user in range(300,301):\n",
    "    df = single_step_critiquing_experiment(user = user, \n",
    "                           keyphrase_length_threshold = 230, \n",
    "                           max_iteration_threshold = 10,\n",
    "                           k = 50,\n",
    "                           df = df,\n",
    "                           row = row,\n",
    "                           business_df = business_df,\n",
    "                           keyphrases = keyphrases,\n",
    "                           keyphrase_popularity = keyphrase_popularity,\n",
    "                           keyphrase_selection_method = 'random',\n",
    "                           recommend_type = 'all'\n",
    "                           )\n",
    "df.to_csv(single_step_with_avg_path+\"random_all_50user.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>target_item</th>\n",
       "      <th>item_name</th>\n",
       "      <th>iter</th>\n",
       "      <th>pre_rank</th>\n",
       "      <th>top_prediction_item_name</th>\n",
       "      <th>critiqued_keyphrase</th>\n",
       "      <th>keyphrase_name</th>\n",
       "      <th>post_rank0</th>\n",
       "      <th>post_rank1</th>\n",
       "      <th>...</th>\n",
       "      <th>post_rank3</th>\n",
       "      <th>post_rank4</th>\n",
       "      <th>post_rank5</th>\n",
       "      <th>post_rank6</th>\n",
       "      <th>post_rank7</th>\n",
       "      <th>post_rank8</th>\n",
       "      <th>post_rank9</th>\n",
       "      <th>post_rank10</th>\n",
       "      <th>num_existing_keyphrases</th>\n",
       "      <th>post_rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>300</td>\n",
       "      <td>886</td>\n",
       "      <td>b'Wok &amp; Roast Chinese BBQ'</td>\n",
       "      <td>0</td>\n",
       "      <td>755</td>\n",
       "      <td>b'Khao San Road'</td>\n",
       "      <td>223</td>\n",
       "      <td>general tao</td>\n",
       "      <td>755</td>\n",
       "      <td>765</td>\n",
       "      <td>...</td>\n",
       "      <td>371</td>\n",
       "      <td>268</td>\n",
       "      <td>246</td>\n",
       "      <td>301</td>\n",
       "      <td>249</td>\n",
       "      <td>224</td>\n",
       "      <td>196</td>\n",
       "      <td>176</td>\n",
       "      <td>10</td>\n",
       "      <td>[755, 765, 773, 371, 268, 246, 301, 249, 224, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>300</td>\n",
       "      <td>886</td>\n",
       "      <td>b'Wok &amp; Roast Chinese BBQ'</td>\n",
       "      <td>1</td>\n",
       "      <td>755</td>\n",
       "      <td>b'Khao San Road'</td>\n",
       "      <td>27</td>\n",
       "      <td>bbq</td>\n",
       "      <td>755</td>\n",
       "      <td>795</td>\n",
       "      <td>...</td>\n",
       "      <td>424</td>\n",
       "      <td>445</td>\n",
       "      <td>873</td>\n",
       "      <td>811</td>\n",
       "      <td>815</td>\n",
       "      <td>830</td>\n",
       "      <td>847</td>\n",
       "      <td>866</td>\n",
       "      <td>10</td>\n",
       "      <td>[755, 795, 473, 424, 445, 873, 811, 815, 830, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>300</td>\n",
       "      <td>886</td>\n",
       "      <td>b'Wok &amp; Roast Chinese BBQ'</td>\n",
       "      <td>2</td>\n",
       "      <td>755</td>\n",
       "      <td>b'Khao San Road'</td>\n",
       "      <td>60</td>\n",
       "      <td>squid</td>\n",
       "      <td>755</td>\n",
       "      <td>784</td>\n",
       "      <td>...</td>\n",
       "      <td>756</td>\n",
       "      <td>885</td>\n",
       "      <td>1874</td>\n",
       "      <td>2967</td>\n",
       "      <td>2934</td>\n",
       "      <td>2901</td>\n",
       "      <td>2919</td>\n",
       "      <td>2903</td>\n",
       "      <td>10</td>\n",
       "      <td>[755, 784, 783, 756, 885, 1874, 2967, 2934, 29...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>300</td>\n",
       "      <td>886</td>\n",
       "      <td>b'Wok &amp; Roast Chinese BBQ'</td>\n",
       "      <td>3</td>\n",
       "      <td>755</td>\n",
       "      <td>b'Khao San Road'</td>\n",
       "      <td>73</td>\n",
       "      <td>congee</td>\n",
       "      <td>755</td>\n",
       "      <td>774</td>\n",
       "      <td>...</td>\n",
       "      <td>765</td>\n",
       "      <td>816</td>\n",
       "      <td>939</td>\n",
       "      <td>1076</td>\n",
       "      <td>1842</td>\n",
       "      <td>2024</td>\n",
       "      <td>4499</td>\n",
       "      <td>3288</td>\n",
       "      <td>10</td>\n",
       "      <td>[755, 774, 780, 765, 816, 939, 1076, 1842, 202...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>300</td>\n",
       "      <td>886</td>\n",
       "      <td>b'Wok &amp; Roast Chinese BBQ'</td>\n",
       "      <td>4</td>\n",
       "      <td>755</td>\n",
       "      <td>b'Khao San Road'</td>\n",
       "      <td>72</td>\n",
       "      <td>scallop</td>\n",
       "      <td>755</td>\n",
       "      <td>819</td>\n",
       "      <td>...</td>\n",
       "      <td>944</td>\n",
       "      <td>1364</td>\n",
       "      <td>2166</td>\n",
       "      <td>2105</td>\n",
       "      <td>1946</td>\n",
       "      <td>1955</td>\n",
       "      <td>1933</td>\n",
       "      <td>1923</td>\n",
       "      <td>10</td>\n",
       "      <td>[755, 819, 906, 944, 1364, 2166, 2105, 1946, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>300</td>\n",
       "      <td>886</td>\n",
       "      <td>b'Wok &amp; Roast Chinese BBQ'</td>\n",
       "      <td>5</td>\n",
       "      <td>755</td>\n",
       "      <td>b'Khao San Road'</td>\n",
       "      <td>108</td>\n",
       "      <td>duck</td>\n",
       "      <td>755</td>\n",
       "      <td>830</td>\n",
       "      <td>...</td>\n",
       "      <td>2045</td>\n",
       "      <td>1916</td>\n",
       "      <td>1962</td>\n",
       "      <td>4303</td>\n",
       "      <td>3101</td>\n",
       "      <td>3083</td>\n",
       "      <td>3054</td>\n",
       "      <td>3098</td>\n",
       "      <td>10</td>\n",
       "      <td>[755, 830, 928, 2045, 1916, 1962, 4303, 3101, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>300</td>\n",
       "      <td>886</td>\n",
       "      <td>b'Wok &amp; Roast Chinese BBQ'</td>\n",
       "      <td>6</td>\n",
       "      <td>755</td>\n",
       "      <td>b'Khao San Road'</td>\n",
       "      <td>48</td>\n",
       "      <td>burger</td>\n",
       "      <td>755</td>\n",
       "      <td>784</td>\n",
       "      <td>...</td>\n",
       "      <td>945</td>\n",
       "      <td>2129</td>\n",
       "      <td>2197</td>\n",
       "      <td>2027</td>\n",
       "      <td>3059</td>\n",
       "      <td>4151</td>\n",
       "      <td>4140</td>\n",
       "      <td>2975</td>\n",
       "      <td>10</td>\n",
       "      <td>[755, 784, 875, 945, 2129, 2197, 2027, 3059, 4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>300</td>\n",
       "      <td>886</td>\n",
       "      <td>b'Wok &amp; Roast Chinese BBQ'</td>\n",
       "      <td>7</td>\n",
       "      <td>755</td>\n",
       "      <td>b'Khao San Road'</td>\n",
       "      <td>145</td>\n",
       "      <td>markham</td>\n",
       "      <td>755</td>\n",
       "      <td>865</td>\n",
       "      <td>...</td>\n",
       "      <td>1116</td>\n",
       "      <td>2032</td>\n",
       "      <td>3756</td>\n",
       "      <td>3720</td>\n",
       "      <td>3065</td>\n",
       "      <td>3047</td>\n",
       "      <td>3055</td>\n",
       "      <td>3023</td>\n",
       "      <td>10</td>\n",
       "      <td>[755, 865, 1044, 1116, 2032, 3756, 3720, 3065,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>300</td>\n",
       "      <td>886</td>\n",
       "      <td>b'Wok &amp; Roast Chinese BBQ'</td>\n",
       "      <td>8</td>\n",
       "      <td>755</td>\n",
       "      <td>b'Khao San Road'</td>\n",
       "      <td>59</td>\n",
       "      <td>ice cream</td>\n",
       "      <td>755</td>\n",
       "      <td>837</td>\n",
       "      <td>...</td>\n",
       "      <td>1024</td>\n",
       "      <td>1097</td>\n",
       "      <td>1511</td>\n",
       "      <td>1428</td>\n",
       "      <td>1404</td>\n",
       "      <td>1497</td>\n",
       "      <td>1555</td>\n",
       "      <td>2936</td>\n",
       "      <td>10</td>\n",
       "      <td>[755, 837, 906, 1024, 1097, 1511, 1428, 1404, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>300</td>\n",
       "      <td>968</td>\n",
       "      <td>b'Porter Airlines'</td>\n",
       "      <td>0</td>\n",
       "      <td>574</td>\n",
       "      <td>b'Khao San Road'</td>\n",
       "      <td>205</td>\n",
       "      <td>gelato</td>\n",
       "      <td>574</td>\n",
       "      <td>372</td>\n",
       "      <td>...</td>\n",
       "      <td>430</td>\n",
       "      <td>738</td>\n",
       "      <td>1889</td>\n",
       "      <td>3329</td>\n",
       "      <td>3220</td>\n",
       "      <td>3385</td>\n",
       "      <td>2510</td>\n",
       "      <td>3322</td>\n",
       "      <td>10</td>\n",
       "      <td>[574, 372, 387, 430, 738, 1889, 3329, 3220, 33...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>300</td>\n",
       "      <td>968</td>\n",
       "      <td>b'Porter Airlines'</td>\n",
       "      <td>1</td>\n",
       "      <td>574</td>\n",
       "      <td>b'Khao San Road'</td>\n",
       "      <td>163</td>\n",
       "      <td>dog</td>\n",
       "      <td>574</td>\n",
       "      <td>569</td>\n",
       "      <td>...</td>\n",
       "      <td>368</td>\n",
       "      <td>272</td>\n",
       "      <td>273</td>\n",
       "      <td>203</td>\n",
       "      <td>143</td>\n",
       "      <td>175</td>\n",
       "      <td>165</td>\n",
       "      <td>146</td>\n",
       "      <td>10</td>\n",
       "      <td>[574, 569, 566, 368, 272, 273, 203, 143, 175, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>300</td>\n",
       "      <td>968</td>\n",
       "      <td>b'Porter Airlines'</td>\n",
       "      <td>2</td>\n",
       "      <td>574</td>\n",
       "      <td>b'Khao San Road'</td>\n",
       "      <td>105</td>\n",
       "      <td>latte</td>\n",
       "      <td>574</td>\n",
       "      <td>559</td>\n",
       "      <td>...</td>\n",
       "      <td>550</td>\n",
       "      <td>492</td>\n",
       "      <td>501</td>\n",
       "      <td>533</td>\n",
       "      <td>255</td>\n",
       "      <td>254</td>\n",
       "      <td>319</td>\n",
       "      <td>320</td>\n",
       "      <td>10</td>\n",
       "      <td>[574, 559, 548, 550, 492, 501, 533, 255, 254, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>300</td>\n",
       "      <td>968</td>\n",
       "      <td>b'Porter Airlines'</td>\n",
       "      <td>3</td>\n",
       "      <td>574</td>\n",
       "      <td>b'Khao San Road'</td>\n",
       "      <td>42</td>\n",
       "      <td>sandwich</td>\n",
       "      <td>574</td>\n",
       "      <td>586</td>\n",
       "      <td>...</td>\n",
       "      <td>686</td>\n",
       "      <td>588</td>\n",
       "      <td>607</td>\n",
       "      <td>866</td>\n",
       "      <td>818</td>\n",
       "      <td>794</td>\n",
       "      <td>797</td>\n",
       "      <td>393</td>\n",
       "      <td>10</td>\n",
       "      <td>[574, 586, 623, 686, 588, 607, 866, 818, 794, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>300</td>\n",
       "      <td>968</td>\n",
       "      <td>b'Porter Airlines'</td>\n",
       "      <td>4</td>\n",
       "      <td>574</td>\n",
       "      <td>b'Khao San Road'</td>\n",
       "      <td>38</td>\n",
       "      <td>chocolate</td>\n",
       "      <td>574</td>\n",
       "      <td>600</td>\n",
       "      <td>...</td>\n",
       "      <td>547</td>\n",
       "      <td>443</td>\n",
       "      <td>311</td>\n",
       "      <td>694</td>\n",
       "      <td>620</td>\n",
       "      <td>581</td>\n",
       "      <td>534</td>\n",
       "      <td>498</td>\n",
       "      <td>10</td>\n",
       "      <td>[574, 600, 614, 547, 443, 311, 694, 620, 581, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>300</td>\n",
       "      <td>968</td>\n",
       "      <td>b'Porter Airlines'</td>\n",
       "      <td>5</td>\n",
       "      <td>574</td>\n",
       "      <td>b'Khao San Road'</td>\n",
       "      <td>69</td>\n",
       "      <td>cookie</td>\n",
       "      <td>574</td>\n",
       "      <td>403</td>\n",
       "      <td>...</td>\n",
       "      <td>470</td>\n",
       "      <td>1107</td>\n",
       "      <td>2310</td>\n",
       "      <td>2154</td>\n",
       "      <td>2094</td>\n",
       "      <td>3137</td>\n",
       "      <td>3141</td>\n",
       "      <td>3106</td>\n",
       "      <td>10</td>\n",
       "      <td>[574, 403, 416, 470, 1107, 2310, 2154, 2094, 3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>300</td>\n",
       "      <td>968</td>\n",
       "      <td>b'Porter Airlines'</td>\n",
       "      <td>6</td>\n",
       "      <td>574</td>\n",
       "      <td>b'Khao San Road'</td>\n",
       "      <td>103</td>\n",
       "      <td>fruit</td>\n",
       "      <td>574</td>\n",
       "      <td>380</td>\n",
       "      <td>...</td>\n",
       "      <td>328</td>\n",
       "      <td>282</td>\n",
       "      <td>70</td>\n",
       "      <td>44</td>\n",
       "      <td>40</td>\n",
       "      <td>32</td>\n",
       "      <td>42</td>\n",
       "      <td>40</td>\n",
       "      <td>10</td>\n",
       "      <td>[574, 380, 406, 328, 282, 70, 44, 40, 32, 42, 40]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>300</td>\n",
       "      <td>968</td>\n",
       "      <td>b'Porter Airlines'</td>\n",
       "      <td>7</td>\n",
       "      <td>574</td>\n",
       "      <td>b'Khao San Road'</td>\n",
       "      <td>65</td>\n",
       "      <td>espresso</td>\n",
       "      <td>574</td>\n",
       "      <td>407</td>\n",
       "      <td>...</td>\n",
       "      <td>136</td>\n",
       "      <td>113</td>\n",
       "      <td>154</td>\n",
       "      <td>94</td>\n",
       "      <td>105</td>\n",
       "      <td>84</td>\n",
       "      <td>75</td>\n",
       "      <td>71</td>\n",
       "      <td>10</td>\n",
       "      <td>[574, 407, 281, 136, 113, 154, 94, 105, 84, 75...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>300</td>\n",
       "      <td>968</td>\n",
       "      <td>b'Porter Airlines'</td>\n",
       "      <td>8</td>\n",
       "      <td>574</td>\n",
       "      <td>b'Khao San Road'</td>\n",
       "      <td>230</td>\n",
       "      <td>alcoholic beverage</td>\n",
       "      <td>574</td>\n",
       "      <td>625</td>\n",
       "      <td>...</td>\n",
       "      <td>436</td>\n",
       "      <td>439</td>\n",
       "      <td>420</td>\n",
       "      <td>256</td>\n",
       "      <td>263</td>\n",
       "      <td>155</td>\n",
       "      <td>133</td>\n",
       "      <td>133</td>\n",
       "      <td>10</td>\n",
       "      <td>[574, 625, 383, 436, 439, 420, 256, 263, 155, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id target_item                   item_name iter pre_rank  \\\n",
       "0      300         886  b'Wok & Roast Chinese BBQ'    0      755   \n",
       "1      300         886  b'Wok & Roast Chinese BBQ'    1      755   \n",
       "2      300         886  b'Wok & Roast Chinese BBQ'    2      755   \n",
       "3      300         886  b'Wok & Roast Chinese BBQ'    3      755   \n",
       "4      300         886  b'Wok & Roast Chinese BBQ'    4      755   \n",
       "5      300         886  b'Wok & Roast Chinese BBQ'    5      755   \n",
       "6      300         886  b'Wok & Roast Chinese BBQ'    6      755   \n",
       "7      300         886  b'Wok & Roast Chinese BBQ'    7      755   \n",
       "8      300         886  b'Wok & Roast Chinese BBQ'    8      755   \n",
       "9      300         968          b'Porter Airlines'    0      574   \n",
       "10     300         968          b'Porter Airlines'    1      574   \n",
       "11     300         968          b'Porter Airlines'    2      574   \n",
       "12     300         968          b'Porter Airlines'    3      574   \n",
       "13     300         968          b'Porter Airlines'    4      574   \n",
       "14     300         968          b'Porter Airlines'    5      574   \n",
       "15     300         968          b'Porter Airlines'    6      574   \n",
       "16     300         968          b'Porter Airlines'    7      574   \n",
       "17     300         968          b'Porter Airlines'    8      574   \n",
       "\n",
       "   top_prediction_item_name critiqued_keyphrase      keyphrase_name  \\\n",
       "0          b'Khao San Road'                 223         general tao   \n",
       "1          b'Khao San Road'                  27                 bbq   \n",
       "2          b'Khao San Road'                  60               squid   \n",
       "3          b'Khao San Road'                  73              congee   \n",
       "4          b'Khao San Road'                  72             scallop   \n",
       "5          b'Khao San Road'                 108                duck   \n",
       "6          b'Khao San Road'                  48              burger   \n",
       "7          b'Khao San Road'                 145             markham   \n",
       "8          b'Khao San Road'                  59           ice cream   \n",
       "9          b'Khao San Road'                 205              gelato   \n",
       "10         b'Khao San Road'                 163                 dog   \n",
       "11         b'Khao San Road'                 105               latte   \n",
       "12         b'Khao San Road'                  42            sandwich   \n",
       "13         b'Khao San Road'                  38           chocolate   \n",
       "14         b'Khao San Road'                  69              cookie   \n",
       "15         b'Khao San Road'                 103               fruit   \n",
       "16         b'Khao San Road'                  65            espresso   \n",
       "17         b'Khao San Road'                 230  alcoholic beverage   \n",
       "\n",
       "   post_rank0 post_rank1                        ...                          \\\n",
       "0         755        765                        ...                           \n",
       "1         755        795                        ...                           \n",
       "2         755        784                        ...                           \n",
       "3         755        774                        ...                           \n",
       "4         755        819                        ...                           \n",
       "5         755        830                        ...                           \n",
       "6         755        784                        ...                           \n",
       "7         755        865                        ...                           \n",
       "8         755        837                        ...                           \n",
       "9         574        372                        ...                           \n",
       "10        574        569                        ...                           \n",
       "11        574        559                        ...                           \n",
       "12        574        586                        ...                           \n",
       "13        574        600                        ...                           \n",
       "14        574        403                        ...                           \n",
       "15        574        380                        ...                           \n",
       "16        574        407                        ...                           \n",
       "17        574        625                        ...                           \n",
       "\n",
       "   post_rank3 post_rank4 post_rank5 post_rank6 post_rank7 post_rank8  \\\n",
       "0         371        268        246        301        249        224   \n",
       "1         424        445        873        811        815        830   \n",
       "2         756        885       1874       2967       2934       2901   \n",
       "3         765        816        939       1076       1842       2024   \n",
       "4         944       1364       2166       2105       1946       1955   \n",
       "5        2045       1916       1962       4303       3101       3083   \n",
       "6         945       2129       2197       2027       3059       4151   \n",
       "7        1116       2032       3756       3720       3065       3047   \n",
       "8        1024       1097       1511       1428       1404       1497   \n",
       "9         430        738       1889       3329       3220       3385   \n",
       "10        368        272        273        203        143        175   \n",
       "11        550        492        501        533        255        254   \n",
       "12        686        588        607        866        818        794   \n",
       "13        547        443        311        694        620        581   \n",
       "14        470       1107       2310       2154       2094       3137   \n",
       "15        328        282         70         44         40         32   \n",
       "16        136        113        154         94        105         84   \n",
       "17        436        439        420        256        263        155   \n",
       "\n",
       "   post_rank9 post_rank10 num_existing_keyphrases  \\\n",
       "0         196         176                      10   \n",
       "1         847         866                      10   \n",
       "2        2919        2903                      10   \n",
       "3        4499        3288                      10   \n",
       "4        1933        1923                      10   \n",
       "5        3054        3098                      10   \n",
       "6        4140        2975                      10   \n",
       "7        3055        3023                      10   \n",
       "8        1555        2936                      10   \n",
       "9        2510        3322                      10   \n",
       "10        165         146                      10   \n",
       "11        319         320                      10   \n",
       "12        797         393                      10   \n",
       "13        534         498                      10   \n",
       "14       3141        3106                      10   \n",
       "15         42          40                      10   \n",
       "16         75          71                      10   \n",
       "17        133         133                      10   \n",
       "\n",
       "                                            post_rank  \n",
       "0   [755, 765, 773, 371, 268, 246, 301, 249, 224, ...  \n",
       "1   [755, 795, 473, 424, 445, 873, 811, 815, 830, ...  \n",
       "2   [755, 784, 783, 756, 885, 1874, 2967, 2934, 29...  \n",
       "3   [755, 774, 780, 765, 816, 939, 1076, 1842, 202...  \n",
       "4   [755, 819, 906, 944, 1364, 2166, 2105, 1946, 1...  \n",
       "5   [755, 830, 928, 2045, 1916, 1962, 4303, 3101, ...  \n",
       "6   [755, 784, 875, 945, 2129, 2197, 2027, 3059, 4...  \n",
       "7   [755, 865, 1044, 1116, 2032, 3756, 3720, 3065,...  \n",
       "8   [755, 837, 906, 1024, 1097, 1511, 1428, 1404, ...  \n",
       "9   [574, 372, 387, 430, 738, 1889, 3329, 3220, 33...  \n",
       "10  [574, 569, 566, 368, 272, 273, 203, 143, 175, ...  \n",
       "11  [574, 559, 548, 550, 492, 501, 533, 255, 254, ...  \n",
       "12  [574, 586, 623, 686, 588, 607, 866, 818, 794, ...  \n",
       "13  [574, 600, 614, 547, 443, 311, 694, 620, 581, ...  \n",
       "14  [574, 403, 416, 470, 1107, 2310, 2154, 2094, 3...  \n",
       "15  [574, 380, 406, 328, 282, 70, 44, 40, 32, 42, 40]  \n",
       "16  [574, 407, 281, 136, 113, 154, 94, 105, 84, 75...  \n",
       "17  [574, 625, 383, 436, 439, 420, 256, 263, 155, ...  \n",
       "\n",
       "[18 rows x 21 columns]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>target_item</th>\n",
       "      <th>item_name</th>\n",
       "      <th>iter</th>\n",
       "      <th>pre_rank</th>\n",
       "      <th>top_prediction_item_name</th>\n",
       "      <th>critiqued_keyphrase</th>\n",
       "      <th>keyphrase_name</th>\n",
       "      <th>post_rank0</th>\n",
       "      <th>post_rank1</th>\n",
       "      <th>...</th>\n",
       "      <th>post_rank3</th>\n",
       "      <th>post_rank4</th>\n",
       "      <th>post_rank5</th>\n",
       "      <th>post_rank6</th>\n",
       "      <th>post_rank7</th>\n",
       "      <th>post_rank8</th>\n",
       "      <th>post_rank9</th>\n",
       "      <th>post_rank10</th>\n",
       "      <th>num_existing_keyphrases</th>\n",
       "      <th>post_rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>300</td>\n",
       "      <td>886</td>\n",
       "      <td>b'Wok &amp; Roast Chinese BBQ'</td>\n",
       "      <td>0</td>\n",
       "      <td>755</td>\n",
       "      <td>b'Khao San Road'</td>\n",
       "      <td>59</td>\n",
       "      <td>ice cream</td>\n",
       "      <td>285</td>\n",
       "      <td>311</td>\n",
       "      <td>...</td>\n",
       "      <td>389</td>\n",
       "      <td>409</td>\n",
       "      <td>471</td>\n",
       "      <td>477</td>\n",
       "      <td>473</td>\n",
       "      <td>505</td>\n",
       "      <td>523</td>\n",
       "      <td>2321</td>\n",
       "      <td>10</td>\n",
       "      <td>[285, 311, 342, 389, 409, 471, 477, 473, 505, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>300</td>\n",
       "      <td>886</td>\n",
       "      <td>b'Wok &amp; Roast Chinese BBQ'</td>\n",
       "      <td>1</td>\n",
       "      <td>755</td>\n",
       "      <td>b'Khao San Road'</td>\n",
       "      <td>73</td>\n",
       "      <td>congee</td>\n",
       "      <td>48</td>\n",
       "      <td>60</td>\n",
       "      <td>...</td>\n",
       "      <td>77</td>\n",
       "      <td>91</td>\n",
       "      <td>108</td>\n",
       "      <td>121</td>\n",
       "      <td>143</td>\n",
       "      <td>150</td>\n",
       "      <td>2247</td>\n",
       "      <td>2247</td>\n",
       "      <td>10</td>\n",
       "      <td>[48, 60, 66, 77, 91, 108, 121, 143, 150, 2247,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>300</td>\n",
       "      <td>886</td>\n",
       "      <td>b'Wok &amp; Roast Chinese BBQ'</td>\n",
       "      <td>2</td>\n",
       "      <td>755</td>\n",
       "      <td>b'Khao San Road'</td>\n",
       "      <td>115</td>\n",
       "      <td>lobster</td>\n",
       "      <td>145</td>\n",
       "      <td>152</td>\n",
       "      <td>...</td>\n",
       "      <td>144</td>\n",
       "      <td>151</td>\n",
       "      <td>187</td>\n",
       "      <td>190</td>\n",
       "      <td>207</td>\n",
       "      <td>226</td>\n",
       "      <td>239</td>\n",
       "      <td>247</td>\n",
       "      <td>10</td>\n",
       "      <td>[145, 152, 139, 144, 151, 187, 190, 207, 226, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>300</td>\n",
       "      <td>886</td>\n",
       "      <td>b'Wok &amp; Roast Chinese BBQ'</td>\n",
       "      <td>3</td>\n",
       "      <td>755</td>\n",
       "      <td>b'Khao San Road'</td>\n",
       "      <td>223</td>\n",
       "      <td>general tao</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>10</td>\n",
       "      <td>[10, 8, 12, 8, 10, 11, 15, 15, 14, 14, 14]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>300</td>\n",
       "      <td>886</td>\n",
       "      <td>b'Wok &amp; Roast Chinese BBQ'</td>\n",
       "      <td>4</td>\n",
       "      <td>755</td>\n",
       "      <td>b'Khao San Road'</td>\n",
       "      <td>60</td>\n",
       "      <td>squid</td>\n",
       "      <td>139</td>\n",
       "      <td>160</td>\n",
       "      <td>...</td>\n",
       "      <td>157</td>\n",
       "      <td>188</td>\n",
       "      <td>293</td>\n",
       "      <td>2205</td>\n",
       "      <td>2264</td>\n",
       "      <td>2235</td>\n",
       "      <td>2237</td>\n",
       "      <td>2235</td>\n",
       "      <td>10</td>\n",
       "      <td>[139, 160, 158, 157, 188, 293, 2205, 2264, 223...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>300</td>\n",
       "      <td>968</td>\n",
       "      <td>b'Porter Airlines'</td>\n",
       "      <td>0</td>\n",
       "      <td>574</td>\n",
       "      <td>b'Khao San Road'</td>\n",
       "      <td>42</td>\n",
       "      <td>sandwich</td>\n",
       "      <td>267</td>\n",
       "      <td>279</td>\n",
       "      <td>...</td>\n",
       "      <td>318</td>\n",
       "      <td>292</td>\n",
       "      <td>308</td>\n",
       "      <td>406</td>\n",
       "      <td>380</td>\n",
       "      <td>371</td>\n",
       "      <td>368</td>\n",
       "      <td>214</td>\n",
       "      <td>10</td>\n",
       "      <td>[267, 279, 296, 318, 292, 308, 406, 380, 371, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>300</td>\n",
       "      <td>968</td>\n",
       "      <td>b'Porter Airlines'</td>\n",
       "      <td>1</td>\n",
       "      <td>574</td>\n",
       "      <td>b'Khao San Road'</td>\n",
       "      <td>103</td>\n",
       "      <td>fruit</td>\n",
       "      <td>255</td>\n",
       "      <td>185</td>\n",
       "      <td>...</td>\n",
       "      <td>170</td>\n",
       "      <td>148</td>\n",
       "      <td>36</td>\n",
       "      <td>24</td>\n",
       "      <td>20</td>\n",
       "      <td>16</td>\n",
       "      <td>24</td>\n",
       "      <td>23</td>\n",
       "      <td>10</td>\n",
       "      <td>[255, 185, 199, 170, 148, 36, 24, 20, 16, 24, 23]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>300</td>\n",
       "      <td>968</td>\n",
       "      <td>b'Porter Airlines'</td>\n",
       "      <td>2</td>\n",
       "      <td>574</td>\n",
       "      <td>b'Khao San Road'</td>\n",
       "      <td>38</td>\n",
       "      <td>chocolate</td>\n",
       "      <td>273</td>\n",
       "      <td>287</td>\n",
       "      <td>...</td>\n",
       "      <td>268</td>\n",
       "      <td>231</td>\n",
       "      <td>183</td>\n",
       "      <td>351</td>\n",
       "      <td>331</td>\n",
       "      <td>322</td>\n",
       "      <td>297</td>\n",
       "      <td>282</td>\n",
       "      <td>10</td>\n",
       "      <td>[273, 287, 300, 268, 231, 183, 351, 331, 322, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>300</td>\n",
       "      <td>968</td>\n",
       "      <td>b'Porter Airlines'</td>\n",
       "      <td>3</td>\n",
       "      <td>574</td>\n",
       "      <td>b'Khao San Road'</td>\n",
       "      <td>230</td>\n",
       "      <td>alcoholic beverage</td>\n",
       "      <td>25</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>27</td>\n",
       "      <td>33</td>\n",
       "      <td>33</td>\n",
       "      <td>26</td>\n",
       "      <td>23</td>\n",
       "      <td>19</td>\n",
       "      <td>16</td>\n",
       "      <td>17</td>\n",
       "      <td>10</td>\n",
       "      <td>[25, 30, 23, 27, 33, 33, 26, 23, 19, 16, 17]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>300</td>\n",
       "      <td>968</td>\n",
       "      <td>b'Porter Airlines'</td>\n",
       "      <td>4</td>\n",
       "      <td>574</td>\n",
       "      <td>b'Khao San Road'</td>\n",
       "      <td>65</td>\n",
       "      <td>espresso</td>\n",
       "      <td>117</td>\n",
       "      <td>84</td>\n",
       "      <td>...</td>\n",
       "      <td>38</td>\n",
       "      <td>41</td>\n",
       "      <td>67</td>\n",
       "      <td>48</td>\n",
       "      <td>49</td>\n",
       "      <td>43</td>\n",
       "      <td>39</td>\n",
       "      <td>36</td>\n",
       "      <td>10</td>\n",
       "      <td>[117, 84, 66, 38, 41, 67, 48, 49, 43, 39, 36]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  user_id target_item                   item_name iter pre_rank  \\\n",
       "0     300         886  b'Wok & Roast Chinese BBQ'    0      755   \n",
       "1     300         886  b'Wok & Roast Chinese BBQ'    1      755   \n",
       "2     300         886  b'Wok & Roast Chinese BBQ'    2      755   \n",
       "3     300         886  b'Wok & Roast Chinese BBQ'    3      755   \n",
       "4     300         886  b'Wok & Roast Chinese BBQ'    4      755   \n",
       "5     300         968          b'Porter Airlines'    0      574   \n",
       "6     300         968          b'Porter Airlines'    1      574   \n",
       "7     300         968          b'Porter Airlines'    2      574   \n",
       "8     300         968          b'Porter Airlines'    3      574   \n",
       "9     300         968          b'Porter Airlines'    4      574   \n",
       "\n",
       "  top_prediction_item_name critiqued_keyphrase      keyphrase_name post_rank0  \\\n",
       "0         b'Khao San Road'                  59           ice cream        285   \n",
       "1         b'Khao San Road'                  73              congee         48   \n",
       "2         b'Khao San Road'                 115             lobster        145   \n",
       "3         b'Khao San Road'                 223         general tao         10   \n",
       "4         b'Khao San Road'                  60               squid        139   \n",
       "5         b'Khao San Road'                  42            sandwich        267   \n",
       "6         b'Khao San Road'                 103               fruit        255   \n",
       "7         b'Khao San Road'                  38           chocolate        273   \n",
       "8         b'Khao San Road'                 230  alcoholic beverage         25   \n",
       "9         b'Khao San Road'                  65            espresso        117   \n",
       "\n",
       "  post_rank1                        ...                         post_rank3  \\\n",
       "0        311                        ...                                389   \n",
       "1         60                        ...                                 77   \n",
       "2        152                        ...                                144   \n",
       "3          8                        ...                                  8   \n",
       "4        160                        ...                                157   \n",
       "5        279                        ...                                318   \n",
       "6        185                        ...                                170   \n",
       "7        287                        ...                                268   \n",
       "8         30                        ...                                 27   \n",
       "9         84                        ...                                 38   \n",
       "\n",
       "  post_rank4 post_rank5 post_rank6 post_rank7 post_rank8 post_rank9  \\\n",
       "0        409        471        477        473        505        523   \n",
       "1         91        108        121        143        150       2247   \n",
       "2        151        187        190        207        226        239   \n",
       "3         10         11         15         15         14         14   \n",
       "4        188        293       2205       2264       2235       2237   \n",
       "5        292        308        406        380        371        368   \n",
       "6        148         36         24         20         16         24   \n",
       "7        231        183        351        331        322        297   \n",
       "8         33         33         26         23         19         16   \n",
       "9         41         67         48         49         43         39   \n",
       "\n",
       "  post_rank10 num_existing_keyphrases  \\\n",
       "0        2321                      10   \n",
       "1        2247                      10   \n",
       "2         247                      10   \n",
       "3          14                      10   \n",
       "4        2235                      10   \n",
       "5         214                      10   \n",
       "6          23                      10   \n",
       "7         282                      10   \n",
       "8          17                      10   \n",
       "9          36                      10   \n",
       "\n",
       "                                           post_rank  \n",
       "0  [285, 311, 342, 389, 409, 471, 477, 473, 505, ...  \n",
       "1  [48, 60, 66, 77, 91, 108, 121, 143, 150, 2247,...  \n",
       "2  [145, 152, 139, 144, 151, 187, 190, 207, 226, ...  \n",
       "3         [10, 8, 12, 8, 10, 11, 15, 15, 14, 14, 14]  \n",
       "4  [139, 160, 158, 157, 188, 293, 2205, 2264, 223...  \n",
       "5  [267, 279, 296, 318, 292, 308, 406, 380, 371, ...  \n",
       "6  [255, 185, 199, 170, 148, 36, 24, 20, 16, 24, 23]  \n",
       "7  [273, 287, 300, 268, 231, 183, 351, 331, 322, ...  \n",
       "8       [25, 30, 23, 27, 33, 33, 26, 23, 19, 16, 17]  \n",
       "9      [117, 84, 66, 38, 41, 67, 48, 49, 43, 39, 36]  \n",
       "\n",
       "[10 rows x 21 columns]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pop with normalization\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>target_item</th>\n",
       "      <th>item_name</th>\n",
       "      <th>iter</th>\n",
       "      <th>pre_rank</th>\n",
       "      <th>top_prediction_item_name</th>\n",
       "      <th>critiqued_keyphrase</th>\n",
       "      <th>keyphrase_name</th>\n",
       "      <th>post_rank0</th>\n",
       "      <th>post_rank1</th>\n",
       "      <th>...</th>\n",
       "      <th>post_rank3</th>\n",
       "      <th>post_rank4</th>\n",
       "      <th>post_rank5</th>\n",
       "      <th>post_rank6</th>\n",
       "      <th>post_rank7</th>\n",
       "      <th>post_rank8</th>\n",
       "      <th>post_rank9</th>\n",
       "      <th>post_rank10</th>\n",
       "      <th>num_existing_keyphrases</th>\n",
       "      <th>post_rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>300</td>\n",
       "      <td>886</td>\n",
       "      <td>b'Wok &amp; Roast Chinese BBQ'</td>\n",
       "      <td>0</td>\n",
       "      <td>755</td>\n",
       "      <td>b'Khao San Road'</td>\n",
       "      <td>59</td>\n",
       "      <td>ice cream</td>\n",
       "      <td>285</td>\n",
       "      <td>311</td>\n",
       "      <td>...</td>\n",
       "      <td>389</td>\n",
       "      <td>409</td>\n",
       "      <td>471</td>\n",
       "      <td>477</td>\n",
       "      <td>473</td>\n",
       "      <td>505</td>\n",
       "      <td>523</td>\n",
       "      <td>2321</td>\n",
       "      <td>10</td>\n",
       "      <td>[285, 311, 342, 389, 409, 471, 477, 473, 505, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>300</td>\n",
       "      <td>886</td>\n",
       "      <td>b'Wok &amp; Roast Chinese BBQ'</td>\n",
       "      <td>1</td>\n",
       "      <td>755</td>\n",
       "      <td>b'Khao San Road'</td>\n",
       "      <td>223</td>\n",
       "      <td>general tao</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>10</td>\n",
       "      <td>[10, 8, 12, 8, 10, 11, 15, 15, 14, 14, 14]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>300</td>\n",
       "      <td>886</td>\n",
       "      <td>b'Wok &amp; Roast Chinese BBQ'</td>\n",
       "      <td>2</td>\n",
       "      <td>755</td>\n",
       "      <td>b'Khao San Road'</td>\n",
       "      <td>145</td>\n",
       "      <td>markham</td>\n",
       "      <td>139</td>\n",
       "      <td>179</td>\n",
       "      <td>...</td>\n",
       "      <td>323</td>\n",
       "      <td>510</td>\n",
       "      <td>2321</td>\n",
       "      <td>2350</td>\n",
       "      <td>2297</td>\n",
       "      <td>2298</td>\n",
       "      <td>2298</td>\n",
       "      <td>2295</td>\n",
       "      <td>10</td>\n",
       "      <td>[139, 179, 264, 323, 510, 2321, 2350, 2297, 22...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>300</td>\n",
       "      <td>886</td>\n",
       "      <td>b'Wok &amp; Roast Chinese BBQ'</td>\n",
       "      <td>3</td>\n",
       "      <td>755</td>\n",
       "      <td>b'Khao San Road'</td>\n",
       "      <td>60</td>\n",
       "      <td>squid</td>\n",
       "      <td>139</td>\n",
       "      <td>160</td>\n",
       "      <td>...</td>\n",
       "      <td>157</td>\n",
       "      <td>188</td>\n",
       "      <td>293</td>\n",
       "      <td>2205</td>\n",
       "      <td>2264</td>\n",
       "      <td>2235</td>\n",
       "      <td>2237</td>\n",
       "      <td>2235</td>\n",
       "      <td>10</td>\n",
       "      <td>[139, 160, 158, 157, 188, 293, 2205, 2264, 223...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>300</td>\n",
       "      <td>886</td>\n",
       "      <td>b'Wok &amp; Roast Chinese BBQ'</td>\n",
       "      <td>4</td>\n",
       "      <td>755</td>\n",
       "      <td>b'Khao San Road'</td>\n",
       "      <td>72</td>\n",
       "      <td>scallop</td>\n",
       "      <td>141</td>\n",
       "      <td>163</td>\n",
       "      <td>...</td>\n",
       "      <td>206</td>\n",
       "      <td>255</td>\n",
       "      <td>320</td>\n",
       "      <td>316</td>\n",
       "      <td>320</td>\n",
       "      <td>328</td>\n",
       "      <td>328</td>\n",
       "      <td>332</td>\n",
       "      <td>10</td>\n",
       "      <td>[141, 163, 179, 206, 255, 320, 316, 320, 328, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>300</td>\n",
       "      <td>968</td>\n",
       "      <td>b'Porter Airlines'</td>\n",
       "      <td>0</td>\n",
       "      <td>574</td>\n",
       "      <td>b'Khao San Road'</td>\n",
       "      <td>38</td>\n",
       "      <td>chocolate</td>\n",
       "      <td>273</td>\n",
       "      <td>287</td>\n",
       "      <td>...</td>\n",
       "      <td>268</td>\n",
       "      <td>231</td>\n",
       "      <td>183</td>\n",
       "      <td>351</td>\n",
       "      <td>331</td>\n",
       "      <td>322</td>\n",
       "      <td>297</td>\n",
       "      <td>282</td>\n",
       "      <td>10</td>\n",
       "      <td>[273, 287, 300, 268, 231, 183, 351, 331, 322, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>300</td>\n",
       "      <td>968</td>\n",
       "      <td>b'Porter Airlines'</td>\n",
       "      <td>1</td>\n",
       "      <td>574</td>\n",
       "      <td>b'Khao San Road'</td>\n",
       "      <td>105</td>\n",
       "      <td>latte</td>\n",
       "      <td>335</td>\n",
       "      <td>333</td>\n",
       "      <td>...</td>\n",
       "      <td>333</td>\n",
       "      <td>305</td>\n",
       "      <td>307</td>\n",
       "      <td>330</td>\n",
       "      <td>182</td>\n",
       "      <td>183</td>\n",
       "      <td>220</td>\n",
       "      <td>219</td>\n",
       "      <td>10</td>\n",
       "      <td>[335, 333, 331, 333, 305, 307, 330, 182, 183, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>300</td>\n",
       "      <td>968</td>\n",
       "      <td>b'Porter Airlines'</td>\n",
       "      <td>2</td>\n",
       "      <td>574</td>\n",
       "      <td>b'Khao San Road'</td>\n",
       "      <td>69</td>\n",
       "      <td>cookie</td>\n",
       "      <td>115</td>\n",
       "      <td>90</td>\n",
       "      <td>...</td>\n",
       "      <td>112</td>\n",
       "      <td>202</td>\n",
       "      <td>295</td>\n",
       "      <td>289</td>\n",
       "      <td>279</td>\n",
       "      <td>3508</td>\n",
       "      <td>3507</td>\n",
       "      <td>3505</td>\n",
       "      <td>10</td>\n",
       "      <td>[115, 90, 98, 112, 202, 295, 289, 279, 3508, 3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>300</td>\n",
       "      <td>968</td>\n",
       "      <td>b'Porter Airlines'</td>\n",
       "      <td>3</td>\n",
       "      <td>574</td>\n",
       "      <td>b'Khao San Road'</td>\n",
       "      <td>230</td>\n",
       "      <td>alcoholic beverage</td>\n",
       "      <td>25</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>27</td>\n",
       "      <td>33</td>\n",
       "      <td>33</td>\n",
       "      <td>26</td>\n",
       "      <td>23</td>\n",
       "      <td>19</td>\n",
       "      <td>16</td>\n",
       "      <td>17</td>\n",
       "      <td>10</td>\n",
       "      <td>[25, 30, 23, 27, 33, 33, 26, 23, 19, 16, 17]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>300</td>\n",
       "      <td>968</td>\n",
       "      <td>b'Porter Airlines'</td>\n",
       "      <td>4</td>\n",
       "      <td>574</td>\n",
       "      <td>b'Khao San Road'</td>\n",
       "      <td>143</td>\n",
       "      <td>station</td>\n",
       "      <td>200</td>\n",
       "      <td>140</td>\n",
       "      <td>...</td>\n",
       "      <td>102</td>\n",
       "      <td>75</td>\n",
       "      <td>82</td>\n",
       "      <td>70</td>\n",
       "      <td>68</td>\n",
       "      <td>79</td>\n",
       "      <td>75</td>\n",
       "      <td>74</td>\n",
       "      <td>10</td>\n",
       "      <td>[200, 140, 145, 102, 75, 82, 70, 68, 79, 75, 74]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  user_id target_item                   item_name iter pre_rank  \\\n",
       "0     300         886  b'Wok & Roast Chinese BBQ'    0      755   \n",
       "1     300         886  b'Wok & Roast Chinese BBQ'    1      755   \n",
       "2     300         886  b'Wok & Roast Chinese BBQ'    2      755   \n",
       "3     300         886  b'Wok & Roast Chinese BBQ'    3      755   \n",
       "4     300         886  b'Wok & Roast Chinese BBQ'    4      755   \n",
       "5     300         968          b'Porter Airlines'    0      574   \n",
       "6     300         968          b'Porter Airlines'    1      574   \n",
       "7     300         968          b'Porter Airlines'    2      574   \n",
       "8     300         968          b'Porter Airlines'    3      574   \n",
       "9     300         968          b'Porter Airlines'    4      574   \n",
       "\n",
       "  top_prediction_item_name critiqued_keyphrase      keyphrase_name post_rank0  \\\n",
       "0         b'Khao San Road'                  59           ice cream        285   \n",
       "1         b'Khao San Road'                 223         general tao         10   \n",
       "2         b'Khao San Road'                 145             markham        139   \n",
       "3         b'Khao San Road'                  60               squid        139   \n",
       "4         b'Khao San Road'                  72             scallop        141   \n",
       "5         b'Khao San Road'                  38           chocolate        273   \n",
       "6         b'Khao San Road'                 105               latte        335   \n",
       "7         b'Khao San Road'                  69              cookie        115   \n",
       "8         b'Khao San Road'                 230  alcoholic beverage         25   \n",
       "9         b'Khao San Road'                 143             station        200   \n",
       "\n",
       "  post_rank1                        ...                         post_rank3  \\\n",
       "0        311                        ...                                389   \n",
       "1          8                        ...                                  8   \n",
       "2        179                        ...                                323   \n",
       "3        160                        ...                                157   \n",
       "4        163                        ...                                206   \n",
       "5        287                        ...                                268   \n",
       "6        333                        ...                                333   \n",
       "7         90                        ...                                112   \n",
       "8         30                        ...                                 27   \n",
       "9        140                        ...                                102   \n",
       "\n",
       "  post_rank4 post_rank5 post_rank6 post_rank7 post_rank8 post_rank9  \\\n",
       "0        409        471        477        473        505        523   \n",
       "1         10         11         15         15         14         14   \n",
       "2        510       2321       2350       2297       2298       2298   \n",
       "3        188        293       2205       2264       2235       2237   \n",
       "4        255        320        316        320        328        328   \n",
       "5        231        183        351        331        322        297   \n",
       "6        305        307        330        182        183        220   \n",
       "7        202        295        289        279       3508       3507   \n",
       "8         33         33         26         23         19         16   \n",
       "9         75         82         70         68         79         75   \n",
       "\n",
       "  post_rank10 num_existing_keyphrases  \\\n",
       "0        2321                      10   \n",
       "1          14                      10   \n",
       "2        2295                      10   \n",
       "3        2235                      10   \n",
       "4         332                      10   \n",
       "5         282                      10   \n",
       "6         219                      10   \n",
       "7        3505                      10   \n",
       "8          17                      10   \n",
       "9          74                      10   \n",
       "\n",
       "                                           post_rank  \n",
       "0  [285, 311, 342, 389, 409, 471, 477, 473, 505, ...  \n",
       "1         [10, 8, 12, 8, 10, 11, 15, 15, 14, 14, 14]  \n",
       "2  [139, 179, 264, 323, 510, 2321, 2350, 2297, 22...  \n",
       "3  [139, 160, 158, 157, 188, 293, 2205, 2264, 223...  \n",
       "4  [141, 163, 179, 206, 255, 320, 316, 320, 328, ...  \n",
       "5  [273, 287, 300, 268, 231, 183, 351, 331, 322, ...  \n",
       "6  [335, 333, 331, 333, 305, 307, 330, 182, 183, ...  \n",
       "7  [115, 90, 98, 112, 202, 295, 289, 279, 3508, 3...  \n",
       "8       [25, 30, 23, 27, 33, 33, 26, 23, 19, 16, 17]  \n",
       "9   [200, 140, 145, 102, 75, 82, 70, 68, 79, 75, 74]  \n",
       "\n",
       "[10 rows x 21 columns]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# without normalization\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot HR vs. Performance for 3 keyphrase selection method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Utlilty func\n",
    "def hr_at_k(df, k):\n",
    "    \"\"\"\n",
    "    Given the above dataframe, calculate the avg pre and post hit rate at k \n",
    "    \"\"\"\n",
    "    pre_hit = np.where(df['pre_rank']<k)[0]\n",
    "    post_hit = np.where(df['post_rank']<k)[0]\n",
    "    pre_hr = len(pre_hit)/len(df)\n",
    "    post_hr = len(post_hit)/len(df)\n",
    "    return pre_hr, post_hr\n",
    "\n",
    "def get_hr(l=5, rang = 200):\n",
    "    \"\"\"\n",
    "    Get the hit rate at different rang, with different lambda value\n",
    "    Output in the form of list\n",
    "    \"\"\"\n",
    "    pre_hr_list = []\n",
    "    post_hr_list = []\n",
    "    for k in range(1,rang):\n",
    "        pre_hr,post_hr = hr_at_k(df,4, k)\n",
    "        pre_hr_list.append(pre_hr)\n",
    "        post_hr_list.append(post_hr)\n",
    "    return pre_hr_list,post_hr_list\n",
    "\n",
    "def get_hr_of_all_lambda(methods):\n",
    "    for method in methods:\n",
    "        post_rates = []\n",
    "        for i in range(9):\n",
    "            _,a = get_hr(l=i)\n",
    "            diff.append(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pre_hr_list,b = get_hr(l=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_hr_performance():\n",
    "    plt.figure(figsize=(12,12))\n",
    "    for \n",
    "    plt.plot(np.arange(len(pre_hr_list)), pre_hr_list)\n",
    "    plt.plot(np.arange(len(pre_hr_list)), a1)\n",
    "    plt.plot(np.arange(len(pre_hr_list)), a2)\n",
    "    plt.plot(np.arange(len(pre_hr_list)), a3)\n",
    "    plt.plot(np.arange(len(pre_hr_list)), a4)\n",
    "    plt.plot(np.arange(len(pre_hr_list)), a5)\n",
    "    plt.plot(np.arange(len(pre_hr_list)), a6)\n",
    "\n",
    "    # plt.xticks(np.arange(len(k_list)), k_list)\n",
    "    plt.xlabel('k')\n",
    "    plt.ylabel('HR@K')\n",
    "    plt.legend(['Pre-Critiquing','Random', 'Random_Upper','Pop','Pop_Upper','Diff','Diff_Upper'])\n",
    "    plt.show()\n",
    "    plt.savefig('../figs/three_keyphrase_selection_methods_with_upper_bound_0104')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
