{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/litos/opt/anaconda3/envs/tensorflow_cpu/lib/python36.zip',\n",
       " '/Users/litos/opt/anaconda3/envs/tensorflow_cpu/lib/python3.6',\n",
       " '/Users/litos/opt/anaconda3/envs/tensorflow_cpu/lib/python3.6/lib-dynload',\n",
       " '',\n",
       " '/Users/litos/opt/anaconda3/envs/tensorflow_cpu/lib/python3.6/site-packages',\n",
       " '/Users/litos/opt/anaconda3/envs/tensorflow_cpu/lib/python3.6/site-packages/IPython/extensions',\n",
       " '/Users/litos/.ipython']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gurobipy import *\n",
    "\n",
    "from scipy.sparse import csr_matrix, load_npz, save_npz\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import normalize\n",
    "from collections import *\n",
    "import datetime\n",
    "import json\n",
    "import pandas as pd\n",
    "import time\n",
    "# import yaml\n",
    "import scipy.sparse as sparse\n",
    "from ast import literal_eval\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.utils.extmath import randomized_svd\n",
    "\n",
    "from scipy.optimize import minimize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Original Data\n",
    "df_train = pd.read_csv('../../data/yelp/Train.csv',encoding='latin-1')\n",
    "# df_valid = pd.read_csv('../../data/yelp/Valid.csv',encoding='latin-1')\n",
    "# df_test = pd.read_csv('../../data/yelp/Test.csv',encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyphrases = pd.read_csv('../../data/yelp/KeyPhrases.csv')['Phrases'].tolist()\n",
    "keyphrase_popularity = np.loadtxt('../data/yelp/'+'keyphrase_popularity.txt', dtype=int)\n",
    "\n",
    "# Load U-I Data \n",
    "rtrain = load_npz(\"../../data/yelp/Rtrain.npz\")\n",
    "rvalid = load_npz(\"../../data/yelp/Rvalid.npz\")\n",
    "rtest = load_npz(\"../../data/yelp/Rtest.npz\")\n",
    "\n",
    "# Load user/item keyphrase data\n",
    "U_K = load_npz(\"../../data/yelp/U_K.npz\")\n",
    "I_K = load_npz(\"../../data/yelp/I_K.npz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_I_K(df, row_name = 'ItemIndex', shape = (3668,75)):\n",
    "    rows = []\n",
    "    cols = []\n",
    "    vals = []\n",
    "    for i in tqdm(range(df.shape[0])):\n",
    "        key_vector = literal_eval(df['keyVector'][i])\n",
    "        rows.extend([df[row_name][i]]*len(key_vector)) ## Item index\n",
    "        cols.extend(key_vector) ## Keyword Index\n",
    "        vals.extend(np.array([1]*len(key_vector)))\n",
    "    return csr_matrix((vals, (rows, cols)), shape=shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLREC \n",
    "def inhour(elapsed):\n",
    "    return time.strftime('%H:%M:%S', time.gmtime(elapsed))\n",
    "\n",
    "def plrec(matrix_train, iteration=4, lamb=80, rank=200, seed=1):\n",
    "    \"\"\"\n",
    "    Function used to achieve generalized projected lrec w/o item-attribute embedding\n",
    "    :param matrix_train: user-item matrix with shape m*n\n",
    "    :param iteration: number of power iterations in randomized svd\n",
    "    :param lamb: parameter of penalty\n",
    "    :param rank: latent dimension size\n",
    "    :param seed: the seed of the pseudo random number generator to use when shuffling the data\n",
    "    :return: prediction in sparse matrix\n",
    "    \"\"\"\n",
    "    print (\"Randomized SVD\")\n",
    "    start_time = time.time()\n",
    "    P, sigma, Qt = randomized_svd(matrix_train,\n",
    "                                  n_components=rank,\n",
    "                                  n_iter=iteration,\n",
    "                                  random_state=seed)\n",
    "\n",
    "    RQ = matrix_train.dot(sparse.csc_matrix(Qt.T*np.sqrt(sigma)))\n",
    "\n",
    "    print(\"Elapsed: {}\".format(inhour(time.time() - start_time)))\n",
    "\n",
    "    print (\"Closed-Form Linear Optimization\")\n",
    "    start_time = time.time()\n",
    "    pre_inv = RQ.T.dot(RQ) + lamb * sparse.identity(rank, dtype=np.float32)\n",
    "    inverse = sparse.linalg.inv(pre_inv.tocsc())\n",
    "    Y = inverse.dot(RQ.T).dot(matrix_train)\n",
    "    print(\"Elapsed: {}\".format(inhour(time.time() - start_time)))\n",
    "\n",
    "    return np.array(RQ.todense()), np.array(Y.todense()), None\n",
    "\n",
    "# def predict_vector(rating_vector, train_vector, remove_train=True):\n",
    "#     dim = len(rating_vector)\n",
    "#     candidate_index = np.argpartition(-rating_vector, dim-1)[:dim]\n",
    "#     prediction_items = candidate_index[rating_vector[candidate_index].argsort()[::-1]]\n",
    "    \n",
    "#     if remove_train:\n",
    "#         return np.delete(prediction_items, np.isin(prediction_items, train_vector.nonzero()[1]).nonzero()[0])\n",
    "#     else:\n",
    "#         return prediction_items\n",
    "\n",
    "    \n",
    "def predict_scores(matrix_U, matrix_V, bias=None,\n",
    "                   penalize = False,\n",
    "                   keyphrase_freq = I_K, \n",
    "                   critiqued_keyphrase = 0, \n",
    "                   matrix_Train = rtrain,\n",
    "                   alpha = 0):\n",
    "    prediction = matrix_U.dot(matrix_V.T)\n",
    "    # Penalize\n",
    "    if penalize == True:\n",
    "        items_with_keyphrase = np.ravel(keyphrase_freq.T[critiqued_keyphrase].nonzero()[1])\n",
    "        items_without_keyphrase = np.setdiff1d(np.arange(matrix_Train.shape[1]), items_with_keyphrase)\n",
    "        prediction[items_without_keyphrase] = alpha # penalize\n",
    "    \n",
    "    return prediction\n",
    "\n",
    "def predict_vector(rating_vector, train_vector, remove_train=True):\n",
    "    dim = len(rating_vector)\n",
    "    candidate_index = np.argpartition(-rating_vector, dim-1)[:dim]\n",
    "    prediction_items = candidate_index[rating_vector[candidate_index].argsort()[::-1]]\n",
    "    \n",
    "    if remove_train:\n",
    "        return np.delete(prediction_items, np.isin(prediction_items, train_vector.nonzero()[1]).nonzero()[0])\n",
    "    else:\n",
    "        return prediction_items\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial Prediction\n",
    "def predict_scores(matrix_U, matrix_V, bias=None,\n",
    "                   penalize = False,\n",
    "                   keyphrase_freq = I_K, \n",
    "                   critiqued_keyphrase = 0, \n",
    "                   matrix_Train = rtrain,\n",
    "                   alpha = 0):\n",
    "    \n",
    "    prediction = matrix_U.dot(matrix_V.T)\n",
    "    # Penalize\n",
    "    if penalize == True:\n",
    "        items_with_keyphrase = np.ravel(keyphrase_freq.T[critiqued_keyphrase].nonzero()[1])\n",
    "        items_without_keyphrase = np.setdiff1d(np.arange(matrix_Train.shape[1]), items_with_keyphrase)\n",
    "        prediction[items_without_keyphrase] = alpha # penalize\n",
    "    \n",
    "    return prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keyphrase Selection Helpers\n",
    "def get_valid_keyphrases(keyphrase_freq,top_recommendations,item = None,threshold=50,mutiple_keyphrases_en = False, top_items = None):\n",
    "    \"\"\"\n",
    "    Wrapper function to get either top 1 or top n keyphrases\n",
    "    \"\"\"\n",
    "    if mutiple_keyphrases_en:\n",
    "        top_keyphrases = []\n",
    "        for item in top_items:\n",
    "            top_keyphrases.extend(get_valid_keyphrases_for_one_item(keyphrase_freq,top_recommendations,item,threshold=threshold))\n",
    "        return np.ravel(list(set(top_keyphrases))) # remove duplicate and reformat to np array\n",
    "    else:\n",
    "        return get_valid_keyphrases_for_one_item(keyphrase_freq,top_recommendations,item,threshold=threshold)\n",
    "\n",
    "def get_valid_keyphrases_for_one_item(keyphrase_freq,top_recommendations, item,threshold=50):\n",
    "    \"\"\"\n",
    "    Get keyphrases of item that make sense\n",
    "    E.g. if the item has fewer than threshold=50 keyphrases, get all of them\n",
    "    otherwise get top 50 keyphrases\n",
    "    \"\"\"\n",
    "    keyphrase_length = len(keyphrase_freq[item].nonzero()[1])\n",
    "    if keyphrase_length<threshold:\n",
    "        return keyphrase_freq[item].nonzero()[1]\n",
    "    else:\n",
    "        keyphrases = np.ravel(keyphrase_freq[top_recommendations[0]].todense())\n",
    "        top_keyphrases = np.argsort(keyphrases)[::-1][:threshold]\n",
    "        return top_keyphrases\n",
    "    \n",
    "# For keyphrase selecting method # 3 \"diff\" \n",
    "def get_item_keyphrase_freq(keyphrase_freq,item):\n",
    "    \"\"\"\n",
    "    Get item's keyphrase frequency \n",
    "    \"\"\"\n",
    "    count = keyphrase_freq[item].todense()\n",
    "    return count/np.sum(count)\n",
    "\n",
    "def get_keyphrase_popularity(df,keyphrases):\n",
    "    \"\"\"\n",
    "    Get keyphrase popularity (count) from dataframe\n",
    "    \"\"\"\n",
    "    keyphrase_popularity = np.zeros(len(keyphrases)) #initialize\n",
    "    for i in range(len(df)):\n",
    "        keyphrase_vector = literal_eval(df['keyVector'][i])\n",
    "        keyphrase_popularity[keyphrase_vector] += 1 # count\n",
    "    return keyphrase_popularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One hot encoding of critiquing\n",
    "def get_critiqued_UK(user_keyphrase_frequency,user_index,critiqued_keyphrase):\n",
    "    \"\"\"\n",
    "    user_keyphrase_frequency is the U_K matrix (csr sparse matrix)\n",
    "    return the one-hot encoding of the critique\n",
    "    \"\"\"\n",
    "    U_K_cp = user_keyphrase_frequency.copy()\n",
    "    U_K_cp[user_index] = 0\n",
    "    U_K_cp[user_index,critiqued_keyphrase] = 1\n",
    "    return U_K_cp\n",
    "\n",
    "def project_one_hot_encoding(reg, user_keyphrase_frequency,user_index = 0,critiqued_keyphrase = 0, normalize_en = True):\n",
    "    \"\"\"\n",
    "    Return the projection on user_sim space from one-hot encoding of critiqued keyphrase\n",
    "    The res[user_index] should be target embedding row\n",
    "    \"\"\"\n",
    "    critiqued_matrix = get_critiqued_UK(user_keyphrase_frequency, user_index, critiqued_keyphrase)\n",
    "    res = reg.predict(critiqued_matrix)\n",
    "    if normalize_en:\n",
    "        res = normalize((res))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upper bound method \n",
    "def get_all_affected_items(wanted_keyphrases,keyphrase_freq):\n",
    "    res = []\n",
    "    for keyphrase in wanted_keyphrases:\n",
    "        items = np.ravel(keyphrase_freq.T[keyphrase].nonzero()[1])\n",
    "        res.extend(items)\n",
    "    return np.array(list(set(res)))\n",
    "    \n",
    "def select_only_wanted_keyphrase(top_recommendations, wanted_keyphrases, keyphrase_freq, matrix_Train = rtrain):\n",
    "    all_items_with_keyphrases = get_all_affected_items(wanted_keyphrases,keyphrase_freq)\n",
    "    affected_items = np.setdiff1d(np.arange(matrix_Train.shape[1]), all_items_with_keyphrases) # Get all other keyphrases\n",
    "    top_recommendations[~np.in1d(top_recommendations, affected_items)]\n",
    "    return top_recommendations\n",
    "\n",
    "def pruning(prediction_score, \n",
    "           wanted_keyphrases_random, \n",
    "           top_recommendations, \n",
    "           keyphrase_freq, \n",
    "           matrix_Train = rtrain,\n",
    "           alpha = 0):\n",
    "    items_with_keyphrase = get_all_affected_items(wanted_keyphrases_random, keyphrase_freq)\n",
    "    #Return the unique values in ar1 that are not in ar2.\n",
    "    items_without_keyphrase = np.setdiff1d(np.arange(matrix_Train.shape[1]), items_with_keyphrase)\n",
    "#     print (items_without_keyphrase)\n",
    "    print (sum(prediction_score[items_without_keyphrase]))\n",
    "    score = np.copy(prediction_score)\n",
    "    score[items_without_keyphrase] = alpha # penalize\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function for getting restaurant info from ItemIndex\n",
    "def get_business_df(path = \"../../data/yelp/business.json\" ):\n",
    "    with open(path,encoding=\"utf8\") as json_file:\n",
    "        data = json_file.readlines()\n",
    "        data = list(map(json.loads, data))\n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def get_restaurant_info(business_df, business_id, name = True, review_count = True, stars = True ):\n",
    "    output_list = {}\n",
    "    row_idx = int(business_df.index[business_df['business_id'] == business_id].tolist()[0])\n",
    "    if name == True:\n",
    "        output_list['name'] = business_df['name'][row_idx].encode('utf-8').strip()\n",
    "    if review_count == True:\n",
    "        output_list['review_count'] = business_df['review_count'][row_idx]\n",
    "    if stars == True:\n",
    "        output_list['stars'] = business_df['stars'][row_idx] \n",
    "    return output_list\n",
    "\n",
    "# def get_businessid_from_Itemindex(ItemIndex_list, itemindex):\n",
    "#     return ItemIndex_list['business_id'].tolist()[itemindex]\n",
    "\n",
    "def get_restaurant_name(df_train, business_df, ItemIndex):\n",
    "    rows = np.where(df_train['ItemIndex'] == ItemIndex)\n",
    "    if len(rows)!= 0:\n",
    "        business_id = df_train.loc[rows[0][0]]['business_id']\n",
    "        item_info = get_restaurant_info(business_df, business_id)\n",
    "        return item_info['name']\n",
    "    return \"NOT_FOUND\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evluation \n",
    "def recallk(vector_true_dense, hits, **unused):\n",
    "    hits = len(hits.nonzero()[0])\n",
    "    return float(hits)/len(vector_true_dense)\n",
    "\n",
    "def precisionk(vector_predict, hits, **unused):\n",
    "    hits = len(hits.nonzero()[0])\n",
    "    return float(hits)/len(vector_predict)\n",
    "\n",
    "\n",
    "def average_precisionk(vector_predict, hits, **unused):\n",
    "    precisions = np.cumsum(hits, dtype=np.float32)/range(1, len(vector_predict)+1)\n",
    "    return np.mean(precisions)\n",
    "\n",
    "\n",
    "def r_precision(vector_true_dense, vector_predict, **unused):\n",
    "    vector_predict_short = vector_predict[:len(vector_true_dense)]\n",
    "    hits = len(np.isin(vector_predict_short, vector_true_dense).nonzero()[0])\n",
    "    return float(hits)/len(vector_true_dense)\n",
    "\n",
    "\n",
    "def _dcg_support(size):\n",
    "    arr = np.arange(1, size+1)+1\n",
    "    return 1./np.log2(arr)\n",
    "\n",
    "\n",
    "def ndcg(vector_true_dense, vector_predict, hits):\n",
    "    idcg = np.sum(_dcg_support(len(vector_true_dense)))\n",
    "    dcg_base = _dcg_support(len(vector_predict))\n",
    "    dcg_base[np.logical_not(hits)] = 0\n",
    "    dcg = np.sum(dcg_base)\n",
    "    return dcg/idcg\n",
    "\n",
    "\n",
    "def click(hits, **unused):\n",
    "    first_hit = next((i for i, x in enumerate(hits) if x), None)\n",
    "    if first_hit is None:\n",
    "        return 5\n",
    "    else:\n",
    "        return first_hit/10\n",
    "\n",
    "\n",
    "def evaluate(matrix_Predict, matrix_Test, metric_names =['R-Precision', 'NDCG', 'Precision', 'Recall', 'MAP'], atK = [5, 10, 15, 20, 50], analytical=False):\n",
    "    \"\"\"\n",
    "    :param matrix_U: Latent representations of users, for LRecs it is RQ, for ALSs it is U\n",
    "    :param matrix_V: Latent representations of items, for LRecs it is Q, for ALSs it is V\n",
    "    :param matrix_Train: Rating matrix for training, features.\n",
    "    :param matrix_Test: Rating matrix for evaluation, true labels.\n",
    "    :param k: Top K retrieval\n",
    "    :param metric_names: Evaluation metrics\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    global_metrics = {\n",
    "        \"R-Precision\": r_precision,\n",
    "        \"NDCG\": ndcg,\n",
    "        \"Clicks\": click\n",
    "    }\n",
    "\n",
    "    local_metrics = {\n",
    "        \"Precision\": precisionk,\n",
    "        \"Recall\": recallk,\n",
    "        \"MAP\": average_precisionk\n",
    "    }\n",
    "\n",
    "    output = dict()\n",
    "\n",
    "    num_users = matrix_Predict.shape[0]\n",
    "\n",
    "    for k in atK:\n",
    "\n",
    "        local_metric_names = list(set(metric_names).intersection(local_metrics.keys()))\n",
    "        results = {name: [] for name in local_metric_names}\n",
    "        topK_Predict = matrix_Predict[:, :k]\n",
    "\n",
    "        for user_index in tqdm(range(topK_Predict.shape[0])):\n",
    "            vector_predict = topK_Predict[user_index]\n",
    "            if len(vector_predict.nonzero()[0]) > 0:\n",
    "                vector_true = matrix_Test[user_index]\n",
    "                vector_true_dense = vector_true.nonzero()[1]\n",
    "                hits = np.isin(vector_predict, vector_true_dense)\n",
    "\n",
    "                if vector_true_dense.size > 0:\n",
    "                    for name in local_metric_names:\n",
    "                        results[name].append(local_metrics[name](vector_true_dense=vector_true_dense,\n",
    "                                                                 vector_predict=vector_predict,\n",
    "                                                                 hits=hits))\n",
    "\n",
    "        results_summary = dict()\n",
    "        if analytical:\n",
    "            for name in local_metric_names:\n",
    "                results_summary['{0}@{1}'.format(name, k)] = results[name]\n",
    "        else:\n",
    "            for name in local_metric_names:\n",
    "                results_summary['{0}@{1}'.format(name, k)] = (np.average(results[name]),\n",
    "                                                              1.96*np.std(results[name])/np.sqrt(num_users))\n",
    "        output.update(results_summary)\n",
    "\n",
    "    global_metric_names = list(set(metric_names).intersection(global_metrics.keys()))\n",
    "    results = {name: [] for name in global_metric_names}\n",
    "\n",
    "    topK_Predict = matrix_Predict[:]\n",
    "\n",
    "    for user_index in tqdm(range(topK_Predict.shape[0])):\n",
    "        vector_predict = topK_Predict[user_index]\n",
    "\n",
    "        if len(vector_predict.nonzero()[0]) > 0:\n",
    "            vector_true = matrix_Test[user_index]\n",
    "            vector_true_dense = vector_true.nonzero()[1]\n",
    "            hits = np.isin(vector_predict, vector_true_dense)\n",
    "\n",
    "            # if user_index == 1:\n",
    "            #     import ipdb;\n",
    "            #     ipdb.set_trace()\n",
    "\n",
    "            if vector_true_dense.size > 0:\n",
    "                for name in global_metric_names:\n",
    "                    results[name].append(global_metrics[name](vector_true_dense=vector_true_dense,\n",
    "                                                              vector_predict=vector_predict,\n",
    "                                                              hits=hits))\n",
    "\n",
    "    results_summary = dict()\n",
    "    if analytical:\n",
    "        for name in global_metric_names:\n",
    "            results_summary[name] = results[name]\n",
    "    else:\n",
    "        for name in global_metric_names:\n",
    "            results_summary[name] = (np.average(results[name]), 1.96*np.std(results[name])/np.sqrt(num_users))\n",
    "    output.update(results_summary)\n",
    "\n",
    "    return output\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Critiquing Pipline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "business_df = get_business_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyphrase_popularity = np.loadtxt('../data/yelp/'+'keyphrase_popularity.txt', dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Randomized SVD\n",
      "Elapsed: 00:00:00\n",
      "Closed-Form Linear Optimization\n",
      "Elapsed: 00:00:00\n"
     ]
    }
   ],
   "source": [
    "Y, RQt, Bias = plrec(rtrain,\n",
    "                    iteration = 10,\n",
    "                    lamb = 200,\n",
    "                    rank = 200)\n",
    "RQ = RQt.T\n",
    "reg = LinearRegression().fit(normalize(U_K), Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up dataframe \n",
    "\n",
    "# post_ranki is post rank with different lambda ratio for combining pre-post User similarity matrix \n",
    "\n",
    "columns = ['user_id', 'target_item', 'item_name', 'iter', 'pre_rank', \n",
    "           'top_prediction_item_name',\n",
    "           'post_rank_random_all',\n",
    "           'post_rank_random_upper',\n",
    "           'random_scores',\n",
    "           'post_rank_pop_all',\n",
    "           'post_rank_pop_upper',\n",
    "           'pop_scores',\n",
    "           'post_rank_diff_all',\n",
    "           'post_rank_diff_upper',\n",
    "           'diff_scores',\n",
    "           'critiqued_keyphrase_random',\n",
    "           'keyphrase_name_random',\n",
    "           'critiqued_keyphrase_pop',\n",
    "           'keyphrase_name_pop',\n",
    "           'critiqued_keyphrase_diff',\n",
    "           'keyphrase_name_diff',\n",
    "           'num_existing_keyphrases',\n",
    "           'pure_pruning_rank'] \n",
    "df = pd.DataFrame(columns=columns)\n",
    "row = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rating Objective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Average(initial_prediction_u, keyphrase_freq, affected_items, unaffected_items, num_keyphrases, query, test_user, item_latent, reg, all_equal = True):\n",
    "    critiqued_vector = np.zeros(keyphrase_freq.shape[1])\n",
    "    \n",
    "    for q in query:\n",
    "        critiqued_vector[q] = 1\n",
    "#         critiqued_vector[q] = keyphrase_freq[test_user,q]\n",
    "        \n",
    "    num_critiques = len(query)\n",
    "    \n",
    "    # Get item latent for updating prediction\n",
    "    W2 = reg.coef_\n",
    "    W = item_latent.dot(W2)\n",
    "    \n",
    "    optimal_lambda = 1 # weight all critiquing equally\n",
    "    lambdas = [optimal_lambda]*num_critiques\n",
    "    \n",
    "    # Record lambda values \n",
    "    for k in range(num_critiques):\n",
    "        critiqued_vector[query[k]] *= optimal_lambda\n",
    "\n",
    "    critique_score = predict_scores(matrix_U=reg.predict(critiqued_vector.reshape(1, -1)),\n",
    "                                    matrix_V=item_latent)\n",
    "\n",
    "    if all_equal:\n",
    "        # weight initial and each critiquing equally \n",
    "        new_prediction = initial_prediction_u/(num_critiques) + critique_score.flatten()\n",
    "    else:\n",
    "        # weight intial and combined critiquing equally\n",
    "        new_prediction = initial_prediction_u + critique_score.flatten() \n",
    "#     print (len(new_prediction))\n",
    "    return new_prediction, lambdas   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LP1SimplifiedOptimize(initial_prediction_u, keyphrase_freq, affected_items, unaffected_items, num_keyphrases, query, test_user, item_latent, reg):\n",
    "\n",
    "    critiqued_vector = np.zeros(keyphrase_freq.shape[1])\n",
    "\n",
    "    for q in query:\n",
    "        critiqued_vector[q] = 1 # set critiqued/boosted keyphrase to 1\n",
    "#         critiqued_vector[q] = -keyphrase_freq[test_user][q]\n",
    "\n",
    "    num_critiques = len(query)\n",
    "\n",
    "    W2 = reg.coef_\n",
    "    W = item_latent.dot(W2)\n",
    "\n",
    "    num_affected_items = len(affected_items)\n",
    "    num_unaffected_items = len(unaffected_items)\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Model\n",
    "    m = Model(\"LP1Simplified\") # Create gurobi model with name\n",
    "\n",
    "    # Assignment variables\n",
    "    lambs = []\n",
    "\n",
    "    for k in range(num_critiques):\n",
    "        lambs.append(m.addVar(lb=-1,\n",
    "                              ub=1,\n",
    "                              vtype=GRB.CONTINUOUS,\n",
    "                              name=\"lamb%d\" % query[k]))\n",
    "\n",
    "    m.setObjective(quicksum(initial_prediction_u[affected_item] * num_unaffected_items + quicksum(lambs[k] * critiqued_vector[query[k]] * W[affected_item][query[k]] * num_unaffected_items for k in range(num_critiques)) for affected_item in affected_items) - quicksum(initial_prediction_u[unaffected_item] * num_affected_items + quicksum(lambs[k] * critiqued_vector[query[k]] * W[unaffected_item][query[k]] * num_affected_items for k in range(num_critiques)) for unaffected_item in unaffected_items), GRB.MINIMIZE)\n",
    "\n",
    "    # Optimize\n",
    "    m.optimize()\n",
    "\n",
    "    print(\"Elapsed: {}\".format(inhour(time.time() - start_time)))\n",
    "\n",
    "    lambdas = []\n",
    "    for k in range(num_critiques):\n",
    "        optimal_lambda = m.getVars()[k].X\n",
    "        lambdas.append(optimal_lambda)\n",
    "        critiqued_vector[query[k]] *= optimal_lambda\n",
    "\n",
    "    modified_user_laten = reg.predict(critiqued_vector.reshape(1, -1)) + self.Y\n",
    "    new_prediction = predict_scores(matrix_U=modified_user_laten,\n",
    "                                    matrix_V=item_latent)\n",
    "#     critique_score = predict_scores(matrix_U=reg.predict(critiqued_vector.reshape(1, -1)),\n",
    "#                                     matrix_V=item_latent)\n",
    "#     new_prediction = initial_prediction_u + critique_score.flatten()\n",
    "\n",
    "    return new_prediction, lambdas\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LP1SumToOneOptimize(initial_prediction_u, keyphrase_freq, affected_items, unaffected_items, num_keyphrases, query, test_user, item_latent, reg):\n",
    "\n",
    "    critiqued_vector = np.zeros(keyphrase_freq.shape[1])\n",
    "\n",
    "    for q in query:\n",
    "        critiqued_vector[q] = 1 # set critiqued/boosted keyphrase to 1\n",
    "#         critiqued_vector[q] = -keyphrase_freq[test_user][q]\n",
    "\n",
    "    num_critiques = len(query)\n",
    "\n",
    "    W2 = reg.coef_\n",
    "    W = item_latent.dot(W2)\n",
    "\n",
    "    num_affected_items = len(affected_items)\n",
    "    num_unaffected_items = len(unaffected_items)\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Model\n",
    "    m = Model(\"LP1SumToOneOptimize\")\n",
    "\n",
    "    # Assignment variables\n",
    "    lambs = []\n",
    "    for k in range(1+num_critiques):\n",
    "        lambs.append(m.addVar(lb=0,\n",
    "                              ub=1,\n",
    "                              vtype=GRB.CONTINUOUS,\n",
    "                              name=\"lamb%d\" % k))\n",
    "\n",
    "    m.addConstr((sum(lambs[k] for k in range(1+num_critiques)) == 1), name=\"sum_to_one\")\n",
    "\n",
    "    m.setObjective(quicksum(lambs[0] * initial_prediction_u[affected_item] * num_unaffected_items + quicksum(lambs[k+1] * critiqued_vector[query[k]] * W[affected_item][query[k]] * num_unaffected_items for k in range(num_critiques)) for affected_item in affected_items) - quicksum(lambs[0] * initial_prediction_u[unaffected_item] * num_affected_items + quicksum(lambs[k+1] * critiqued_vector[query[k]] * W[unaffected_item][query[k]] * num_affected_items for k in range(num_critiques)) for unaffected_item in unaffected_items), GRB.MINIMIZE)\n",
    "\n",
    "    # Optimize\n",
    "    m.optimize()\n",
    "\n",
    "    print(\"Elapsed: {}\".format(inhour(time.time() - start_time)))\n",
    "\n",
    "    lambdas = []\n",
    "    for k in range(1+num_critiques):\n",
    "        optimal_lambda = m.getVars()[k].X\n",
    "        lambdas.append(optimal_lambda)\n",
    "\n",
    "    for k in range(num_critiques):\n",
    "        critiqued_vector[query[k]] *= lambdas[k+1]\n",
    "\n",
    "    critique_score = predict_scores(matrix_U=reg.predict(critiqued_vector.reshape(1, -1)),\n",
    "                                    matrix_V=item_latent)\n",
    "    new_prediction = lambdas[0]*initial_prediction_u + critique_score.flatten()\n",
    "\n",
    "    return new_prediction, lambdas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LP1Simplified(object):\n",
    "    def __init__(self, keyphrase_freq, item_keyphrase_freq, row, matrix_Train, matrix_Test, test_users,\n",
    "                 target_ranks, num_items_sampled, num_keyphrases, df,\n",
    "                 max_iteration_threshold, keyphrase_popularity, dataset_name,\n",
    "                 model, parameters_row, keyphrases_names, keyphrase_selection_method, max_wanted_keyphrase, **unused):\n",
    "        self.keyphrase_freq = keyphrase_freq\n",
    "        self.item_keyphrase_freq = item_keyphrase_freq\n",
    "        self.row = row\n",
    "        self.matrix_Train = matrix_Train\n",
    "        self.num_users, self.num_items = matrix_Train.shape\n",
    "        self.matrix_Test = matrix_Test\n",
    "        self.test_users = test_users\n",
    "        self.target_ranks = target_ranks\n",
    "        self.num_items_sampled = num_items_sampled\n",
    "        self.num_keyphrases = num_keyphrases\n",
    "        self.df = df\n",
    "        self.max_iteration_threshold = max_iteration_threshold\n",
    "        self.keyphrase_popularity = keyphrase_popularity\n",
    "        self.dataset_name = dataset_name\n",
    "        self.model = model\n",
    "        self.parameters_row = parameters_row\n",
    "        self.keyphrase_selection_method = keyphrase_selection_method\n",
    "        self.max_wanted_keyphrase = max_wanted_keyphrase\n",
    "        \n",
    "        \n",
    "        self.keyphrases_names = keyphrases_names\n",
    "\n",
    "    def start_critiquing(self):\n",
    "#         self.get_initial_predictions() # No need to do it every time\n",
    "        self.RQ = RQ\n",
    "        Yt = Y.T \n",
    "        self.Y = Y\n",
    "\n",
    "        self.reg = reg\n",
    "\n",
    "        self.prediction_scores = predict_scores(matrix_U=self.RQ,\n",
    "                                                matrix_V=self.Y,\n",
    "                                                bias=Bias).T\n",
    "        \n",
    "        for user in self.test_users:\n",
    "            # User id starts from 0\n",
    "            self.row['user_id'] = user\n",
    "            \n",
    "            initial_prediction_items = predict_vector(rating_vector=self.prediction_scores[user],\n",
    "                                                            train_vector=self.matrix_Train[user],\n",
    "                                                            remove_train=True)\n",
    "            # For keyphrase selection method 'diff' \n",
    "            top_recommended_keyphrase_freq = get_item_keyphrase_freq(self.item_keyphrase_freq,item = initial_prediction_items[0])\n",
    "            \n",
    "            # The iteration will stop if the wanted item is in top n\n",
    "            for target_rank in self.target_ranks:\n",
    "                self.row['target_rank'] = target_rank\n",
    "                \n",
    "                # Pick wanted items in test items\n",
    "                candidate_items = self.matrix_Test[user].nonzero()[1]\n",
    "                train_items = self.matrix_Train[user].nonzero()[1]\n",
    "                wanted_items = np.setdiff1d(candidate_items, train_items)\n",
    "                \n",
    "\n",
    "                \n",
    "                for item in wanted_items:\n",
    "                    # Item id starts from 0\n",
    "                    self.row['item_id'] = item\n",
    "                    self.row['item_name'] = get_restaurant_name(df_train, business_df,item)\n",
    "                    # Set the wanted item's initial rank as None\n",
    "                    self.row['item_rank'] = None\n",
    "                    # Set the wanted item's initial prediction score as None\n",
    "                    self.row['item_score'] = None\n",
    "                    \n",
    "                    if self.keyphrase_selection_method == \"random\" or self.keyphrase_selection_method == \"pop\":\n",
    "                        # Get the item's existing keyphrases (we can boost)\n",
    "                        remaining_keyphrases = self.item_keyphrase_freq[item].nonzero()[1]\n",
    "                    if self.keyphrase_selection_method == \"diff\":\n",
    "                        # For keyphrase selection method 'diff' \n",
    "                        target_keyphrase_freq = get_item_keyphrase_freq(self.item_keyphrase_freq,item = item)\n",
    "                        diff_keyphrase_freq = target_keyphrase_freq - top_recommended_keyphrase_freq\n",
    "                        remaining_keyphrases = np.argsort(np.ravel(diff_keyphrase_freq))[::-1][:self.max_wanted_keyphrase]\n",
    "                        \n",
    "#                    print(\"The number of remaining_keyphrases is {}. remaining_keyphrases are: {}\".format(len(remaining_keyphrases), remaining_keyphrases))\n",
    "                    self.row['num_existing_keyphrases'] = len(remaining_keyphrases)\n",
    "                    if len(remaining_keyphrases) == 0:\n",
    "                        break\n",
    "                    self.row['iteration'] = 0\n",
    "                    self.row['critiqued_keyphrase'] = None\n",
    "                    self.row['result'] = None\n",
    "                    self.df = self.df.append(self.row, ignore_index=True)\n",
    "\n",
    "                    query = []\n",
    "                    affected_items = np.array([])\n",
    "\n",
    "                    for iteration in range(self.max_iteration_threshold):\n",
    "                        self.row['iteration'] = iteration + 1\n",
    "                        \n",
    "                        if self.keyphrase_selection_method == \"pop\":\n",
    "                            # Always critique the most popular keyphrase\n",
    "                            critiqued_keyphrase = remaining_keyphrases[np.argmax(self.keyphrase_popularity[remaining_keyphrases])]\n",
    "    #                        print(\"remaining keyphrases popularity: {}\".format(self.keyphrase_popularity[remaining_keyphrases]))\n",
    "                        elif self.keyphrase_selection_method == \"random\":\n",
    "                            critiqued_keyphrase = np.random.choice(remaining_keyphrases, size=1, replace=False)[0]\n",
    "            \n",
    "                        elif self.keyphrase_selection_method == \"diff\":\n",
    "                            critiqued_keyphrase = remaining_keyphrases[0]\n",
    "                        \n",
    "                        self.row['critiqued_keyphrase'] = critiqued_keyphrase\n",
    "                        self.row['critiqued_keyphrase_name'] = keyphrases_names[critiqued_keyphrase]\n",
    "                        query.append(critiqued_keyphrase)\n",
    "\n",
    "                        # Get affected items (items have critiqued keyphrase)\n",
    "                        current_affected_items = self.item_keyphrase_freq[:, critiqued_keyphrase].nonzero()[0]\n",
    "                        affected_items = np.unique(np.concatenate((affected_items, current_affected_items))).astype(int)\n",
    "                        unaffected_items = np.setdiff1d(range(self.num_items), affected_items)\n",
    "\n",
    "                        if iteration == 0:\n",
    "                            prediction_items = initial_prediction_items #calculated once for each user\n",
    "\n",
    "                        affected_items_mask = np.in1d(prediction_items, affected_items)\n",
    "                        affected_items_index_rank = np.where(affected_items_mask == True)\n",
    "                        unaffected_items_index_rank = np.where(affected_items_mask == False)\n",
    "\n",
    "                        import copy\n",
    "#                         prediction_scores_u, lambdas = LP1SimplifiedOptimize(initial_prediction_u=self.prediction_scores[user],\n",
    "#                                                                              keyphrase_freq=copy.deepcopy(self.keyphrase_freq),\n",
    "#                                                                              affected_items=np.intersect1d(affected_items, prediction_items[affected_items_index_rank[0][:100]]),\n",
    "#                                                                              unaffected_items=np.intersect1d(unaffected_items, prediction_items[unaffected_items_index_rank[0][:100]]),\n",
    "#                                                                              num_keyphrases=self.num_keyphrases,\n",
    "#                                                                              query=query,\n",
    "#                                                                              test_user=user,\n",
    "#                                                                              item_latent=self.RQ,\n",
    "#                                                                              reg=self.reg)\n",
    "#                         prediction_scores_u, lambdas = LP1SumToOneOptimize(initial_prediction_u=self.prediction_scores[user],\n",
    "#                                                                            keyphrase_freq=copy.deepcopy(self.keyphrase_freq),\n",
    "#                                                                            affected_items=np.intersect1d(affected_items, prediction_items[affected_items_index_rank[0][:100]]),\n",
    "#                                                                            unaffected_items=np.intersect1d(unaffected_items, prediction_items[unaffected_items_index_rank[0][:100]]),\n",
    "#                                                                            num_keyphrases=self.num_keyphrases,\n",
    "#                                                                            query=query,\n",
    "#                                                                            test_user=user,\n",
    "#                                                                            item_latent=self.RQ,\n",
    "#                                                                            reg=self.reg)\n",
    "                        prediction_scores_u, lambdas = Average(initial_prediction_u=self.prediction_scores[user],\n",
    "                                                                             keyphrase_freq=copy.deepcopy(self.keyphrase_freq),\n",
    "                                                                             affected_items=np.intersect1d(affected_items, prediction_items[affected_items_index_rank[0][:100]]),\n",
    "                                                                             unaffected_items=np.intersect1d(unaffected_items, prediction_items[unaffected_items_index_rank[0][:100]]),\n",
    "                                                                             num_keyphrases=self.num_keyphrases,\n",
    "                                                                             query=query,\n",
    "                                                                             test_user=user,\n",
    "                                                                             item_latent=self.RQ,\n",
    "                                                                             reg=self.reg)\n",
    "\n",
    "                        self.row['lambda'] = lambdas\n",
    "                        prediction_items = predict_vector(rating_vector=prediction_scores_u,\n",
    "                                                          train_vector=self.matrix_Train[user],\n",
    "                                                          remove_train=False)\n",
    "                        recommended_items = prediction_items\n",
    "                        \n",
    "                        # Current item rank\n",
    "                        item_rank = np.where(recommended_items == item)[0][0]\n",
    "\n",
    "                        self.row['item_rank'] = item_rank\n",
    "                        self.row['item_score'] = prediction_scores_u[item]\n",
    "\n",
    "                        if item_rank + 1 <= target_rank:\n",
    "                            # Items is ranked within target rank\n",
    "                            self.row['result'] = 'successful'\n",
    "                            self.df = self.df.append(self.row, ignore_index=True)\n",
    "                            break\n",
    "                        else:\n",
    "                            remaining_keyphrases = np.setdiff1d(remaining_keyphrases, critiqued_keyphrase)\n",
    "                            # Continue if more keyphrases and iterations remained\n",
    "                            if len(remaining_keyphrases) > 0 and self.row['iteration'] < self.max_iteration_threshold:\n",
    "                                self.row['result'] = None\n",
    "                                self.df = self.df.append(self.row, ignore_index=True)\n",
    "                            else:\n",
    "                                # Otherwise, mark fail\n",
    "                                self.row['result'] = 'fail'\n",
    "                                self.df = self.df.append(self.row, ignore_index=True)\n",
    "                                break\n",
    "        return self.df\n",
    "\n",
    "\n",
    "    def get_initial_predictions(self):\n",
    "        self.RQ, Yt, Bias = plrec(self.matrix_Train,\n",
    "                                       iteration=self.parameters_row['iter'],\n",
    "                                       lamb=self.parameters_row['lambda'],\n",
    "                                       rank=self.parameters_row['rank'])\n",
    "        self.Y = Yt.T\n",
    "\n",
    "        self.reg = LinearRegression().fit(self.keyphrase_freq, self.RQ)\n",
    "\n",
    "        self.prediction_scores = predict_scores(matrix_U=self.RQ,\n",
    "                                                matrix_V=self.Y,\n",
    "                                                bias=Bias)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "row = {}\n",
    "matrix_Train = rtrain\n",
    "matrix_Test = rtest\n",
    "test_users = [0]\n",
    "target_ranks = [20]\n",
    "num_items_sampled = 5\n",
    "num_keyphrases = 10\n",
    "df = pd.DataFrame(row)\n",
    "max_iteration_threshold = 20\n",
    "keyphrase_popularity = keyphrase_popularity\n",
    "dataset_name = \"yelp\"\n",
    "model = \"plrec\"\n",
    "parameters_row = {'iter': 10,\n",
    "                  'lambda':200,\n",
    "                  'rank':200}\n",
    "keyphrases_names = keyphrases\n",
    "keyphrase_selection_method = 'diff'\n",
    "max_wanted_keyphrase = 20\n",
    "\n",
    "\n",
    "critiquing_model = LP1Simplified(keyphrase_freq=U_K,\n",
    "                                item_keyphrase_freq=I_K,\n",
    "                                row=row,\n",
    "                                matrix_Train=matrix_Train,\n",
    "                                matrix_Test=matrix_Test,\n",
    "                                test_users=test_users,\n",
    "                                target_ranks=target_ranks,\n",
    "                                num_items_sampled=num_items_sampled,\n",
    "                                num_keyphrases=num_keyphrases,\n",
    "                                df=df,\n",
    "                                max_iteration_threshold=max_iteration_threshold,\n",
    "                                keyphrase_popularity=keyphrase_popularity,\n",
    "                                dataset_name=dataset_name,\n",
    "                                model=model,\n",
    "                                parameters_row=parameters_row,\n",
    "                                keyphrases_names = keyphrases_names,\n",
    "                                keyphrase_selection_method = keyphrase_selection_method,\n",
    "                                max_wanted_keyphrase = max_wanted_keyphrase)\n",
    "df = critiquing_model.start_critiquing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>critiqued_keyphrase</th>\n",
       "      <th>item_id</th>\n",
       "      <th>item_name</th>\n",
       "      <th>item_rank</th>\n",
       "      <th>item_score</th>\n",
       "      <th>iteration</th>\n",
       "      <th>num_existing_keyphrases</th>\n",
       "      <th>result</th>\n",
       "      <th>target_rank</th>\n",
       "      <th>user_id</th>\n",
       "      <th>critiqued_keyphrase_name</th>\n",
       "      <th>lambda</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>78.0</td>\n",
       "      <td>b'The Works Gourmet Burger Bistro'</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>None</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>48</td>\n",
       "      <td>78.0</td>\n",
       "      <td>b'The Works Gourmet Burger Bistro'</td>\n",
       "      <td>445</td>\n",
       "      <td>0.146624</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>None</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>burger</td>\n",
       "      <td>[1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>78.0</td>\n",
       "      <td>b'The Works Gourmet Burger Bistro'</td>\n",
       "      <td>191</td>\n",
       "      <td>0.28233</td>\n",
       "      <td>2.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>None</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>fry</td>\n",
       "      <td>[1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>78.0</td>\n",
       "      <td>b'The Works Gourmet Burger Bistro'</td>\n",
       "      <td>614</td>\n",
       "      <td>0.170418</td>\n",
       "      <td>3.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>None</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>fried</td>\n",
       "      <td>[1, 1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>78.0</td>\n",
       "      <td>b'The Works Gourmet Burger Bistro'</td>\n",
       "      <td>1357</td>\n",
       "      <td>0.0988711</td>\n",
       "      <td>4.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>None</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>dinner</td>\n",
       "      <td>[1, 1, 1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>25</td>\n",
       "      <td>78.0</td>\n",
       "      <td>b'The Works Gourmet Burger Bistro'</td>\n",
       "      <td>786</td>\n",
       "      <td>0.182535</td>\n",
       "      <td>5.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>None</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>vegetarian</td>\n",
       "      <td>[1, 1, 1, 1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>27</td>\n",
       "      <td>78.0</td>\n",
       "      <td>b'The Works Gourmet Burger Bistro'</td>\n",
       "      <td>5938</td>\n",
       "      <td>-0.0708863</td>\n",
       "      <td>6.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>None</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>bbq</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>34</td>\n",
       "      <td>78.0</td>\n",
       "      <td>b'The Works Gourmet Burger Bistro'</td>\n",
       "      <td>1507</td>\n",
       "      <td>0.115082</td>\n",
       "      <td>7.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>None</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>potato</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>35</td>\n",
       "      <td>78.0</td>\n",
       "      <td>b'The Works Gourmet Burger Bistro'</td>\n",
       "      <td>1612</td>\n",
       "      <td>0.109923</td>\n",
       "      <td>8.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>None</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>crispy</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>49</td>\n",
       "      <td>78.0</td>\n",
       "      <td>b'The Works Gourmet Burger Bistro'</td>\n",
       "      <td>496</td>\n",
       "      <td>0.31969</td>\n",
       "      <td>9.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>None</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>cheese</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>52</td>\n",
       "      <td>78.0</td>\n",
       "      <td>b'The Works Gourmet Burger Bistro'</td>\n",
       "      <td>535</td>\n",
       "      <td>0.341074</td>\n",
       "      <td>10.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>None</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>beef</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>56</td>\n",
       "      <td>78.0</td>\n",
       "      <td>b'The Works Gourmet Burger Bistro'</td>\n",
       "      <td>542</td>\n",
       "      <td>0.357522</td>\n",
       "      <td>11.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>None</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>chicken</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>85</td>\n",
       "      <td>78.0</td>\n",
       "      <td>b'The Works Gourmet Burger Bistro'</td>\n",
       "      <td>187</td>\n",
       "      <td>0.720025</td>\n",
       "      <td>12.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>None</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>patty</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>96</td>\n",
       "      <td>78.0</td>\n",
       "      <td>b'The Works Gourmet Burger Bistro'</td>\n",
       "      <td>103</td>\n",
       "      <td>1.02881</td>\n",
       "      <td>13.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>None</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>poutine</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>119</td>\n",
       "      <td>78.0</td>\n",
       "      <td>b'The Works Gourmet Burger Bistro'</td>\n",
       "      <td>142</td>\n",
       "      <td>0.885124</td>\n",
       "      <td>14.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>None</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>bun</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>126</td>\n",
       "      <td>78.0</td>\n",
       "      <td>b'The Works Gourmet Burger Bistro'</td>\n",
       "      <td>180</td>\n",
       "      <td>0.918561</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>None</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>milk</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>153</td>\n",
       "      <td>78.0</td>\n",
       "      <td>b'The Works Gourmet Burger Bistro'</td>\n",
       "      <td>172</td>\n",
       "      <td>0.960565</td>\n",
       "      <td>16.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>None</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>friendly</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>182</td>\n",
       "      <td>78.0</td>\n",
       "      <td>b'The Works Gourmet Burger Bistro'</td>\n",
       "      <td>142</td>\n",
       "      <td>1.11583</td>\n",
       "      <td>17.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>None</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>chip</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>193</td>\n",
       "      <td>78.0</td>\n",
       "      <td>b'The Works Gourmet Burger Bistro'</td>\n",
       "      <td>132</td>\n",
       "      <td>1.22062</td>\n",
       "      <td>18.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>None</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>mayo</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>206</td>\n",
       "      <td>78.0</td>\n",
       "      <td>b'The Works Gourmet Burger Bistro'</td>\n",
       "      <td>115</td>\n",
       "      <td>1.28562</td>\n",
       "      <td>19.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>None</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>salt</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>217</td>\n",
       "      <td>78.0</td>\n",
       "      <td>b'The Works Gourmet Burger Bistro'</td>\n",
       "      <td>110</td>\n",
       "      <td>1.22707</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>fail</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>juicy</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   critiqued_keyphrase  item_id                           item_name item_rank  \\\n",
       "0                 None     78.0  b'The Works Gourmet Burger Bistro'      None   \n",
       "1                   48     78.0  b'The Works Gourmet Burger Bistro'       445   \n",
       "2                    4     78.0  b'The Works Gourmet Burger Bistro'       191   \n",
       "3                    5     78.0  b'The Works Gourmet Burger Bistro'       614   \n",
       "4                    7     78.0  b'The Works Gourmet Burger Bistro'      1357   \n",
       "5                   25     78.0  b'The Works Gourmet Burger Bistro'       786   \n",
       "6                   27     78.0  b'The Works Gourmet Burger Bistro'      5938   \n",
       "7                   34     78.0  b'The Works Gourmet Burger Bistro'      1507   \n",
       "8                   35     78.0  b'The Works Gourmet Burger Bistro'      1612   \n",
       "9                   49     78.0  b'The Works Gourmet Burger Bistro'       496   \n",
       "10                  52     78.0  b'The Works Gourmet Burger Bistro'       535   \n",
       "11                  56     78.0  b'The Works Gourmet Burger Bistro'       542   \n",
       "12                  85     78.0  b'The Works Gourmet Burger Bistro'       187   \n",
       "13                  96     78.0  b'The Works Gourmet Burger Bistro'       103   \n",
       "14                 119     78.0  b'The Works Gourmet Burger Bistro'       142   \n",
       "15                 126     78.0  b'The Works Gourmet Burger Bistro'       180   \n",
       "16                 153     78.0  b'The Works Gourmet Burger Bistro'       172   \n",
       "17                 182     78.0  b'The Works Gourmet Burger Bistro'       142   \n",
       "18                 193     78.0  b'The Works Gourmet Burger Bistro'       132   \n",
       "19                 206     78.0  b'The Works Gourmet Burger Bistro'       115   \n",
       "20                 217     78.0  b'The Works Gourmet Burger Bistro'       110   \n",
       "\n",
       "   item_score  iteration  num_existing_keyphrases result  target_rank  \\\n",
       "0        None        0.0                     20.0   None         20.0   \n",
       "1    0.146624        1.0                     20.0   None         20.0   \n",
       "2     0.28233        2.0                     20.0   None         20.0   \n",
       "3    0.170418        3.0                     20.0   None         20.0   \n",
       "4   0.0988711        4.0                     20.0   None         20.0   \n",
       "5    0.182535        5.0                     20.0   None         20.0   \n",
       "6  -0.0708863        6.0                     20.0   None         20.0   \n",
       "7    0.115082        7.0                     20.0   None         20.0   \n",
       "8    0.109923        8.0                     20.0   None         20.0   \n",
       "9     0.31969        9.0                     20.0   None         20.0   \n",
       "10   0.341074       10.0                     20.0   None         20.0   \n",
       "11   0.357522       11.0                     20.0   None         20.0   \n",
       "12   0.720025       12.0                     20.0   None         20.0   \n",
       "13    1.02881       13.0                     20.0   None         20.0   \n",
       "14   0.885124       14.0                     20.0   None         20.0   \n",
       "15   0.918561       15.0                     20.0   None         20.0   \n",
       "16   0.960565       16.0                     20.0   None         20.0   \n",
       "17    1.11583       17.0                     20.0   None         20.0   \n",
       "18    1.22062       18.0                     20.0   None         20.0   \n",
       "19    1.28562       19.0                     20.0   None         20.0   \n",
       "20    1.22707       20.0                     20.0   fail         20.0   \n",
       "\n",
       "    user_id critiqued_keyphrase_name  \\\n",
       "0       0.0                      NaN   \n",
       "1       0.0                   burger   \n",
       "2       0.0                      fry   \n",
       "3       0.0                    fried   \n",
       "4       0.0                   dinner   \n",
       "5       0.0               vegetarian   \n",
       "6       0.0                      bbq   \n",
       "7       0.0                   potato   \n",
       "8       0.0                   crispy   \n",
       "9       0.0                   cheese   \n",
       "10      0.0                     beef   \n",
       "11      0.0                  chicken   \n",
       "12      0.0                    patty   \n",
       "13      0.0                  poutine   \n",
       "14      0.0                      bun   \n",
       "15      0.0                     milk   \n",
       "16      0.0                 friendly   \n",
       "17      0.0                     chip   \n",
       "18      0.0                     mayo   \n",
       "19      0.0                     salt   \n",
       "20      0.0                    juicy   \n",
       "\n",
       "                                               lambda  \n",
       "0                                                 NaN  \n",
       "1                                                 [1]  \n",
       "2                                              [1, 1]  \n",
       "3                                           [1, 1, 1]  \n",
       "4                                        [1, 1, 1, 1]  \n",
       "5                                     [1, 1, 1, 1, 1]  \n",
       "6                                  [1, 1, 1, 1, 1, 1]  \n",
       "7                               [1, 1, 1, 1, 1, 1, 1]  \n",
       "8                            [1, 1, 1, 1, 1, 1, 1, 1]  \n",
       "9                         [1, 1, 1, 1, 1, 1, 1, 1, 1]  \n",
       "10                     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]  \n",
       "11                  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]  \n",
       "12               [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]  \n",
       "13            [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]  \n",
       "14         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]  \n",
       "15      [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]  \n",
       "16   [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]  \n",
       "17  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "18  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "19  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "20  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  "
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Avg\n",
    "df.head(21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>critiqued_keyphrase</th>\n",
       "      <th>item_id</th>\n",
       "      <th>item_name</th>\n",
       "      <th>item_rank</th>\n",
       "      <th>item_score</th>\n",
       "      <th>iteration</th>\n",
       "      <th>num_existing_keyphrases</th>\n",
       "      <th>result</th>\n",
       "      <th>target_rank</th>\n",
       "      <th>user_id</th>\n",
       "      <th>critiqued_keyphrase_name</th>\n",
       "      <th>lambda</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>78.0</td>\n",
       "      <td>b'The Works Gourmet Burger Bistro'</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>None</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>48</td>\n",
       "      <td>78.0</td>\n",
       "      <td>b'The Works Gourmet Burger Bistro'</td>\n",
       "      <td>7274</td>\n",
       "      <td>-0.249077</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>None</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>burger</td>\n",
       "      <td>[-1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>78.0</td>\n",
       "      <td>b'The Works Gourmet Burger Bistro'</td>\n",
       "      <td>2928</td>\n",
       "      <td>0.0109182</td>\n",
       "      <td>2.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>None</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>fry</td>\n",
       "      <td>[1.0, -1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>78.0</td>\n",
       "      <td>b'The Works Gourmet Burger Bistro'</td>\n",
       "      <td>3919</td>\n",
       "      <td>-0.00145876</td>\n",
       "      <td>3.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>None</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>fried</td>\n",
       "      <td>[-1.0, 1.0, -1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>78.0</td>\n",
       "      <td>b'The Works Gourmet Burger Bistro'</td>\n",
       "      <td>6930</td>\n",
       "      <td>-0.172541</td>\n",
       "      <td>4.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>None</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>dinner</td>\n",
       "      <td>[1.0, -1.0, 1.0, 1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>25</td>\n",
       "      <td>78.0</td>\n",
       "      <td>b'The Works Gourmet Burger Bistro'</td>\n",
       "      <td>802</td>\n",
       "      <td>0.153752</td>\n",
       "      <td>5.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>None</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>vegetarian</td>\n",
       "      <td>[-1.0, 1.0, -1.0, -1.0, 1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>27</td>\n",
       "      <td>78.0</td>\n",
       "      <td>b'The Works Gourmet Burger Bistro'</td>\n",
       "      <td>7372</td>\n",
       "      <td>-0.509626</td>\n",
       "      <td>6.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>None</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>bbq</td>\n",
       "      <td>[1.0, -1.0, 1.0, 1.0, -1.0, 1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>34</td>\n",
       "      <td>78.0</td>\n",
       "      <td>b'The Works Gourmet Burger Bistro'</td>\n",
       "      <td>114</td>\n",
       "      <td>0.593141</td>\n",
       "      <td>7.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>None</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>potato</td>\n",
       "      <td>[-1.0, 1.0, -1.0, -1.0, 1.0, -1.0, 1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>35</td>\n",
       "      <td>78.0</td>\n",
       "      <td>b'The Works Gourmet Burger Bistro'</td>\n",
       "      <td>7395</td>\n",
       "      <td>-0.690435</td>\n",
       "      <td>8.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>None</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>crispy</td>\n",
       "      <td>[1.0, -1.0, 1.0, 1.0, -1.0, 1.0, -1.0, -1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>49</td>\n",
       "      <td>78.0</td>\n",
       "      <td>b'The Works Gourmet Burger Bistro'</td>\n",
       "      <td>304</td>\n",
       "      <td>0.378216</td>\n",
       "      <td>9.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>None</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>cheese</td>\n",
       "      <td>[-1.0, 1.0, -1.0, -1.0, 1.0, -1.0, 1.0, 1.0, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>52</td>\n",
       "      <td>78.0</td>\n",
       "      <td>b'The Works Gourmet Burger Bistro'</td>\n",
       "      <td>7268</td>\n",
       "      <td>-0.502053</td>\n",
       "      <td>10.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>None</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>beef</td>\n",
       "      <td>[1.0, -1.0, 1.0, 1.0, -1.0, 1.0, -1.0, -1.0, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>56</td>\n",
       "      <td>78.0</td>\n",
       "      <td>b'The Works Gourmet Burger Bistro'</td>\n",
       "      <td>392</td>\n",
       "      <td>0.383153</td>\n",
       "      <td>11.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>None</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>chicken</td>\n",
       "      <td>[-1.0, 1.0, -1.0, -1.0, 1.0, -1.0, 1.0, 1.0, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>85</td>\n",
       "      <td>78.0</td>\n",
       "      <td>b'The Works Gourmet Burger Bistro'</td>\n",
       "      <td>6793</td>\n",
       "      <td>-0.333078</td>\n",
       "      <td>12.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>None</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>patty</td>\n",
       "      <td>[1.0, -1.0, 1.0, -1.0, -1.0, 1.0, 1.0, -1.0, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>96</td>\n",
       "      <td>78.0</td>\n",
       "      <td>b'The Works Gourmet Burger Bistro'</td>\n",
       "      <td>225</td>\n",
       "      <td>0.639738</td>\n",
       "      <td>13.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>None</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>poutine</td>\n",
       "      <td>[-1.0, 1.0, -1.0, -1.0, 1.0, -1.0, -1.0, 1.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>119</td>\n",
       "      <td>78.0</td>\n",
       "      <td>b'The Works Gourmet Burger Bistro'</td>\n",
       "      <td>7062</td>\n",
       "      <td>-0.455408</td>\n",
       "      <td>14.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>None</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>bun</td>\n",
       "      <td>[1.0, -1.0, 1.0, -1.0, -1.0, 1.0, 1.0, -1.0, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>126</td>\n",
       "      <td>78.0</td>\n",
       "      <td>b'The Works Gourmet Burger Bistro'</td>\n",
       "      <td>383</td>\n",
       "      <td>0.462614</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>None</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>milk</td>\n",
       "      <td>[-1.0, 1.0, -1.0, -1.0, 1.0, -1.0, -1.0, 1.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>153</td>\n",
       "      <td>78.0</td>\n",
       "      <td>b'The Works Gourmet Burger Bistro'</td>\n",
       "      <td>6766</td>\n",
       "      <td>-0.363522</td>\n",
       "      <td>16.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>None</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>friendly</td>\n",
       "      <td>[1.0, -1.0, 1.0, -1.0, 1.0, 1.0, 1.0, -1.0, 1....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>182</td>\n",
       "      <td>78.0</td>\n",
       "      <td>b'The Works Gourmet Burger Bistro'</td>\n",
       "      <td>1400</td>\n",
       "      <td>0.164892</td>\n",
       "      <td>17.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>None</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>chip</td>\n",
       "      <td>[-1.0, 1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 1.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>193</td>\n",
       "      <td>78.0</td>\n",
       "      <td>b'The Works Gourmet Burger Bistro'</td>\n",
       "      <td>6497</td>\n",
       "      <td>-0.355815</td>\n",
       "      <td>18.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>None</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>mayo</td>\n",
       "      <td>[1.0, -1.0, 1.0, -1.0, 1.0, 1.0, 1.0, -1.0, 1....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>206</td>\n",
       "      <td>78.0</td>\n",
       "      <td>b'The Works Gourmet Burger Bistro'</td>\n",
       "      <td>1251</td>\n",
       "      <td>0.204682</td>\n",
       "      <td>19.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>None</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>salt</td>\n",
       "      <td>[-1.0, 1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 1.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>217</td>\n",
       "      <td>78.0</td>\n",
       "      <td>b'The Works Gourmet Burger Bistro'</td>\n",
       "      <td>6439</td>\n",
       "      <td>-0.349367</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>fail</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>juicy</td>\n",
       "      <td>[1.0, -1.0, 1.0, -1.0, 1.0, 1.0, 1.0, -1.0, 1....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   critiqued_keyphrase  item_id                           item_name item_rank  \\\n",
       "0                 None     78.0  b'The Works Gourmet Burger Bistro'      None   \n",
       "1                   48     78.0  b'The Works Gourmet Burger Bistro'      7274   \n",
       "2                    4     78.0  b'The Works Gourmet Burger Bistro'      2928   \n",
       "3                    5     78.0  b'The Works Gourmet Burger Bistro'      3919   \n",
       "4                    7     78.0  b'The Works Gourmet Burger Bistro'      6930   \n",
       "5                   25     78.0  b'The Works Gourmet Burger Bistro'       802   \n",
       "6                   27     78.0  b'The Works Gourmet Burger Bistro'      7372   \n",
       "7                   34     78.0  b'The Works Gourmet Burger Bistro'       114   \n",
       "8                   35     78.0  b'The Works Gourmet Burger Bistro'      7395   \n",
       "9                   49     78.0  b'The Works Gourmet Burger Bistro'       304   \n",
       "10                  52     78.0  b'The Works Gourmet Burger Bistro'      7268   \n",
       "11                  56     78.0  b'The Works Gourmet Burger Bistro'       392   \n",
       "12                  85     78.0  b'The Works Gourmet Burger Bistro'      6793   \n",
       "13                  96     78.0  b'The Works Gourmet Burger Bistro'       225   \n",
       "14                 119     78.0  b'The Works Gourmet Burger Bistro'      7062   \n",
       "15                 126     78.0  b'The Works Gourmet Burger Bistro'       383   \n",
       "16                 153     78.0  b'The Works Gourmet Burger Bistro'      6766   \n",
       "17                 182     78.0  b'The Works Gourmet Burger Bistro'      1400   \n",
       "18                 193     78.0  b'The Works Gourmet Burger Bistro'      6497   \n",
       "19                 206     78.0  b'The Works Gourmet Burger Bistro'      1251   \n",
       "20                 217     78.0  b'The Works Gourmet Burger Bistro'      6439   \n",
       "\n",
       "    item_score  iteration  num_existing_keyphrases result  target_rank  \\\n",
       "0         None        0.0                     20.0   None         20.0   \n",
       "1    -0.249077        1.0                     20.0   None         20.0   \n",
       "2    0.0109182        2.0                     20.0   None         20.0   \n",
       "3  -0.00145876        3.0                     20.0   None         20.0   \n",
       "4    -0.172541        4.0                     20.0   None         20.0   \n",
       "5     0.153752        5.0                     20.0   None         20.0   \n",
       "6    -0.509626        6.0                     20.0   None         20.0   \n",
       "7     0.593141        7.0                     20.0   None         20.0   \n",
       "8    -0.690435        8.0                     20.0   None         20.0   \n",
       "9     0.378216        9.0                     20.0   None         20.0   \n",
       "10   -0.502053       10.0                     20.0   None         20.0   \n",
       "11    0.383153       11.0                     20.0   None         20.0   \n",
       "12   -0.333078       12.0                     20.0   None         20.0   \n",
       "13    0.639738       13.0                     20.0   None         20.0   \n",
       "14   -0.455408       14.0                     20.0   None         20.0   \n",
       "15    0.462614       15.0                     20.0   None         20.0   \n",
       "16   -0.363522       16.0                     20.0   None         20.0   \n",
       "17    0.164892       17.0                     20.0   None         20.0   \n",
       "18   -0.355815       18.0                     20.0   None         20.0   \n",
       "19    0.204682       19.0                     20.0   None         20.0   \n",
       "20   -0.349367       20.0                     20.0   fail         20.0   \n",
       "\n",
       "    user_id critiqued_keyphrase_name  \\\n",
       "0       0.0                      NaN   \n",
       "1       0.0                   burger   \n",
       "2       0.0                      fry   \n",
       "3       0.0                    fried   \n",
       "4       0.0                   dinner   \n",
       "5       0.0               vegetarian   \n",
       "6       0.0                      bbq   \n",
       "7       0.0                   potato   \n",
       "8       0.0                   crispy   \n",
       "9       0.0                   cheese   \n",
       "10      0.0                     beef   \n",
       "11      0.0                  chicken   \n",
       "12      0.0                    patty   \n",
       "13      0.0                  poutine   \n",
       "14      0.0                      bun   \n",
       "15      0.0                     milk   \n",
       "16      0.0                 friendly   \n",
       "17      0.0                     chip   \n",
       "18      0.0                     mayo   \n",
       "19      0.0                     salt   \n",
       "20      0.0                    juicy   \n",
       "\n",
       "                                               lambda  \n",
       "0                                                 NaN  \n",
       "1                                              [-1.0]  \n",
       "2                                         [1.0, -1.0]  \n",
       "3                                   [-1.0, 1.0, -1.0]  \n",
       "4                               [1.0, -1.0, 1.0, 1.0]  \n",
       "5                        [-1.0, 1.0, -1.0, -1.0, 1.0]  \n",
       "6                    [1.0, -1.0, 1.0, 1.0, -1.0, 1.0]  \n",
       "7             [-1.0, 1.0, -1.0, -1.0, 1.0, -1.0, 1.0]  \n",
       "8        [1.0, -1.0, 1.0, 1.0, -1.0, 1.0, -1.0, -1.0]  \n",
       "9   [-1.0, 1.0, -1.0, -1.0, 1.0, -1.0, 1.0, 1.0, -...  \n",
       "10  [1.0, -1.0, 1.0, 1.0, -1.0, 1.0, -1.0, -1.0, 1...  \n",
       "11  [-1.0, 1.0, -1.0, -1.0, 1.0, -1.0, 1.0, 1.0, -...  \n",
       "12  [1.0, -1.0, 1.0, -1.0, -1.0, 1.0, 1.0, -1.0, 1...  \n",
       "13  [-1.0, 1.0, -1.0, -1.0, 1.0, -1.0, -1.0, 1.0, ...  \n",
       "14  [1.0, -1.0, 1.0, -1.0, -1.0, 1.0, 1.0, -1.0, 1...  \n",
       "15  [-1.0, 1.0, -1.0, -1.0, 1.0, -1.0, -1.0, 1.0, ...  \n",
       "16  [1.0, -1.0, 1.0, -1.0, 1.0, 1.0, 1.0, -1.0, 1....  \n",
       "17  [-1.0, 1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 1.0,...  \n",
       "18  [1.0, -1.0, 1.0, -1.0, 1.0, 1.0, 1.0, -1.0, 1....  \n",
       "19  [-1.0, 1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 1.0,...  \n",
       "20  [1.0, -1.0, 1.0, -1.0, 1.0, 1.0, 1.0, -1.0, 1....  "
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Simplified\n",
    "df.head(21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>critiqued_keyphrase</th>\n",
       "      <th>item_id</th>\n",
       "      <th>item_rank</th>\n",
       "      <th>item_score</th>\n",
       "      <th>iteration</th>\n",
       "      <th>num_existing_keyphrases</th>\n",
       "      <th>result</th>\n",
       "      <th>target_rank</th>\n",
       "      <th>user_id</th>\n",
       "      <th>critiqued_keyphrase_name</th>\n",
       "      <th>lambda</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>78.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34</td>\n",
       "      <td>78.0</td>\n",
       "      <td>205</td>\n",
       "      <td>0.16336</td>\n",
       "      <td>1.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>None</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>potato</td>\n",
       "      <td>[0.0, 1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>114</td>\n",
       "      <td>78.0</td>\n",
       "      <td>6164</td>\n",
       "      <td>-0.0512262</td>\n",
       "      <td>2.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>None</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>tomato</td>\n",
       "      <td>[1.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>90</td>\n",
       "      <td>78.0</td>\n",
       "      <td>205</td>\n",
       "      <td>0.16336</td>\n",
       "      <td>3.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>None</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>tuna</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>76</td>\n",
       "      <td>78.0</td>\n",
       "      <td>6796</td>\n",
       "      <td>-0.0664696</td>\n",
       "      <td>4.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>None</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>lettuce</td>\n",
       "      <td>[0.0, 0.0, 0.0, 1.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>88</td>\n",
       "      <td>78.0</td>\n",
       "      <td>205</td>\n",
       "      <td>0.16336</td>\n",
       "      <td>5.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>None</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>four</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>55</td>\n",
       "      <td>78.0</td>\n",
       "      <td>884</td>\n",
       "      <td>0.0593435</td>\n",
       "      <td>6.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>None</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>meat</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>152</td>\n",
       "      <td>78.0</td>\n",
       "      <td>205</td>\n",
       "      <td>0.16336</td>\n",
       "      <td>7.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>None</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>fresh</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>27</td>\n",
       "      <td>78.0</td>\n",
       "      <td>884</td>\n",
       "      <td>0.0593435</td>\n",
       "      <td>8.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>None</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>bbq</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>7</td>\n",
       "      <td>78.0</td>\n",
       "      <td>7330</td>\n",
       "      <td>-0.276029</td>\n",
       "      <td>9.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>None</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>dinner</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>177</td>\n",
       "      <td>78.0</td>\n",
       "      <td>6278</td>\n",
       "      <td>-0.0596727</td>\n",
       "      <td>10.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>None</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>nicely</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>24</td>\n",
       "      <td>78.0</td>\n",
       "      <td>5069</td>\n",
       "      <td>-0.0389414</td>\n",
       "      <td>11.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>None</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>birthday</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>26</td>\n",
       "      <td>78.0</td>\n",
       "      <td>205</td>\n",
       "      <td>0.16336</td>\n",
       "      <td>12.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>None</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>downtown</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>198</td>\n",
       "      <td>78.0</td>\n",
       "      <td>201</td>\n",
       "      <td>0.148447</td>\n",
       "      <td>13.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>None</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>crunchy</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>40</td>\n",
       "      <td>78.0</td>\n",
       "      <td>205</td>\n",
       "      <td>0.16336</td>\n",
       "      <td>14.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>None</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>pizza</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>48</td>\n",
       "      <td>78.0</td>\n",
       "      <td>884</td>\n",
       "      <td>0.0593435</td>\n",
       "      <td>15.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>None</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>burger</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>183</td>\n",
       "      <td>78.0</td>\n",
       "      <td>7330</td>\n",
       "      <td>-0.276029</td>\n",
       "      <td>16.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>None</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>attentive</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>5</td>\n",
       "      <td>78.0</td>\n",
       "      <td>6278</td>\n",
       "      <td>-0.0596727</td>\n",
       "      <td>17.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>None</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>fried</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>79</td>\n",
       "      <td>78.0</td>\n",
       "      <td>5069</td>\n",
       "      <td>-0.0389414</td>\n",
       "      <td>18.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>None</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>apple</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>214</td>\n",
       "      <td>78.0</td>\n",
       "      <td>205</td>\n",
       "      <td>0.16336</td>\n",
       "      <td>19.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>None</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>solid</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>211</td>\n",
       "      <td>78.0</td>\n",
       "      <td>5523</td>\n",
       "      <td>-0.0377502</td>\n",
       "      <td>20.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>fail</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>seasoned</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   critiqued_keyphrase  item_id item_rank item_score  iteration  \\\n",
       "0                  NaN     78.0       NaN        NaN        0.0   \n",
       "1                   34     78.0       205    0.16336        1.0   \n",
       "2                  114     78.0      6164 -0.0512262        2.0   \n",
       "3                   90     78.0       205    0.16336        3.0   \n",
       "4                   76     78.0      6796 -0.0664696        4.0   \n",
       "5                   88     78.0       205    0.16336        5.0   \n",
       "6                   55     78.0       884  0.0593435        6.0   \n",
       "7                  152     78.0       205    0.16336        7.0   \n",
       "8                   27     78.0       884  0.0593435        8.0   \n",
       "9                    7     78.0      7330  -0.276029        9.0   \n",
       "10                 177     78.0      6278 -0.0596727       10.0   \n",
       "11                  24     78.0      5069 -0.0389414       11.0   \n",
       "12                  26     78.0       205    0.16336       12.0   \n",
       "13                 198     78.0       201   0.148447       13.0   \n",
       "14                  40     78.0       205    0.16336       14.0   \n",
       "15                  48     78.0       884  0.0593435       15.0   \n",
       "16                 183     78.0      7330  -0.276029       16.0   \n",
       "17                   5     78.0      6278 -0.0596727       17.0   \n",
       "18                  79     78.0      5069 -0.0389414       18.0   \n",
       "19                 214     78.0       205    0.16336       19.0   \n",
       "20                 211     78.0      5523 -0.0377502       20.0   \n",
       "\n",
       "    num_existing_keyphrases result  target_rank  user_id  \\\n",
       "0                      87.0    NaN         20.0      0.0   \n",
       "1                      87.0   None         20.0      0.0   \n",
       "2                      87.0   None         20.0      0.0   \n",
       "3                      87.0   None         20.0      0.0   \n",
       "4                      87.0   None         20.0      0.0   \n",
       "5                      87.0   None         20.0      0.0   \n",
       "6                      87.0   None         20.0      0.0   \n",
       "7                      87.0   None         20.0      0.0   \n",
       "8                      87.0   None         20.0      0.0   \n",
       "9                      87.0   None         20.0      0.0   \n",
       "10                     87.0   None         20.0      0.0   \n",
       "11                     87.0   None         20.0      0.0   \n",
       "12                     87.0   None         20.0      0.0   \n",
       "13                     87.0   None         20.0      0.0   \n",
       "14                     87.0   None         20.0      0.0   \n",
       "15                     87.0   None         20.0      0.0   \n",
       "16                     87.0   None         20.0      0.0   \n",
       "17                     87.0   None         20.0      0.0   \n",
       "18                     87.0   None         20.0      0.0   \n",
       "19                     87.0   None         20.0      0.0   \n",
       "20                     87.0   fail         20.0      0.0   \n",
       "\n",
       "   critiqued_keyphrase_name                                             lambda  \n",
       "0                       NaN                                                NaN  \n",
       "1                    potato                                         [0.0, 1.0]  \n",
       "2                    tomato                                    [1.0, 0.0, 0.0]  \n",
       "3                      tuna                               [0.0, 1.0, 0.0, 0.0]  \n",
       "4                   lettuce                          [0.0, 0.0, 0.0, 1.0, 0.0]  \n",
       "5                      four                     [0.0, 1.0, 0.0, 0.0, 0.0, 0.0]  \n",
       "6                      meat                [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]  \n",
       "7                     fresh           [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]  \n",
       "8                       bbq      [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]  \n",
       "9                    dinner  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...  \n",
       "10                   nicely  [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "11                 birthday  [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "12                 downtown  [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "13                  crunchy  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "14                    pizza  [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "15                   burger  [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, ...  \n",
       "16                attentive  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...  \n",
       "17                    fried  [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "18                    apple  [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "19                    solid  [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "20                 seasoned  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  "
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sum to one\n",
    "df.head(21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>critiqued_keyphrase</th>\n",
       "      <th>item_id</th>\n",
       "      <th>item_rank</th>\n",
       "      <th>item_score</th>\n",
       "      <th>iteration</th>\n",
       "      <th>num_existing_keyphrases</th>\n",
       "      <th>result</th>\n",
       "      <th>target_rank</th>\n",
       "      <th>user_id</th>\n",
       "      <th>critiqued_keyphrase_name</th>\n",
       "      <th>lambda</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>78.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>48</td>\n",
       "      <td>78.0</td>\n",
       "      <td>445</td>\n",
       "      <td>0.146624</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>None</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>burger</td>\n",
       "      <td>[1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>78.0</td>\n",
       "      <td>90</td>\n",
       "      <td>0.296639</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>None</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>fry</td>\n",
       "      <td>[1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34</td>\n",
       "      <td>78.0</td>\n",
       "      <td>56</td>\n",
       "      <td>0.487377</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>None</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>potato</td>\n",
       "      <td>[1, 1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>49</td>\n",
       "      <td>78.0</td>\n",
       "      <td>25</td>\n",
       "      <td>0.699528</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>None</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>cheese</td>\n",
       "      <td>[1, 1, 1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>52</td>\n",
       "      <td>78.0</td>\n",
       "      <td>30</td>\n",
       "      <td>0.722344</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>None</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>beef</td>\n",
       "      <td>[1, 1, 1, 1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>85</td>\n",
       "      <td>78.0</td>\n",
       "      <td>34</td>\n",
       "      <td>1.0858</td>\n",
       "      <td>6.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>None</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>patty</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>119</td>\n",
       "      <td>78.0</td>\n",
       "      <td>55</td>\n",
       "      <td>0.942795</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>None</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>bun</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>182</td>\n",
       "      <td>78.0</td>\n",
       "      <td>54</td>\n",
       "      <td>1.09857</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>None</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>chip</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>193</td>\n",
       "      <td>78.0</td>\n",
       "      <td>49</td>\n",
       "      <td>1.20376</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>None</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>mayo</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>206</td>\n",
       "      <td>78.0</td>\n",
       "      <td>43</td>\n",
       "      <td>1.26907</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>fail</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>salt</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>None</td>\n",
       "      <td>623.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>None</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>salt</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>58</td>\n",
       "      <td>623.0</td>\n",
       "      <td>136</td>\n",
       "      <td>0.366992</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>None</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>cocktail</td>\n",
       "      <td>[1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3</td>\n",
       "      <td>623.0</td>\n",
       "      <td>149</td>\n",
       "      <td>0.305369</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>None</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>bar</td>\n",
       "      <td>[1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>12</td>\n",
       "      <td>623.0</td>\n",
       "      <td>157</td>\n",
       "      <td>0.522642</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>None</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>mexican</td>\n",
       "      <td>[1, 1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>52</td>\n",
       "      <td>623.0</td>\n",
       "      <td>152</td>\n",
       "      <td>0.603731</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>None</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>beef</td>\n",
       "      <td>[1, 1, 1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>122</td>\n",
       "      <td>623.0</td>\n",
       "      <td>89</td>\n",
       "      <td>0.779942</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>None</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>bean</td>\n",
       "      <td>[1, 1, 1, 1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>142</td>\n",
       "      <td>623.0</td>\n",
       "      <td>155</td>\n",
       "      <td>0.671444</td>\n",
       "      <td>6.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>None</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>window</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>147</td>\n",
       "      <td>623.0</td>\n",
       "      <td>113</td>\n",
       "      <td>0.988513</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>None</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>market</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>168</td>\n",
       "      <td>623.0</td>\n",
       "      <td>170</td>\n",
       "      <td>0.854994</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>None</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>fair</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   critiqued_keyphrase  item_id item_rank item_score  iteration  \\\n",
       "0                  NaN     78.0       NaN        NaN        0.0   \n",
       "1                   48     78.0       445   0.146624        1.0   \n",
       "2                    4     78.0        90   0.296639        2.0   \n",
       "3                   34     78.0        56   0.487377        3.0   \n",
       "4                   49     78.0        25   0.699528        4.0   \n",
       "5                   52     78.0        30   0.722344        5.0   \n",
       "6                   85     78.0        34     1.0858        6.0   \n",
       "7                  119     78.0        55   0.942795        7.0   \n",
       "8                  182     78.0        54    1.09857        8.0   \n",
       "9                  193     78.0        49    1.20376        9.0   \n",
       "10                 206     78.0        43    1.26907       10.0   \n",
       "11                None    623.0      None       None        0.0   \n",
       "12                  58    623.0       136   0.366992        1.0   \n",
       "13                   3    623.0       149   0.305369        2.0   \n",
       "14                  12    623.0       157   0.522642        3.0   \n",
       "15                  52    623.0       152   0.603731        4.0   \n",
       "16                 122    623.0        89   0.779942        5.0   \n",
       "17                 142    623.0       155   0.671444        6.0   \n",
       "18                 147    623.0       113   0.988513        7.0   \n",
       "19                 168    623.0       170   0.854994        8.0   \n",
       "\n",
       "    num_existing_keyphrases result  target_rank  user_id  \\\n",
       "0                      10.0    NaN         20.0      0.0   \n",
       "1                      10.0   None         20.0      0.0   \n",
       "2                      10.0   None         20.0      0.0   \n",
       "3                      10.0   None         20.0      0.0   \n",
       "4                      10.0   None         20.0      0.0   \n",
       "5                      10.0   None         20.0      0.0   \n",
       "6                      10.0   None         20.0      0.0   \n",
       "7                      10.0   None         20.0      0.0   \n",
       "8                      10.0   None         20.0      0.0   \n",
       "9                      10.0   None         20.0      0.0   \n",
       "10                     10.0   fail         20.0      0.0   \n",
       "11                     10.0   None         20.0      0.0   \n",
       "12                     10.0   None         20.0      0.0   \n",
       "13                     10.0   None         20.0      0.0   \n",
       "14                     10.0   None         20.0      0.0   \n",
       "15                     10.0   None         20.0      0.0   \n",
       "16                     10.0   None         20.0      0.0   \n",
       "17                     10.0   None         20.0      0.0   \n",
       "18                     10.0   None         20.0      0.0   \n",
       "19                     10.0   None         20.0      0.0   \n",
       "\n",
       "   critiqued_keyphrase_name                          lambda  \n",
       "0                       NaN                             NaN  \n",
       "1                    burger                             [1]  \n",
       "2                       fry                          [1, 1]  \n",
       "3                    potato                       [1, 1, 1]  \n",
       "4                    cheese                    [1, 1, 1, 1]  \n",
       "5                      beef                 [1, 1, 1, 1, 1]  \n",
       "6                     patty              [1, 1, 1, 1, 1, 1]  \n",
       "7                       bun           [1, 1, 1, 1, 1, 1, 1]  \n",
       "8                      chip        [1, 1, 1, 1, 1, 1, 1, 1]  \n",
       "9                      mayo     [1, 1, 1, 1, 1, 1, 1, 1, 1]  \n",
       "10                     salt  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]  \n",
       "11                     salt  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]  \n",
       "12                 cocktail                             [1]  \n",
       "13                      bar                          [1, 1]  \n",
       "14                  mexican                       [1, 1, 1]  \n",
       "15                     beef                    [1, 1, 1, 1]  \n",
       "16                     bean                 [1, 1, 1, 1, 1]  \n",
       "17                   window              [1, 1, 1, 1, 1, 1]  \n",
       "18                   market           [1, 1, 1, 1, 1, 1, 1]  \n",
       "19                     fair        [1, 1, 1, 1, 1, 1, 1, 1]  "
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_step_critiquing_plrec(user = 2, \n",
    "                           keyphrase_length_threshold = 150, \n",
    "                           max_iteration_threshold = 5,\n",
    "                           k = 50,\n",
    "                           df = df,\n",
    "                           row = row,\n",
    "                           business_df = business_df,\n",
    "                           keyphrases = keyphrases,\n",
    "                           keyphrase_popularity = keyphrase_popularity, \n",
    "                           keyphrase_selection_method = 'random',\n",
    "                           recommend_type = 'all',\n",
    "                           lams = [0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1],\n",
    "                           reg = reg, Y = Y, RQt = RQt, Bias = Bias,\n",
    "                           top_k_rec = 20, affected_weight = 1, unaffected_weight = -1,\n",
    "                                 w1 = 1, w2 = 1,\n",
    "                            matrix_Train = rtrain,\n",
    "                            matrix_Test = rtest,\n",
    "                            keyphrase_freq = I_K,\n",
    "                            num_items = rtrain.shape[1],\n",
    "                            max_wanted_keyphrase = 10,\n",
    "                          ):\n",
    "    \"\"\"\n",
    "    k: HR@k \n",
    "    keyphrase_length_threshold: limit the number of keyphrases in top recommended item\n",
    "    keyphrase_selection_method: 'random': randomly select keyphrase from wanted_keyphrases\n",
    "                                'pop': always select the most popular keyphrase in wanted_keyphrases\n",
    "                                'diff': select the keyphrase with largest frequency difference between top recommended \n",
    "                                        item and target item.\n",
    "    recommend_type: 'all': recommend all items\n",
    "                    'upper' (only_with_critiqued_keyphrase): recommend items with only critiqued_keyphrase\n",
    "    lam: modified_matrix = lam*origianl_matrix + (1-lam)*critiquing_embedding \n",
    "    \"\"\"\n",
    "    \n",
    "    row['user_id'] = user\n",
    "    print ('User ID ', user)\n",
    "    \n",
    "    # Get wanted items \n",
    "    candidate_items = matrix_Test[user].nonzero()[1]\n",
    "    train_items = matrix_Train[user].nonzero()[1]\n",
    "    wanted_items = np.setdiff1d(candidate_items, train_items)\n",
    "    print ('wanted_items length: ',len(wanted_items))\n",
    "    \n",
    "    # Get initial forward prediction \n",
    "    prediction_score = predict_scores(matrix_U=RQ,\n",
    "                                      matrix_V=Y,\n",
    "                                      bias=Bias).T[user]\n",
    "    prediction_items = predict_vector(rating_vector=prediction_score,\n",
    "                                                              train_vector=matrix_Train[user],\n",
    "                                                              remove_train=True)\n",
    "    # Get initial top recommended item(s)\n",
    "    top_recommendations = np.argsort(prediction_score)[::-1]\n",
    "    print (\"Initial top recommendation index\",top_recommendations[0])\n",
    "    try:\n",
    "        row['top_prediction_item_name'] = get_restaurant_name(df_train, business_df, top_recommendations[0])\n",
    "    except: \n",
    "        row['top_prediction_item_name'] = 'CANNOT_FIND'\n",
    "        print ('Cannot get restaurant name for ItemIndex: ', top_recommendations[0])\n",
    "    \n",
    "    \n",
    "    # Get top recommended item's keyphrases\n",
    "    top_item = top_recommendations[0] \n",
    "    top_recommend_keyphrases = get_valid_keyphrases(keyphrase_freq,\n",
    "                                                    top_recommendations, \n",
    "                                                    item = top_item,\n",
    "                                                    threshold=keyphrase_length_threshold,\n",
    "                                                    mutiple_keyphrases_en = False, \n",
    "                                                    top_items = None)\n",
    "    top_recommended_keyphrase_freq = get_item_keyphrase_freq(keyphrase_freq,item = top_item)\n",
    "    \n",
    "    \n",
    "    #####################################\n",
    "    # For each item, do the critiquing\n",
    "    \n",
    "    #limit the item to only 10\n",
    "    num_target_item = 0 # initialize item count\n",
    "    \n",
    "    for item in wanted_items:    \n",
    "        print ('target_item: ', item)\n",
    "        row['target_item'] = item\n",
    "        try:\n",
    "            row['item_name'] = get_restaurant_name(df_train, business_df, item)\n",
    "        except:\n",
    "            row['item_name'] = 'CANNOT_FIND'\n",
    "            print ('Cannot get restaurant name for ItemIndex: ', item)\n",
    "\n",
    "        # Get pre-critiquing rank\n",
    "        initial_rank = np.where(item == np.argsort(prediction_score)[::-1])[0][0]\n",
    "        row['pre_rank'] = int(initial_rank)\n",
    "\n",
    "        # Get the target item's existing keyphrases\n",
    "        item_keyphrases = keyphrase_freq[item].nonzero()[1]\n",
    "        \n",
    "        # For diff \n",
    "        target_keyphrase_freq = get_item_keyphrase_freq(keyphrase_freq,item = item)\n",
    "        diff_keyphrase_freq = target_keyphrase_freq - top_recommended_keyphrase_freq\n",
    "        \n",
    "        wanted_keyphrases_random = np.setdiff1d(item_keyphrases,top_recommend_keyphrases)\n",
    "        wanted_keyphrases_pop = np.setdiff1d(item_keyphrases,top_recommend_keyphrases)\n",
    "        wanted_keyphrases_diff = np.argsort(np.ravel(diff_keyphrase_freq))[::-1][:max_wanted_keyphrase]\n",
    "        \n",
    "        pruned_prediction_score = pruning(prediction_score, \n",
    "                                           wanted_keyphrases_random, \n",
    "                                           top_recommendations, \n",
    "                                           keyphrase_freq, \n",
    "                                           matrix_Train = rtrain)\n",
    "        pure_pruning_rank = np.where(item == np.argsort(pruned_prediction_score)[::-1])[0][0]\n",
    "        if pure_pruning_rank>initial_rank:\n",
    "            pure_pruning_rank = initial_rank\n",
    "        row['pure_pruning_rank'] = int(pure_pruning_rank)    \n",
    "        \n",
    "        affected_items = np.array([])\n",
    "        modified_matrix = initial_user_similarity_embedding # initialize user similarity embedding\n",
    "        \n",
    "        #############################################\n",
    "        # Critiquing iteration\n",
    "        for iteration in range(max_iteration_threshold):\n",
    "            print ('cur_iter ', iteration)\n",
    "            row['iter'] = iteration\n",
    "\n",
    "            if len(wanted_keyphrases_random) == 0 or len(wanted_keyphrases_diff) == 0: \n",
    "                print ('no more keyphrase available')\n",
    "                break\n",
    "            critiqued_keyphrase_random = np.random.choice(wanted_keyphrases_random, size=1, replace=False)[0]\n",
    "            critiqued_keyphrase_pop = wanted_keyphrases_pop[np.argmin(keyphrase_popularity[wanted_keyphrases_pop])] # Select the least popular\n",
    "            critiqued_keyphrase_diff = wanted_keyphrases_diff[0]\n",
    "            \n",
    "            row['critiqued_keyphrase_random'] = critiqued_keyphrase_random\n",
    "            row['keyphrase_name_random'] = keyphrases[critiqued_keyphrase_random]\n",
    "            row['critiqued_keyphrase_pop'] = critiqued_keyphrase_pop\n",
    "            row['keyphrase_name_pop'] = keyphrases[critiqued_keyphrase_pop]\n",
    "            row['critiqued_keyphrase_diff'] = critiqued_keyphrase_diff\n",
    "            row['keyphrase_name_diff'] = keyphrases[critiqued_keyphrase_diff]\n",
    "            \n",
    "            # Do not critique this keyphrase next time\n",
    "            wanted_keyphrases_random = np.delete(wanted_keyphrases_random, np.where(critiqued_keyphrase_random == wanted_keyphrases_random))\n",
    "            wanted_keyphrases_pop = np.delete(wanted_keyphrases_pop, np.where(critiqued_keyphrase_pop == wanted_keyphrases_pop))\n",
    "            wanted_keyphrases_diff = np.delete(wanted_keyphrases_diff, np.where(critiqued_keyphrase_diff == wanted_keyphrases_diff))\n",
    "            \n",
    "            # Critiquing Embedding\n",
    "\n",
    "            # One hot encoding\n",
    "            critiqued_matrix_onehot = get_critiqued_UK(U_K,user,critiqued_keyphrase_random)\n",
    "            critiqued_matrix = reg.predict(critiqued_matrix_onehot)\n",
    "            critiqued_matrix_random =critiqued_matrix\n",
    "\n",
    "            critiqued_matrix_onehot = get_critiqued_UK(U_K,user,critiqued_keyphrase_pop)\n",
    "            critiqued_matrix = reg.predict(critiqued_matrix_onehot)\n",
    "            critiqued_matrix_pop = critiqued_matrix\n",
    "\n",
    "            critiqued_matrix_onehot = get_critiqued_UK(U_K,user,critiqued_keyphrase_diff)\n",
    "            critiqued_matrix = reg.predict(critiqued_matrix_onehot)\n",
    "            critiqued_matrix_diff = critiqued_matrix\n",
    "\n",
    "\n",
    "            # Warning!!! The following is used only for testing single step critiquing, \n",
    "            # for full average critiquing, use the above commented line \n",
    "            post_ranks_random_all = []\n",
    "            post_ranks_random_upper = []\n",
    "            random_scores = []\n",
    "            random_ratings = []\n",
    "            post_ranks_pop_all = []\n",
    "            post_ranks_pop_upper = []\n",
    "            pop_scores = []\n",
    "            pop_ratings = []\n",
    "            post_ranks_diff_all = []\n",
    "            post_ranks_diff_upper = []\n",
    "            diff_scores = []\n",
    "            diff_ratings = []\n",
    "            \n",
    "            num_items = matrix_Train.shape[1]\n",
    "            affected_items_random = keyphrase_freq[:,critiqued_keyphrase_random].nonzero()[0]\n",
    "            affected_items_pop = keyphrase_freq[:,critiqued_keyphrase_pop].nonzero()[0]\n",
    "            affected_items_diff = keyphrase_freq[:,critiqued_keyphrase_diff].nonzero()[0]\n",
    "            \n",
    "            unaffected_items_random = np.setdiff1d(range(num_items), affected_items_random)\n",
    "            unaffected_items_pop = np.setdiff1d(range(num_items), affected_items_pop)\n",
    "            unaffected_items_diff = np.setdiff1d(range(num_items), affected_items_diff)\n",
    "            \n",
    "            for lam in lams:\n",
    "                modified_matrix_random = (1-lam)*Y + lam*critiqued_matrix_random \n",
    "                modified_matrix_pop = (1-lam)*Y + lam*critiqued_matrix_pop \n",
    "                modified_matrix_diff = (1-lam)*Y + lam*critiqued_matrix_diff \n",
    "                \n",
    "                # Random\n",
    "                prediction_scores_u = predict_scores(matrix_U=modified_matrix_random[user], \n",
    "                                     matrix_V=RQ,\n",
    "                                     )\n",
    "                prediction_items = predict_vector(rating_vector=prediction_scores_u,\n",
    "                                                  train_vector=matrix_Train[user],\n",
    "                                                  remove_train=False)\n",
    "                \n",
    "                item_rank = np.where(prediction_items == item)[0][0]\n",
    "                post_ranks_random_all.append(item_rank)\n",
    "                \n",
    "                # Random scores\n",
    "                affected_hit = sum(np.in1d(prediction_items[:top_k_rec],affected_items_random))\n",
    "                unaffected_hit = sum(np.in1d(prediction_items[:top_k_rec],unaffected_items_random))\n",
    "                score = affected_weight*affected_hit + unaffected_weight*unaffected_hit\n",
    "                random_scores.append(score)\n",
    "                \n",
    "                # Random Rating\n",
    "                latent_diff = modified_matrix_random - Y #post-pre\n",
    "                rating_diff = predict_scores(matrix_U=latent_diff[user], \n",
    "                                     matrix_V=RQ,\n",
    "                                     )\n",
    "                affected_items_mask = np.in1d(prediction_items, affected_items_random)\n",
    "                affected_items_index_rank = np.where(affected_items_mask == True)\n",
    "                unaffected_items_index_rank = np.where(affected_items_mask == False)\n",
    "                \n",
    "                rating_diff_sum_unaffected = np.sum(np.abs(rating_diff), \n",
    "                                                    where = np.in1d(range(num_items),np.intersect1d(unaffected_items_random, prediction_items[unaffected_items_index_rank[0][:100]])))\n",
    "                rating_diff_sum_affected = np.sum(rating_diff, where = np.in1d(range(num_items), \n",
    "                                                                               np.intersect1d(affected_items_random, prediction_items[affected_items_index_rank[0][:100]])))\n",
    "                rating_score = w1*rating_diff_sum_unaffected - w2*rating_diff_sum_affected\n",
    "#                 print (rating_score)\n",
    "                random_ratings.append(rating_score)\n",
    "    \n",
    "                # Random upper \n",
    "                prediction_scores_u = predict_scores(matrix_U=modified_matrix_random[user], \n",
    "                                                     matrix_V=RQ, \n",
    "                                                     bias=None,\n",
    "                                                   penalize = True,\n",
    "                                                   keyphrase_freq = keyphrase_freq, \n",
    "                                                   critiqued_keyphrase = critiqued_keyphrase_random, \n",
    "                                                   matrix_Train = matrix_Train,\n",
    "                                                   alpha = 0)\n",
    "                prediction_items = predict_vector(rating_vector=prediction_scores_u,\n",
    "                                                  train_vector=matrix_Train[user],\n",
    "                                                  remove_train=False)\n",
    "                item_rank = np.where(prediction_items == item)[0][0]\n",
    "                post_ranks_random_upper.append(item_rank)\n",
    "                \n",
    "                # Pop\n",
    "                prediction_scores_u = predict_scores(matrix_U=modified_matrix_pop[user], \n",
    "                                     matrix_V=RQ,\n",
    "                                     )\n",
    "                prediction_items = predict_vector(rating_vector=prediction_scores_u,\n",
    "                                                  train_vector=matrix_Train[user],\n",
    "                                                  remove_train=False)\n",
    "                \n",
    "                item_rank = np.where(prediction_items == item)[0][0]\n",
    "                post_ranks_pop_all.append(item_rank)\n",
    "                \n",
    "                \n",
    "                # pop scores\n",
    "                affected_hit = sum(np.in1d(prediction_items[:top_k_rec],affected_items_pop))\n",
    "                unaffected_hit = sum(np.in1d(prediction_items[:top_k_rec],unaffected_items_pop))\n",
    "                score = affected_weight*affected_hit + unaffected_weight*unaffected_hit\n",
    "                pop_scores.append(score)\n",
    "            \n",
    "                # Pop Rating\n",
    "                latent_diff = modified_matrix_pop - Y #post-pre\n",
    "                rating_diff = predict_scores(matrix_U=latent_diff[user], \n",
    "                                     matrix_V=RQ,\n",
    "                                     )\n",
    "                affected_items_mask = np.in1d(prediction_items, affected_items_pop)\n",
    "                affected_items_index_rank = np.where(affected_items_mask == True)\n",
    "                unaffected_items_index_rank = np.where(affected_items_mask == False)\n",
    "                \n",
    "                rating_diff_sum_unaffected = np.sum(np.abs(rating_diff), where = np.in1d(range(num_items),np.intersect1d(unaffected_items_pop, prediction_items[unaffected_items_index_rank[0][:100]])))\n",
    "                rating_diff_sum_affected = np.sum(rating_diff, where = np.in1d(range(num_items), np.intersect1d(affected_items_pop, prediction_items[affected_items_index_rank[0][:100]])))\n",
    "                rating_score = w1*rating_diff_sum_unaffected - w2*rating_diff_sum_affected\n",
    "                pop_ratings.append(rating_score)\n",
    "                \n",
    "                # Pop upper \n",
    "                \n",
    "                prediction_scores_u = predict_scores(matrix_U=modified_matrix_pop[user], \n",
    "                                                     matrix_V=RQ, \n",
    "                                                     bias=None,\n",
    "                                                   penalize = True,\n",
    "                                                   keyphrase_freq = keyphrase_freq, \n",
    "                                                   critiqued_keyphrase = critiqued_keyphrase_pop, \n",
    "                                                   matrix_Train = matrix_Train,\n",
    "                                                   alpha = 0)\n",
    "                prediction_items = predict_vector(rating_vector=prediction_scores_u,\n",
    "                                                  train_vector=matrix_Train[user],\n",
    "                                                  remove_train=False)\n",
    "                item_rank = np.where(prediction_items == item)[0][0]\n",
    "                post_ranks_pop_upper.append(item_rank)\n",
    "                \n",
    "                # Diff\n",
    "                prediction_scores_u = predict_scores(matrix_U=modified_matrix_diff[user], \n",
    "                                     matrix_V=RQ,\n",
    "                                     )\n",
    "                prediction_items = predict_vector(rating_vector=prediction_scores_u,\n",
    "                                                  train_vector=matrix_Train[user],\n",
    "                                                  remove_train=False)\n",
    "                \n",
    "                item_rank = np.where(prediction_items == item)[0][0]\n",
    "                post_ranks_diff_all.append(item_rank)\n",
    "                \n",
    "                # Diff scores\n",
    "                affected_hit = sum(np.in1d(prediction_items[:top_k_rec],affected_items_diff))\n",
    "                unaffected_hit = sum(np.in1d(prediction_items[:top_k_rec],unaffected_items_diff))\n",
    "                score = affected_weight*affected_hit + unaffected_weight*unaffected_hit\n",
    "                diff_scores.append(score)\n",
    "                \n",
    "                # Diff Rating\n",
    "                latent_diff = modified_matrix_diff - Y #post-pre\n",
    "                rating_diff = predict_scores(matrix_U=latent_diff[user], \n",
    "                                     matrix_V=RQ,\n",
    "                                     )\n",
    "                affected_items_mask = np.in1d(prediction_items, affected_items_diff)\n",
    "                affected_items_index_rank = np.where(affected_items_mask == True)\n",
    "                unaffected_items_index_rank = np.where(affected_items_mask == False)\n",
    "                \n",
    "                rating_diff_sum_unaffected = np.sum(np.abs(rating_diff), where = np.in1d(range(num_items),np.intersect1d(unaffected_items_diff, prediction_items[unaffected_items_index_rank[0][:100]])))\n",
    "                rating_diff_sum_affected = np.sum(rating_diff, where = np.in1d(range(num_items), np.intersect1d(affected_items_diff, prediction_items[affected_items_index_rank[0][:100]])))\n",
    "                rating_score = w1*rating_diff_sum_unaffected - w2*rating_diff_sum_affected\n",
    "                diff_ratings.append(rating_score)\n",
    "                # Diff upper \n",
    "                prediction_scores_u = predict_scores(matrix_U=modified_matrix_diff[user], \n",
    "                                                     matrix_V=RQ, \n",
    "                                                     bias=None,\n",
    "                                                   penalize = True,\n",
    "                                                   keyphrase_freq = keyphrase_freq, \n",
    "                                                   critiqued_keyphrase = critiqued_keyphrase_diff, \n",
    "                                                   matrix_Train = matrix_Train,\n",
    "                                                   alpha = 0)\n",
    "                prediction_items = predict_vector(rating_vector=prediction_scores_u,\n",
    "                                                  train_vector=matrix_Train[user],\n",
    "                                                  remove_train=False)\n",
    "                item_rank = np.where(prediction_items == item)[0][0]\n",
    "                post_ranks_diff_upper.append(item_rank)\n",
    "            \n",
    "            ######################################################\n",
    "            # optimal predicted lambda from ranking obj \n",
    "            random_ranking_opti_predicted = lams[np.argmax(random_scores)]\n",
    "            pop_ranking_opti_predicted = lams[np.argmax(pop_scores)]\n",
    "            diff_ranking_opti_predicted = lams[np.argmax(diff_scores)]\n",
    "            \n",
    "            # optimal predicted lambda from rating obj \n",
    "            random_rating_opti_predicted = lams[np.argmin(random_ratings)]\n",
    "            pop_rating_opti_predicted = lams[np.argmin(pop_ratings)]\n",
    "            diff_rating_opti_predicted = lams[np.argmin(diff_ratings)]\n",
    "            \n",
    "            ####################################################\n",
    "            # Get optimal post_ranking predicted\n",
    "            modified_matrix_random_opti_predicted = (1-random_ranking_opti_predicted)*Y + random_ranking_opti_predicted*critiqued_matrix_random \n",
    "            modified_matrix_pop_opti_predicted = (1-random_ranking_opti_predicted)*Y + random_ranking_opti_predicted*critiqued_matrix_pop \n",
    "            modified_matrix_diff_opti_predicted = (1-random_ranking_opti_predicted)*Y + random_ranking_opti_predicted*critiqued_matrix_diff \n",
    "            # Random\n",
    "            prediction_scores_u = predict_scores(matrix_U=modified_matrix_random_opti_predicted[user], \n",
    "                                     matrix_V=RQ,\n",
    "                                     )\n",
    "            prediction_items = predict_vector(rating_vector=prediction_scores_u,\n",
    "                                              train_vector=matrix_Train[user],\n",
    "                                              remove_train=False)\n",
    "\n",
    "            item_rank = np.where(prediction_items == item)[0][0]\n",
    "            row['random_opti_ranking'] = item_rank\n",
    "            \n",
    "            modified_matrix_random_opti_predicted = (1-random_rating_opti_predicted)*Y + random_rating_opti_predicted*critiqued_matrix_random \n",
    "            prediction_scores_u = predict_scores(matrix_U=modified_matrix_random_opti_predicted[user], \n",
    "                                     matrix_V=RQ,\n",
    "                                     )\n",
    "            prediction_items = predict_vector(rating_vector=prediction_scores_u,\n",
    "                                              train_vector=matrix_Train[user],\n",
    "                                              remove_train=False)\n",
    "\n",
    "            item_rank = np.where(prediction_items == item)[0][0]\n",
    "            row['random_opti_rating'] = item_rank\n",
    "            \n",
    "            # Pop\n",
    "            prediction_scores_u = predict_scores(matrix_U=modified_matrix_pop_opti_predicted[user], \n",
    "                                     matrix_V=RQ,\n",
    "                                     )\n",
    "            prediction_items = predict_vector(rating_vector=prediction_scores_u,\n",
    "                                              train_vector=matrix_Train[user],\n",
    "                                              remove_train=False)\n",
    "\n",
    "            item_rank = np.where(prediction_items == item)[0][0]\n",
    "            row['pop_opti_ranking'] = item_rank\n",
    "            \n",
    "            modified_matrix_pop_opti_predicted = (1-pop_rating_opti_predicted)*Y + pop_rating_opti_predicted*critiqued_matrix_pop \n",
    "            prediction_scores_u = predict_scores(matrix_U=modified_matrix_pop_opti_predicted[user], \n",
    "                                     matrix_V=RQ,\n",
    "                                     )\n",
    "            prediction_items = predict_vector(rating_vector=prediction_scores_u,\n",
    "                                              train_vector=matrix_Train[user],\n",
    "                                              remove_train=False)\n",
    "\n",
    "            item_rank = np.where(prediction_items == item)[0][0]\n",
    "            row['pop_opti_rating'] = item_rank\n",
    "            \n",
    "            # Diff\n",
    "            prediction_scores_u = predict_scores(matrix_U=modified_matrix_diff_opti_predicted[user], \n",
    "                                     matrix_V=RQ,\n",
    "                                     )\n",
    "            prediction_items = predict_vector(rating_vector=prediction_scores_u,\n",
    "                                              train_vector=matrix_Train[user],\n",
    "                                              remove_train=False)\n",
    "\n",
    "            item_rank = np.where(prediction_items == item)[0][0]\n",
    "            row['diff_opti_ranking'] = item_rank\n",
    "#             print ('diff_opti_ranking ', item_rank)\n",
    "            \n",
    "            modified_matrix_diff_opti_predicted = (1-diff_rating_opti_predicted)*Y + diff_rating_opti_predicted*critiqued_matrix_diff \n",
    "            prediction_scores_u = predict_scores(matrix_U=modified_matrix_diff_opti_predicted[user], \n",
    "                                     matrix_V=RQ,\n",
    "                                     )\n",
    "            prediction_items = predict_vector(rating_vector=prediction_scores_u,\n",
    "                                              train_vector=matrix_Train[user],\n",
    "                                              remove_train=False)\n",
    "\n",
    "            item_rank = np.where(prediction_items == item)[0][0]\n",
    "            row['diff_opti_rating'] = item_rank\n",
    "            \n",
    "            row['post_rank_random_all'] = post_ranks_random_all\n",
    "            row['post_rank_random_upper'] = post_ranks_random_upper\n",
    "            row['random_scores'] = random_scores\n",
    "            row['random_ratings'] = random_ratings\n",
    "            \n",
    "            row['post_rank_pop_all'] = post_ranks_pop_all\n",
    "            row['post_rank_pop_upper'] = post_ranks_pop_upper\n",
    "            row['pop_scores'] = pop_scores\n",
    "            row['pop_ratings'] = pop_ratings\n",
    "            \n",
    "            row['post_rank_diff_all'] = post_ranks_diff_all\n",
    "            row['post_rank_diff_upper'] = post_ranks_diff_upper\n",
    "            row['diff_scores'] = diff_scores\n",
    "            row['diff_ratings'] = diff_ratings\n",
    "            \n",
    "            df = df.append(row, ignore_index=True)\n",
    "            \n",
    "\n",
    "        # break after got 10 target items \n",
    "        num_target_item += 1\n",
    "        if num_target_item >10: # only want max 10 items per user\n",
    "            break\n",
    "            \n",
    "    return df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
