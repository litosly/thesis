{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_dataframe_csv(df, path, name):\n",
    "    df.to_csv(path+name, index=False)\n",
    "\n",
    "\n",
    "def load_dataframe_csv(path, name, index_col=None):\n",
    "    return pd.read_csv(path+name, index_col=index_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_average_length(df, n):\n",
    "    df_s_f = df[(df['result'] == 'successful') | (df['result'] == 'fail')]\n",
    "    iteration = df_s_f[df_s_f['target_rank']==n].groupby('user_id', as_index=False).agg({'iteration':'mean'})['iteration'].to_numpy()\n",
    "    return (np.average(iteration), 1.96*np.std(iteration)/np.sqrt(len(iteration)))\n",
    "\n",
    "def get_success_num(df, n):\n",
    "    return len(df[(df['result'] == 'successful') & (df['target_rank'] == n)])\n",
    "\n",
    "def get_fail_num(df, n):\n",
    "    return len(df[(df['result'] == 'fail') & (df['target_rank'] == n)])\n",
    "\n",
    "def get_success_rate(df, n):\n",
    "    df_s_f = df[(df['result'] == 'successful') | (df['result'] == 'fail')]\n",
    "    df_list_result = df_s_f[df_s_f['target_rank']==n].groupby('user_id', as_index=False)['result'].apply(list).reset_index(name='result')\n",
    "    successful_rate = df_list_result['result'].apply(lambda r: r.count(\"successful\")/len(r)).to_numpy()\n",
    "    return (np.average(successful_rate), 1.96*np.std(successful_rate)/np.sqrt(len(successful_rate)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_2_metric(df, topk = 20, print_result = True):\n",
    "    if print_result:\n",
    "        print ('avg_length: ',get_average_length(df,topk))\n",
    "        print ('suc_rate: ',get_success_rate(df,topk))\n",
    "        return \n",
    "    else:\n",
    "        return get_average_length(df,topk), get_success_rate(df,topk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_metric_with_single_lambda(data_path, lambs, topk = 20, return_all = False):\n",
    "    avg_lengths = []\n",
    "    suc_rates = []\n",
    "    for lamb in lambs:\n",
    "        \n",
    "        table_name = 'tuning_lamb_'+ str(lamb) + '.csv'\n",
    "        df = load_dataframe_csv(data_path, table_name)\n",
    "        avg_length, suc_rate = get_2_metric(df, topk = topk, print_result = False)\n",
    "#         print ('avg_length', avg_length)\n",
    "#         print ('suc_rate', suc_rate)\n",
    "        avg_lengths.append(avg_length)\n",
    "        suc_rates.append(suc_rate)\n",
    "        \n",
    "    if return_all:\n",
    "        return avg_lengths, suc_rates\n",
    "    else:\n",
    "        suc_rates_temp = [suc_rate[0] for suc_rate in suc_rates]\n",
    "        optimal_lambda_index = np.argmax(suc_rates_temp)\n",
    "#         print (optimal_lambda_index)\n",
    "        return lambs[optimal_lambda_index], avg_lengths[optimal_lambda_index], suc_rates[optimal_lambda_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg_length:  (15.271784016636957, 2.284562766322932)\n",
      "suc_rate:  (0.30891902215431627, 0.1422322315874033)\n"
     ]
    }
   ],
   "source": [
    "table_path = '../tables/critiquing/multi_step_critiquing/beer/avg/avg_25user.csv'\n",
    "df = load_dataframe_csv(table_path,\"\")     \n",
    "get_2_metric(df,topk = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1,\n",
       " (15.140380697733638, 2.2842677996023304),\n",
       " (0.294980264833206, 0.13289815128618654))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_best_metric_with_single_lambda(data_path='../tables/critiquing/multi_step_critiquing/beer/ranksvm3/',\n",
    "                                   lambs = [0.001,0.01,0.1,0.5,1,10,30,50,70,90,100,1000],\n",
    "                                   topk=50,\n",
    "                                   return_all=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
